/*===---- riscv_vector.h - RISC-V V-extension RVVIntrinsics -------------------===
 *
 *
 * Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
 * See https://llvm.org/LICENSE.txt for license information.
 * SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
 *
 *===-----------------------------------------------------------------------===
 */

#ifndef __RISCV_VECTOR_H
#define __RISCV_VECTOR_H

#include <stdint.h>
#include <stddef.h>

#ifndef __riscv_vector
#error "Vector intrinsics require the vector extension."
#endif

#ifdef __cplusplus
extern "C" {
#endif


#define vsetvl_e8mf8(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 5)
#define vsetvl_e8mf4(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 6)
#define vsetvl_e8mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 7)
#define vsetvl_e8m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 0)
#define vsetvl_e8m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 1)
#define vsetvl_e8m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 2)
#define vsetvl_e8m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 0, 3)

#define vsetvl_e16mf4(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 6)
#define vsetvl_e16mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 7)
#define vsetvl_e16m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 0)
#define vsetvl_e16m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 1)
#define vsetvl_e16m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 2)
#define vsetvl_e16m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 1, 3)

#define vsetvl_e32mf2(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 7)
#define vsetvl_e32m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 0)
#define vsetvl_e32m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 1)
#define vsetvl_e32m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 2)
#define vsetvl_e32m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 2, 3)

#define vsetvl_e64m1(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 0)
#define vsetvl_e64m2(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 1)
#define vsetvl_e64m4(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 2)
#define vsetvl_e64m8(avl) __builtin_rvv_vsetvli((size_t)(avl), 3, 3)


#define vsetvlmax_e8mf8() __builtin_rvv_vsetvlimax(0, 5)
#define vsetvlmax_e8mf4() __builtin_rvv_vsetvlimax(0, 6)
#define vsetvlmax_e8mf2() __builtin_rvv_vsetvlimax(0, 7)
#define vsetvlmax_e8m1() __builtin_rvv_vsetvlimax(0, 0)
#define vsetvlmax_e8m2() __builtin_rvv_vsetvlimax(0, 1)
#define vsetvlmax_e8m4() __builtin_rvv_vsetvlimax(0, 2)
#define vsetvlmax_e8m8() __builtin_rvv_vsetvlimax(0, 3)

#define vsetvlmax_e16mf4() __builtin_rvv_vsetvlimax(1, 6)
#define vsetvlmax_e16mf2() __builtin_rvv_vsetvlimax(1, 7)
#define vsetvlmax_e16m1() __builtin_rvv_vsetvlimax(1, 0)
#define vsetvlmax_e16m2() __builtin_rvv_vsetvlimax(1, 1)
#define vsetvlmax_e16m4() __builtin_rvv_vsetvlimax(1, 2)
#define vsetvlmax_e16m8() __builtin_rvv_vsetvlimax(1, 3)

#define vsetvlmax_e32mf2() __builtin_rvv_vsetvlimax(2, 7)
#define vsetvlmax_e32m1() __builtin_rvv_vsetvlimax(2, 0)
#define vsetvlmax_e32m2() __builtin_rvv_vsetvlimax(2, 1)
#define vsetvlmax_e32m4() __builtin_rvv_vsetvlimax(2, 2)
#define vsetvlmax_e32m8() __builtin_rvv_vsetvlimax(2, 3)

#define vsetvlmax_e64m1() __builtin_rvv_vsetvlimax(3, 0)
#define vsetvlmax_e64m2() __builtin_rvv_vsetvlimax(3, 1)
#define vsetvlmax_e64m4() __builtin_rvv_vsetvlimax(3, 2)
#define vsetvlmax_e64m8() __builtin_rvv_vsetvlimax(3, 3)

typedef __rvv_bool64_t vbool64_t;
typedef __rvv_bool32_t vbool32_t;
typedef __rvv_bool16_t vbool16_t;
typedef __rvv_bool8_t vbool8_t;
typedef __rvv_bool4_t vbool4_t;
typedef __rvv_bool2_t vbool2_t;
typedef __rvv_bool1_t vbool1_t;
typedef __rvv_int8mf8_t vint8mf8_t;
typedef __rvv_uint8mf8_t vuint8mf8_t;
typedef __rvv_int8mf4_t vint8mf4_t;
typedef __rvv_uint8mf4_t vuint8mf4_t;
typedef __rvv_int8mf2_t vint8mf2_t;
typedef __rvv_uint8mf2_t vuint8mf2_t;
typedef __rvv_int8m1_t vint8m1_t;
typedef __rvv_uint8m1_t vuint8m1_t;
typedef __rvv_int8m2_t vint8m2_t;
typedef __rvv_uint8m2_t vuint8m2_t;
typedef __rvv_int8m4_t vint8m4_t;
typedef __rvv_uint8m4_t vuint8m4_t;
typedef __rvv_int8m8_t vint8m8_t;
typedef __rvv_uint8m8_t vuint8m8_t;
typedef __rvv_int16mf4_t vint16mf4_t;
typedef __rvv_uint16mf4_t vuint16mf4_t;
typedef __rvv_int16mf2_t vint16mf2_t;
typedef __rvv_uint16mf2_t vuint16mf2_t;
typedef __rvv_int16m1_t vint16m1_t;
typedef __rvv_uint16m1_t vuint16m1_t;
typedef __rvv_int16m2_t vint16m2_t;
typedef __rvv_uint16m2_t vuint16m2_t;
typedef __rvv_int16m4_t vint16m4_t;
typedef __rvv_uint16m4_t vuint16m4_t;
typedef __rvv_int16m8_t vint16m8_t;
typedef __rvv_uint16m8_t vuint16m8_t;
typedef __rvv_int32mf2_t vint32mf2_t;
typedef __rvv_uint32mf2_t vuint32mf2_t;
typedef __rvv_int32m1_t vint32m1_t;
typedef __rvv_uint32m1_t vuint32m1_t;
typedef __rvv_int32m2_t vint32m2_t;
typedef __rvv_uint32m2_t vuint32m2_t;
typedef __rvv_int32m4_t vint32m4_t;
typedef __rvv_uint32m4_t vuint32m4_t;
typedef __rvv_int32m8_t vint32m8_t;
typedef __rvv_uint32m8_t vuint32m8_t;
typedef __rvv_int64m1_t vint64m1_t;
typedef __rvv_uint64m1_t vuint64m1_t;
typedef __rvv_int64m2_t vint64m2_t;
typedef __rvv_uint64m2_t vuint64m2_t;
typedef __rvv_int64m4_t vint64m4_t;
typedef __rvv_uint64m4_t vuint64m4_t;
typedef __rvv_int64m8_t vint64m8_t;
typedef __rvv_uint64m8_t vuint64m8_t;
#if defined(__riscv_zfh)
typedef __rvv_float16mf4_t vfloat16mf4_t;
typedef __rvv_float16mf2_t vfloat16mf2_t;
typedef __rvv_float16m1_t vfloat16m1_t;
typedef __rvv_float16m2_t vfloat16m2_t;
typedef __rvv_float16m4_t vfloat16m4_t;
typedef __rvv_float16m8_t vfloat16m8_t;
#endif
#if defined(__riscv_f)
typedef __rvv_float32mf2_t vfloat32mf2_t;
typedef __rvv_float32m1_t vfloat32m1_t;
typedef __rvv_float32m2_t vfloat32m2_t;
typedef __rvv_float32m4_t vfloat32m4_t;
typedef __rvv_float32m8_t vfloat32m8_t;
#endif
#if defined(__riscv_d)
typedef __rvv_float64m1_t vfloat64m1_t;
typedef __rvv_float64m2_t vfloat64m2_t;
typedef __rvv_float64m4_t vfloat64m4_t;
typedef __rvv_float64m8_t vfloat64m8_t;
#endif

#define vadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16mf4((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16mf2((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16m1((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16m2((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16m4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u16m8((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwaddu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwaddu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u32mf2((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwaddu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u32m1((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u32m2((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwaddu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u32m4((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u32m8((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwaddu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u64m1((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u64m2((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwaddu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u64m4((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwaddu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vv_u64m8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwaddu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m1((const uint8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m2((const uint8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m4((const uint8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_u8m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8m8((const uint8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vluxei8_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf2((const uint8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf4((const uint8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u8mf8((const uint8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8m1((const uint8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8m2((const uint8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf2((const uint8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf4((const uint8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u8mf8((const uint8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8m1((const int8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf2((const int8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf4((const int8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i8mf8((const int8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8m1((const uint8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf2((const uint8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf4((const uint8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u8mf8((const uint8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m1((const int16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m2((const int16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m4((const int16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i16m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16m8((const int16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16mf2((const int16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i16mf4((const int16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m1((const uint16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m2((const uint16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m4((const uint16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u16m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16m8((const uint16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16mf2((const uint16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u16mf4((const uint16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m1((const int16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m2((const int16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m4((const int16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i16m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16m8((const int16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16mf2((const int16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i16mf4((const int16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m1((const uint16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m2((const uint16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m4((const uint16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u16m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16m8((const uint16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16mf2((const uint16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u16mf4((const uint16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m1((const int16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m2((const int16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i16m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16m4((const int16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16mf2((const int16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i16mf4((const int16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m1((const uint16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m2((const uint16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u16m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16m4((const uint16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16mf2((const uint16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u16mf4((const uint16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i16m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16m1((const int16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i16m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16m2((const int16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16mf2((const int16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i16mf4((const int16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u16m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16m1((const uint16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u16m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16m2((const uint16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16mf2((const uint16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u16mf4((const uint16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m1((const int32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m2((const int32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m4((const int32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32m8((const int32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i32mf2((const int32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m1((const uint32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m2((const uint32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m4((const uint32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32m8((const uint32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u32mf2((const uint32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m1((const int32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m2((const int32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m4((const int32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32m8((const int32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i32mf2((const int32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m1((const uint32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m2((const uint32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m4((const uint32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32m8((const uint32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u32mf2((const uint32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m1((const int32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m2((const int32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m4((const int32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32m8((const int32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i32mf2((const int32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m1((const uint32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m2((const uint32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m4((const uint32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32m8((const uint32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u32mf2((const uint32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m1((const int32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m2((const int32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32m4((const int32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i32mf2((const int32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m1((const uint32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m2((const uint32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32m4((const uint32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u32mf2((const uint32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m1((const int64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m2((const int64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m4((const int64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i64m8((const int64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m1((const uint64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m2((const uint64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m4((const uint64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u64m8((const uint64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m1((const int64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m2((const int64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m4((const int64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i64m8((const int64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m1((const uint64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m2((const uint64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m4((const uint64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u64m8((const uint64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m1((const int64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m2((const int64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m4((const int64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i64m8((const int64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m1((const uint64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m2((const uint64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m4((const uint64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_u64m8((const uint64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m1((const int64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m2((const int64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m4((const int64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_i64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_i64m8((const int64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m1((const uint64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m2((const uint64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m4((const uint64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_u64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_u64m8((const uint64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse8_v_i8m1(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse8_v_i8m2(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse8_v_i8m4(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse8_v_i8m8(op1, op0, op2) \
__builtin_rvv_vse8_v_i8m8((vint8m8_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8m8_m((vint8m8_t)(op0), (int8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vse8_v_i8mf2(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse8_v_i8mf4(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse8_v_i8mf8(op1, op0, op2) \
__builtin_rvv_vse8_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (size_t)(op2))
#define vse8_v_i8mf8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8m8((vint8m8_t)(op0), (int8_t *)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8m8_m((vint8m8_t)(op0), (int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8m8((vuint8m8_t)(op0), (uint8_t *)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8m8_m((vuint8m8_t)(op0), (uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vse8_v_u8m1(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse8_v_u8m2(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse8_v_u8m4(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse8_v_u8m8(op1, op0, op2) \
__builtin_rvv_vse8_v_u8m8((vuint8m8_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8m8_m((vuint8m8_t)(op0), (uint8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vse8_v_u8mf2(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse8_v_u8mf4(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse8_v_u8mf8(op1, op0, op2) \
__builtin_rvv_vse8_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse8_v_u8mf8_m(op2, op1, op0, op3) \
__builtin_rvv_vse8_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse8_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse8_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse8_v_i8m4(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsse8_v_i8m8(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8m8((vint8m8_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8m8_m((vint8m8_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsse8_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse8_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse8_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16mf4((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16mf2((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16m1((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16m2((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16m4((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_wv_u16m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u16m8((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwaddu_wv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwaddu_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u32mf2((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwaddu_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u32m2((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwaddu_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u32m4((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wv_u32m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u32m8((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwaddu_wv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_wv_u64m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u64m1((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wv_u64m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u64m2((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwaddu_wv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wv_u64m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u64m4((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwaddu_wv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wv_u64m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wv_u64m8((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwaddu_wv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse8_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse8_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse8_v_u8m4(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsse8_v_u8m8(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8m8((vuint8m8_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8m8_m((vuint8m8_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsse8_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse8_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse8_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsse8_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse8_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse8_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8m1((vint8m1_t)(op0), (int8_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8m1_m((vint8m1_t)(op0), (int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8m2((vint8m2_t)(op0), (int8_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8m2_m((vint8m2_t)(op0), (int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8m4((vint8m4_t)(op0), (int8_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8m4_m((vint8m4_t)(op0), (int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8m8((vint8m8_t)(op0), (int8_t *)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8m8_m((vint8m8_t)(op0), (int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8mf2((vint8mf2_t)(op0), (int8_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8mf2_m((vint8mf2_t)(op0), (int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8mf4((vint8mf4_t)(op0), (int8_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8mf4_m((vint8mf4_t)(op0), (int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_i8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_i8mf8((vint8mf8_t)(op0), (int8_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_i8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_i8mf8_m((vint8mf8_t)(op0), (int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m1(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m1((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m2((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m4((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle16ff_v_i16m8(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16m8((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle16ff_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16mf2((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle16ff_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_i16mf4((const int16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m1(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m1((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m2((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m4((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle16ff_v_u16m8(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16m8((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle16ff_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16mf2((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle16ff_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vle16ff_v_u16mf4((const uint16_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle16ff_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle16ff_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m1((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m2((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m4((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_i32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32m8((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_i32mf2((const int32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m1((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m2((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m4((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_u32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32m8((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_u32mf2((const uint32_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8m1((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8m1_m((vuint8m1_t)(op0), (uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8m2((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8m2_m((vuint8m2_t)(op0), (uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8m4((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8m4_m((vuint8m4_t)(op0), (uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8m8((vuint8m8_t)(op0), (uint8_t *)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8m8_m((vuint8m8_t)(op0), (uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8mf2((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8mf2_m((vuint8mf2_t)(op0), (uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8mf4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8mf4((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8mf4_m((vuint8mf4_t)(op0), (uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_u8mf8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_u8mf8((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_u8mf8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_u8mf8_m((vuint8mf8_t)(op0), (uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m1((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m2((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m4((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_i64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_i64m8((const int64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m1((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m2((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m4((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_u64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_u64m8((const uint64_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vadd_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vadd_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vadd_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vadd_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vadd_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vadd_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vadd_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vadd_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vadd_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vadd_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vadd_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vadd_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vadd_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vadd_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vadd_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vadd_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vadd_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vadd_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vadd_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vadd_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vadd_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vadd_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vadd_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadd_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vadd_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vadd_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vadd_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vadd_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vadd_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vadd_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vadd_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vadd_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsub_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsub_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsub_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsub_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsub_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsub_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsub_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsub_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsub_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsub_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsub_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsub_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsub_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsub_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsub_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsub_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsub_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsub_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsub_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsub_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsub_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsub_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsub_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsub_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsub_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsub_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsub_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16_v_i16m1(op0, op1) \
__builtin_rvv_vle16_v_i16m1((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle16_v_i16m2(op0, op1) \
__builtin_rvv_vle16_v_i16m2((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle16_v_i16m4(op0, op1) \
__builtin_rvv_vle16_v_i16m4((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle16_v_i16m8(op0, op1) \
__builtin_rvv_vle16_v_i16m8((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle16_v_i16mf2(op0, op1) \
__builtin_rvv_vle16_v_i16mf2((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle16_v_i16mf4(op0, op1) \
__builtin_rvv_vle16_v_i16mf4((const int16_t *)(op0), (size_t)(op1))
#define vle16_v_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vrsub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vrsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrsub_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vrsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrsub_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrsub_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vrsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrsub_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vrsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vrsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrsub_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16mf4((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16mf2((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16m1((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16m2((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16m4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u16m8((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwaddu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u32mf2((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u32m1((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u32m2((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u32m4((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u32m8((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u64m1((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u64m2((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u64m4((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vwaddu_vx_u64m8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_vx_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16mf4((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16mf2((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16m1((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16m2((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16m4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u16m8((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwsubu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsubu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u32mf2((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwsubu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u32m1((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u32m2((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwsubu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u32m4((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u32m8((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwsubu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u64m1((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u64m2((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwsubu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u64m4((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwsubu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vv_u64m8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwsubu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16mf4((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16mf2((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16m1((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16m2((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16m4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u16m8((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsubu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u32mf2((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u32m1((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u32m2((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u32m4((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u32m8((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u64m1((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u64m2((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u64m4((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vwsubu_vx_u64m8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_vx_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16mf4((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16mf2((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16m1((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16m2((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16m4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i16m8((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i32mf2((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i32m1((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i32m2((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i32m4((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i32m8((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i64m1((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i64m2((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i64m4((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwadd_vv_i64m8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16mf4((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16mf2((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16m1((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16m2((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16m4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i16m8((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i32mf2((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i32m1((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i32m2((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i32m4((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i32m8((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i64m1((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i64m2((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i64m4((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwadd_vx_i64m8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16mf4((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwsub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16mf2((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwsub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16m1((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwsub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16m2((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwsub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16m4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwsub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i16m8((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwsub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i32mf2((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwsub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i32m1((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwsub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i32m2((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwsub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i32m4((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwsub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i32m8((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwsub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i64m1((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwsub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i64m2((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwsub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i64m4((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwsub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwsub_vv_i64m8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwsub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16mf4((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16mf2((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16m1((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16m2((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16m4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i16m8((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i32mf2((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i32m1((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i32m2((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i32m4((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i32m8((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i64m1((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i64m2((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i64m4((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwsub_vx_i64m8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16mf4((vuint16mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16mf2((vuint16mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16m1((vuint16m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16m2((vuint16m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16m4((vuint16m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_wx_u16m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u16m8((vuint16m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwaddu_wx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwaddu_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u32mf2((vuint32mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u32m1((vuint32m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u32m2((vuint32m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u32m4((vuint32m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwaddu_wx_u32m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u32m8((vuint32m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwaddu_wx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwaddu_wx_u64m1(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u64m1((vuint64m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_wx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwaddu_wx_u64m2(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u64m2((vuint64m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_wx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwaddu_wx_u64m4(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u64m4((vuint64m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_wx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwaddu_wx_u64m8(op0, op1, op2) \
__builtin_rvv_vwaddu_wx_u64m8((vuint64m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwaddu_wx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwaddu_wx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle16_v_u16m1(op0, op1) \
__builtin_rvv_vle16_v_u16m1((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle16_v_u16m2(op0, op1) \
__builtin_rvv_vle16_v_u16m2((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle16_v_u16m4(op0, op1) \
__builtin_rvv_vle16_v_u16m4((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle16_v_u16m8(op0, op1) \
__builtin_rvv_vle16_v_u16m8((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle16_v_u16mf2(op0, op1) \
__builtin_rvv_vle16_v_u16mf2((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle16_v_u16mf4(op0, op1) \
__builtin_rvv_vle16_v_u16mf4((const uint16_t *)(op0), (size_t)(op1))
#define vle16_v_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vwsubu_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16mf4((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16mf2((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16m1((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16m2((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16m4((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_wv_u16m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u16m8((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwsubu_wv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsubu_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u32mf2((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwsubu_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u32m2((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwsubu_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u32m4((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_wv_u32m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u32m8((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwsubu_wv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_wv_u64m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u64m1((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wv_u64m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u64m2((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwsubu_wv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wv_u64m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u64m4((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwsubu_wv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wv_u64m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wv_u64m8((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwsubu_wv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16mf4((vuint16mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16mf2((vuint16mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16m1((vuint16m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16m2((vuint16m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16m4((vuint16m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_wx_u16m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u16m8((vuint16m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwsubu_wx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsubu_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u32mf2((vuint32mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u32m1((vuint32m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u32m2((vuint32m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u32m4((vuint32m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsubu_wx_u32m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u32m8((vuint32m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwsubu_wx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsubu_wx_u64m1(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u64m1((vuint64m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_wx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsubu_wx_u64m2(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u64m2((vuint64m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_wx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsubu_wx_u64m4(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u64m4((vuint64m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_wx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsubu_wx_u64m8(op0, op1, op2) \
__builtin_rvv_vwsubu_wx_u64m8((vuint64m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwsubu_wx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsubu_wx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwadd_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwadd_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwadd_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwadd_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwadd_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_wv_i16m8(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwadd_wv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwadd_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwadd_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwadd_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwadd_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwadd_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wv_i32m8(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwadd_wv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_wv_i64m1(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwadd_wv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wv_i64m2(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwadd_wv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wv_i64m4(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwadd_wv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wv_i64m8(op0, op1, op2) \
__builtin_rvv_vwadd_wv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwadd_wv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_wx_i16m8(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwadd_wx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwadd_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwadd_wx_i32m8(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwadd_wx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwadd_wx_i64m1(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_wx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwadd_wx_i64m2(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_wx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwadd_wx_i64m4(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_wx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwadd_wx_i64m8(op0, op1, op2) \
__builtin_rvv_vwadd_wx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwadd_wx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwadd_wx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwsub_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwsub_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwsub_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwsub_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwsub_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_wv_i16m8(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwsub_wv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsub_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwsub_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwsub_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwsub_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwsub_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wv_i32m8(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwsub_wv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_wv_i64m1(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwsub_wv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wv_i64m2(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwsub_wv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wv_i64m4(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwsub_wv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wv_i64m8(op0, op1, op2) \
__builtin_rvv_vwsub_wv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwsub_wv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_wx_i16m8(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwsub_wx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwsub_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwsub_wx_i32m8(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwsub_wx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwsub_wx_i64m1(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_wx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwsub_wx_i64m2(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_wx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwsub_wx_i64m4(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_wx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwsub_wx_i64m8(op0, op1, op2) \
__builtin_rvv_vwsub_wx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwsub_wx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwsub_wx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vadc_vvm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vvm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vvm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vvm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vvm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vvm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vadc_vxm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vadc_vxm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vadc_vxm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vadc_vxm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vadc_vxm_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_i32m1(op0, op1) \
__builtin_rvv_vle32_v_i32m1((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_i32m2(op0, op1) \
__builtin_rvv_vle32_v_i32m2((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_i32m4(op0, op1) \
__builtin_rvv_vle32_v_i32m4((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_i32m8(op0, op1) \
__builtin_rvv_vle32_v_i32m8((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_i32mf2(op0, op1) \
__builtin_rvv_vle32_v_i32mf2((const int32_t *)(op0), (size_t)(op1))
#define vle32_v_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vvm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vvm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vvm_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmadc_vxm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmadc_vxm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmadc_vxm_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmadc_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmadc_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmadc_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmadc_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmadc_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmadc_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmadc_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsbc_vvm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_u32m1(op0, op1) \
__builtin_rvv_vle32_v_u32m1((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_u32m2(op0, op1) \
__builtin_rvv_vle32_v_u32m2((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_u32m4(op0, op1) \
__builtin_rvv_vle32_v_u32m4((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_u32m8(op0, op1) \
__builtin_rvv_vle32_v_u32m8((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_u32mf2(op0, op1) \
__builtin_rvv_vle32_v_u32mf2((const uint32_t *)(op0), (size_t)(op1))
#define vle32_v_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vvm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vvm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vvm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsbc_vxm_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsbc_vxm_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vsbc_vxm_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_i64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vvm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vvm_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m1_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m2_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m4_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8m8_b1(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf4_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u8mf8_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m1_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m2_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m4_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16m8_b2(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16mf2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u16mf4_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m1_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m2_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m4_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32m8_b4(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u32mf2_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m1_b64(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m2_b32(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m4_b16(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbc_vxm_u64m8_b8(op0, op1, op2, op3) \
__builtin_rvv_vmsbc_vxm_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbc_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsbc_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsbc_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsbc_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsbc_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vand_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vand_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vand_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vand_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vand_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vand_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vand_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vand_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vand_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vand_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vand_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vand_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vand_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vand_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vand_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vand_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vand_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vand_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vand_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vand_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vand_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vand_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vand_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vand_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vand_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vand_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vand_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vand_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vand_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vand_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vand_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vand_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vand_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vand_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vand_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vand_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vand_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vand_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vand_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vand_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vand_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vand_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vand_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vand_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vand_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vand_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vand_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vand_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vand_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vand_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vand_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vand_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vand_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vand_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vand_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vand_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vand_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vand_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vand_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vand_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vand_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vand_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vand_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vand_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vand_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vand_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vand_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vand_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vand_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vand_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vand_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vand_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vxor_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vxor_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vxor_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vxor_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vxor_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vxor_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vxor_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vxor_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vxor_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vxor_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vxor_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vxor_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vxor_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vxor_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vxor_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vxor_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vxor_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vxor_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vxor_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vxor_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vxor_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vxor_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vxor_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vxor_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vxor_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vxor_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vxor_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vxor_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vxor_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vxor_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vxor_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vxor_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vxor_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vxor_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vxor_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vxor_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vxor_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vxor_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vxor_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vxor_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vxor_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vxor_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vxor_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vxor_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vxor_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vxor_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vxor_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vxor_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vxor_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vxor_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vxor_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vxor_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vxor_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vxor_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vxor_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vor_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vor_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vor_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vor_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vor_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vor_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vor_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vor_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vor_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vor_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vor_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vor_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vor_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vor_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vor_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vor_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vor_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vor_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vor_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vor_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vor_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vor_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vor_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vor_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vor_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vor_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vor_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vor_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vor_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vor_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64_v_i64m1(op0, op1) \
__builtin_rvv_vle64_v_i64m1((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_i64m2(op0, op1) \
__builtin_rvv_vle64_v_i64m2((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_i64m4(op0, op1) \
__builtin_rvv_vle64_v_i64m4((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_i64m8(op0, op1) \
__builtin_rvv_vle64_v_i64m8((const int64_t *)(op0), (size_t)(op1))
#define vle64_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vor_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vor_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vor_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vor_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vor_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vor_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vor_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vor_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vor_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vor_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vor_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vor_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vor_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vor_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vor_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vor_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vor_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vor_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vor_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vor_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vor_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vor_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vor_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vor_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vor_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vor_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vor_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vor_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vor_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vor_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vor_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vor_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vor_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vor_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vor_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vor_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vor_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vor_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vor_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vor_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vor_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vor_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vor_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsll_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsll_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsll_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsll_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsll_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsll_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsll_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsll_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsll_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsll_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsll_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsll_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsll_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsll_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsll_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsll_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsll_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsll_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsll_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsll_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsll_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsll_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsll_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsll_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsll_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsll_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsll_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsll_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsll_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsll_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsll_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsll_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsll_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsll_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsll_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsll_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsll_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsll_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsll_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsll_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsll_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsll_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsll_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsll_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsll_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsll_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsll_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsll_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsrl_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsrl_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsrl_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsrl_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsrl_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsrl_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsrl_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsrl_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsrl_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsrl_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsrl_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsrl_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsra_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsra_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsra_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsra_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsra_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsra_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsra_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsra_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsra_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsra_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsra_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsra_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsra_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsra_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsra_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsra_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsra_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsra_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsra_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsra_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsra_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsra_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsra_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsra_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsra_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsra_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsra_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vsra_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsra_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64_v_u64m1(op0, op1) \
__builtin_rvv_vle64_v_u64m1((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_u64m2(op0, op1) \
__builtin_rvv_vle64_v_u64m2((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_u64m4(op0, op1) \
__builtin_rvv_vle64_v_u64m4((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_u64m8(op0, op1) \
__builtin_rvv_vle64_v_u64m8((const uint64_t *)(op0), (size_t)(op1))
#define vle64_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vnsrl_wv_u8m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m1((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m2((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8m4((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf2((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf4((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u8mf8(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u8mf8((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnsrl_wv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m1((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m2((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16m4((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16mf2((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u16mf4((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m1((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m2((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32m4((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wv_u32mf2((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnsrl_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m1((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m2((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8m4((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf2((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf4((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u8mf8(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u8mf8((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m1((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m2((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16m4((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16mf2((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u16mf4((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m1((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m2((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32m4((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsrl_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vnsrl_wx_u32mf2((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsrl_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsrl_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m1((vint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m2((vint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wv_i8m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8m4((vint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf2((vint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf4((vint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i8mf8(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i8mf8((vint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnsra_wv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m1((vint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m2((vint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16m4((vint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16mf2((vint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i16mf4((vint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnsra_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m1((vint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m2((vint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32m4((vint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnsra_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wv_i32mf2((vint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnsra_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wv_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m1((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m2((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wx_i8m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8m4((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf2((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf4((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i8mf8(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i8mf8((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m1((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m2((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16m4((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnsra_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16mf2((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i16mf4((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m1((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m2((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnsra_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32m4((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnsra_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vnsra_wx_i32mf2((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnsra_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnsra_wx_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmseq_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmseq_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmseq_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmseq_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmseq_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmseq_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmseq_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmseq_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmseq_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmseq_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmseq_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmseq_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmseq_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmseq_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmseq_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmseq_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmseq_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmseq_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmseq_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmseq_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsne_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsne_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsne_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsne_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsne_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsne_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8_v_i8m1(op0, op1) \
__builtin_rvv_vle8_v_i8m1((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle8_v_i8m2(op0, op1) \
__builtin_rvv_vle8_v_i8m2((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle8_v_i8m4(op0, op1) \
__builtin_rvv_vle8_v_i8m4((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle8_v_i8m8(op0, op1) \
__builtin_rvv_vle8_v_i8m8((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vle8_v_i8mf2(op0, op1) \
__builtin_rvv_vle8_v_i8mf2((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle8_v_i8mf4(op0, op1) \
__builtin_rvv_vle8_v_i8mf4((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle8_v_i8mf8(op0, op1) \
__builtin_rvv_vle8_v_i8mf8((const int8_t *)(op0), (size_t)(op1))
#define vle8_v_i8mf8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsne_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsne_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsne_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsne_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsne_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsne_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsne_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsne_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsne_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsne_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsne_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsne_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsne_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsne_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsne_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsltu_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsltu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsltu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsltu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsltu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsltu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsltu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsltu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsltu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmslt_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmslt_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmslt_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmslt_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmslt_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmslt_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmslt_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmslt_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmslt_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmslt_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmslt_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmslt_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmslt_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmslt_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m1_b8((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m2_b4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m4_b2((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8m8_b1((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf2_b16((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf4_b32((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u8mf8_b64((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m1_b16((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m2_b8((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m4_b4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16m8_b2((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16mf2_b32((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u16mf4_b64((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m1_b32((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m2_b16((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m4_b8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32m8_b4((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vv_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u32mf2_b64((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m1_b64((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m2_b32((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m4_b16((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vv_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vv_u64m8_b8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmsleu_vv_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vv_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsleu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsleu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsleu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsleu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsleu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsleu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsleu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsleu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m1_b8((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m2_b4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m4_b2((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vv_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8m8_b1((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf2_b16((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf4_b32((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i8mf8_b64((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmsle_vv_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m1_b16((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m2_b8((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m4_b4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16m8_b2((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vv_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16mf2_b32((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i16mf4_b64((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmsle_vv_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m1_b32((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m2_b16((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m4_b8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vv_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32m8_b4((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vv_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i32mf2_b64((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmsle_vv_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m1_b64((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m2_b32((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m4_b16((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vv_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vv_i64m8_b8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmsle_vv_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vv_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsle_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsle_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsle_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsle_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsle_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsle_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsle_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsle_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsle_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsle_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse16_v_i16m1(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse16_v_i16m2(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse16_v_i16m4(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse16_v_i16m8(op1, op0, op2) \
__builtin_rvv_vse16_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse16_v_i16mf2(op1, op0, op2) \
__builtin_rvv_vse16_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse16_v_i16mf4(op1, op0, op2) \
__builtin_rvv_vse16_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (size_t)(op2))
#define vse16_v_i16mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsgtu_vx_u8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m1_b8((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m1_b8_m((vbool8_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m2_b4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m2_b4_m((vbool4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m4_b2((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m4_b2_m((vbool2_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8m8_b1((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8m8_b1_m((vbool1_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf2_b16((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf2_b16_m((vbool16_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf4_b32((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf4_b32_m((vbool32_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u8mf8_b64((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u8mf8_b64_m((vbool64_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m1_b16((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m1_b16_m((vbool16_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m2_b8((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m2_b8_m((vbool8_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m4_b4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m4_b4_m((vbool4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16m8_b2((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16m8_b2_m((vbool2_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16mf2_b32((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16mf2_b32_m((vbool32_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u16mf4_b64((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u16mf4_b64_m((vbool64_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m1_b32((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m1_b32_m((vbool32_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m2_b16((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m2_b16_m((vbool16_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m4_b8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m4_b8_m((vbool8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32m8_b4((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32m8_b4_m((vbool4_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u32mf2_b64((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u32mf2_b64_m((vbool64_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m1_b64((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m1_b64_m((vbool64_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m2_b32((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m2_b32_m((vbool32_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m4_b16((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m4_b16_m((vbool16_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgtu_vx_u64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsgtu_vx_u64m8_b8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmsgtu_vx_u64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgtu_vx_u64m8_b8_m((vbool8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m1_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m1_b8((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m1_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m1_b8_m((vbool8_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m2_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m2_b4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m2_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m2_b4_m((vbool4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m4_b2(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m4_b2((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m4_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m4_b2_m((vbool2_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8m8_b1(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8m8_b1((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8m8_b1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8m8_b1_m((vbool1_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf2_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf2_b16((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf2_b16_m((vbool16_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf4_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf4_b32((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf4_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf4_b32_m((vbool32_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i8mf8_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i8mf8_b64((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmsgt_vx_i8mf8_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i8mf8_b64_m((vbool64_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m1_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m1_b16((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m1_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m1_b16_m((vbool16_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m2_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m2_b8((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m2_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m2_b8_m((vbool8_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m4_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m4_b4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m4_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m4_b4_m((vbool4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16m8_b2(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16m8_b2((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16m8_b2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16m8_b2_m((vbool2_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16mf2_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16mf2_b32((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16mf2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16mf2_b32_m((vbool32_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i16mf4_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i16mf4_b64((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmsgt_vx_i16mf4_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i16mf4_b64_m((vbool64_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m1_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m1_b32((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m1_b32_m((vbool32_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m2_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m2_b16((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m2_b16_m((vbool16_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m4_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m4_b8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m4_b8_m((vbool8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32m8_b4(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32m8_b4((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32m8_b4_m((vbool4_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmsgt_vx_i32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i32mf2_b64((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmsgt_vx_i32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i32mf2_b64_m((vbool64_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m1_b64(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m1_b64((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m1_b64_m((vbool64_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m2_b32(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m2_b32((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m2_b32_m((vbool32_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m4_b16(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m4_b16((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m4_b16_m((vbool16_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmsgt_vx_i64m8_b8(op0, op1, op2) \
__builtin_rvv_vmsgt_vx_i64m8_b8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmsgt_vx_i64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmsgt_vx_i64m8_b8_m((vbool8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vminu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vminu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vminu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vminu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vminu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vminu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vminu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vminu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vminu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vminu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vminu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vminu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vminu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vminu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vminu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vminu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vminu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vminu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vminu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vminu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vminu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vminu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vminu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vminu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vminu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vminu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vminu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vminu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vminu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vminu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vminu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vminu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmin_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmin_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmin_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmin_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmin_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmin_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmin_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmin_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmin_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmin_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmin_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmin_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmin_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmin_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmin_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmin_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmin_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmin_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmin_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmin_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmin_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmin_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmin_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmin_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmin_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmin_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmin_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmin_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmin_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmin_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmin_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmin_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmaxu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmaxu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmaxu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmaxu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmaxu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmaxu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmaxu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmaxu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmaxu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmax_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmax_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmax_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmax_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmax_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmax_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmax_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmax_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmax_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmax_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmax_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmax_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmax_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmax_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmax_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmax_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmax_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmax_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmax_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmax_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmax_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmax_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmax_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmax_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmax_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmax_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmax_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmax_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmax_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmax_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmax_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmax_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse16_v_u16m1(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse16_v_u16m2(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse16_v_u16m4(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse16_v_u16m8(op1, op0, op2) \
__builtin_rvv_vse16_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vse16_v_u16mf2(op1, op0, op2) \
__builtin_rvv_vse16_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse16_v_u16mf4(op1, op0, op2) \
__builtin_rvv_vse16_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (size_t)(op2))
#define vse16_v_u16mf4_m(op2, op1, op0, op3) \
__builtin_rvv_vse16_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmul_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmul_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmul_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmul_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmul_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmul_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmul_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmul_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmul_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmul_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmul_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmul_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmul_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmul_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmul_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmul_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmul_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmul_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmul_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmul_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmul_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmul_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmul_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmul_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmul_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmul_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmul_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmul_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmul_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmul_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmul_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmul_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmul_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmul_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmul_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmul_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmul_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmul_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmul_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vmulh_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vmulh_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vmulh_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmulh_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vmulh_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vmulh_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulh_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vmulh_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulh_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulh_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vmulh_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulh_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmulh_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vmulh_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulh_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmulhu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vmulhu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vmulhsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m1((vint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m2((vint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m4((vint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8m8((vint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf2((vint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf4((vint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i8mf8((vint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m1((vint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m2((vint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m4((vint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16m8((vint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16mf2((vint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i16mf4((vint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m1((vint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m2((vint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m4((vint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32m8((vint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i32mf2((vint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m1((vint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m2((vint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m4((vint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmulhsu_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vmulhsu_vx_i64m8((vint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vmulhsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmulhsu_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse32_v_i32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_i32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_i32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_i32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_i32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (size_t)(op2))
#define vse32_v_i32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vdivu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vdivu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vdivu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vdivu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vdivu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vdivu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vdivu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdivu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vdivu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdivu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdivu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vdivu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdivu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vdivu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vdivu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdivu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vdiv_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vdiv_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vdiv_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vdiv_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vdiv_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vdiv_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vdiv_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vdiv_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vdiv_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vdiv_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vdiv_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vdiv_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vdiv_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vdiv_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vdiv_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vremu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vremu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vremu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vremu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vremu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vremu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vremu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vremu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vremu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vremu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vremu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vremu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vremu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vremu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vremu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vremu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vremu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vremu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vremu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vremu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vremu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vremu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vremu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vremu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vremu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vremu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vremu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vremu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vremu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vremu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vremu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vremu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vrem_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vrem_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vrem_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vrem_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vrem_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vrem_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vrem_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vrem_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vrem_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vrem_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vrem_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vrem_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vrem_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vrem_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vrem_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vrem_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vrem_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vrem_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vrem_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vrem_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vrem_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrem_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vrem_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrem_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrem_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vrem_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrem_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrem_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrem_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vrem_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vrem_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrem_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16mf4((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vwmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16mf2((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vwmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m1((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m2((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m4((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i16m8((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32mf2((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vwmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m1((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m2((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m4((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i32m8((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m1((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m2((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m4((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwmul_vv_i64m8((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vwmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16mf4((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16mf2((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m1((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m2((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m4((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i16m8((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vwmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32mf2((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m1((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m2((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m4((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i32m8((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vwmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m1((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m2((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m4((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwmul_vx_i64m8((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vwmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmul_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse32_v_u32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_u32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_u32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_u32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_u32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (size_t)(op2))
#define vse32_v_u32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vwmulu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16mf4((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16mf2((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m1((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m2((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m4((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u16m8((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32mf2((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m1((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m2((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m4((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u32m8((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m1((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m2((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m4((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vv_u64m8((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwmulu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16mf4((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16mf2((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m1((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m2((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m4((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u16m8((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32mf2((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m1((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m2((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m4((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u32m8((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m1((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m2((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m4((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vwmulu_vx_u64m8((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulu_vx_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16mf4((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16mf2((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m1((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m2((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m4((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i16m8((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32mf2((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m1((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m2((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m4((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i32m8((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m1((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m2((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m4((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vv_i64m8((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vwmulsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16mf4((vint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16mf2((vint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m1((vint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m2((vint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m4((vint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i16m8((vint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32mf2((vint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m1((vint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m2((vint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m4((vint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i32m8((vint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m1((vint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m2((vint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m4((vint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmulsu_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vwmulsu_vx_i64m8((vint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vwmulsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmulsu_vx_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmacc_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmacc_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmacc_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmacc_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmacc_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmacc_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmacc_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmacc_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmacc_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmacc_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmacc_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmacc_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmacc_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsac_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsac_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsac_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsac_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsac_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vmadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmadd_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vmadd_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vmadd_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vmadd_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmadd_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmadd_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vmadd_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmadd_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vmadd_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vmadd_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmadd_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m1_m((vint8m1_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m2_m((vint8m2_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m4_m((vint8m4_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8m8_m((vint8m8_t)(op0), (int8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf2_m((vint8mf2_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf4_m((vint8mf4_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i8mf8_m((vint8mf8_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m1_m((vint16m1_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m2_m((vint16m2_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m4_m((vint16m4_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16m8_m((vint16m8_t)(op0), (int16_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16mf2_m((vint16mf2_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i16mf4_m((vint16mf4_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m1_m((vint32m1_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m2_m((vint32m2_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m4_m((vint32m4_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32m8_m((vint32m8_t)(op0), (int32_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i32mf2_m((vint32mf2_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m1_m((vint64m1_t)(op0), (int64_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m2_m((vint64m2_t)(op0), (int64_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m4_m((vint64m4_t)(op0), (int64_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_i64m8_m((vint64m8_t)(op0), (int64_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m1_m((vuint8m1_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m2_m((vuint8m2_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m4_m((vuint8m4_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8m8_m((vuint8m8_t)(op0), (uint8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf2_m((vuint8mf2_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf4_m((vuint8mf4_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u8mf8_m((vuint8mf8_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m1_m((vuint16m1_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m2_m((vuint16m2_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m4_m((vuint16m4_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16m8_m((vuint16m8_t)(op0), (uint16_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16mf2_m((vuint16mf2_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u16mf4_m((vuint16mf4_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m1_m((vuint32m1_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m2_m((vuint32m2_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m4_m((vuint32m4_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32m8_m((vuint32m8_t)(op0), (uint32_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnmsub_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u32mf2_m((vuint32mf2_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m1_m((vuint64m1_t)(op0), (uint64_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m2_m((vuint64m2_t)(op0), (uint64_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m4_m((vuint64m4_t)(op0), (uint64_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnmsub_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vnmsub_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vnmsub_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnmsub_vx_u64m8_m((vuint64m8_t)(op0), (uint64_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vse64_v_i64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_i64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_i64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_i64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (size_t)(op2))
#define vse64_v_i64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16mf4((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16mf2((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m1((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m2((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m4((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u16m8((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32mf2((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m2((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m4((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u32m8((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m1((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m2((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m4((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vv_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vv_u64m8((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vv_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16mf4((vuint16mf4_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16mf4_m((vuint16mf4_t)(op0), (uint8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16mf2((vuint16mf2_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16mf2_m((vuint16mf2_t)(op0), (uint8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m1((vuint16m1_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m1_m((vuint16m1_t)(op0), (uint8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m2((vuint16m2_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m2_m((vuint16m2_t)(op0), (uint8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m4((vuint16m4_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m4_m((vuint16m4_t)(op0), (uint8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u16m8((vuint16m8_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u16m8_m((vuint16m8_t)(op0), (uint8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32mf2((vuint32mf2_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32mf2_m((vuint32mf2_t)(op0), (uint16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m1((vuint32m1_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m1_m((vuint32m1_t)(op0), (uint16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m2((vuint32m2_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m2_m((vuint32m2_t)(op0), (uint16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m4((vuint32m4_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m4_m((vuint32m4_t)(op0), (uint16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u32m8((vuint32m8_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u32m8_m((vuint32m8_t)(op0), (uint16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m1((vuint64m1_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m1_m((vuint64m1_t)(op0), (uint32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m2((vuint64m2_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m2_m((vuint64m2_t)(op0), (uint32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m4((vuint64m4_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m4_m((vuint64m4_t)(op0), (uint32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccu_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccu_vx_u64m8((vuint64m8_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccu_vx_u64m8_m((vuint64m8_t)(op0), (uint32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmacc_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16mf4_m((vint16mf4_t)(op0), (int8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16mf2_m((vint16mf2_t)(op0), (int8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m1_m((vint16m1_t)(op0), (int8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m2_m((vint16m2_t)(op0), (int8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m4_m((vint16m4_t)(op0), (int8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i16m8_m((vint16m8_t)(op0), (int8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32mf2_m((vint32mf2_t)(op0), (int16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m1_m((vint32m1_t)(op0), (int16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m2_m((vint32m2_t)(op0), (int16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m4_m((vint32m4_t)(op0), (int16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmacc_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i32m8_m((vint32m8_t)(op0), (int16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m1_m((vint64m1_t)(op0), (int32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m2_m((vint64m2_t)(op0), (int32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m4_m((vint64m4_t)(op0), (int32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmacc_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmacc_vx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmacc_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmacc_vx_i64m8_m((vint64m8_t)(op0), (int32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16mf4((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16mf2((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m2((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m4((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i16m8((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32mf2((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m2((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m4((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i32m8((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m2((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m4((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vv_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vv_i64m8((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vv_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16mf4((vint16mf4_t)(op0), (int8_t)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16mf4_m((vint16mf4_t)(op0), (int8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16mf2((vint16mf2_t)(op0), (int8_t)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16mf2_m((vint16mf2_t)(op0), (int8_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m1((vint16m1_t)(op0), (int8_t)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m1_m((vint16m1_t)(op0), (int8_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m2((vint16m2_t)(op0), (int8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m2_m((vint16m2_t)(op0), (int8_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m4((vint16m4_t)(op0), (int8_t)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m4_m((vint16m4_t)(op0), (int8_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i16m8((vint16m8_t)(op0), (int8_t)(op1), (vuint8m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i16m8_m((vint16m8_t)(op0), (int8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32mf2((vint32mf2_t)(op0), (int16_t)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32mf2_m((vint32mf2_t)(op0), (int16_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m1((vint32m1_t)(op0), (int16_t)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m1_m((vint32m1_t)(op0), (int16_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m2((vint32m2_t)(op0), (int16_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m2_m((vint32m2_t)(op0), (int16_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m4((vint32m4_t)(op0), (int16_t)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m4_m((vint32m4_t)(op0), (int16_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i32m8((vint32m8_t)(op0), (int16_t)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i32m8_m((vint32m8_t)(op0), (int16_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m1((vint64m1_t)(op0), (int32_t)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m1_m((vint64m1_t)(op0), (int32_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m2((vint64m2_t)(op0), (int32_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m2_m((vint64m2_t)(op0), (int32_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m4((vint64m4_t)(op0), (int32_t)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m4_m((vint64m4_t)(op0), (int32_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccsu_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccsu_vx_i64m8((vint64m8_t)(op0), (int32_t)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vwmaccsu_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccsu_vx_i64m8_m((vint64m8_t)(op0), (int32_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16mf4((vint16mf4_t)(op0), (uint8_t)(op1), (vint8mf8_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16mf4_m((vint16mf4_t)(op0), (uint8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16mf2((vint16mf2_t)(op0), (uint8_t)(op1), (vint8mf4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16mf2_m((vint16mf2_t)(op0), (uint8_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m1((vint16m1_t)(op0), (uint8_t)(op1), (vint8mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m1_m((vint16m1_t)(op0), (uint8_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m2((vint16m2_t)(op0), (uint8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m2_m((vint16m2_t)(op0), (uint8_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m4((vint16m4_t)(op0), (uint8_t)(op1), (vint8m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m4_m((vint16m4_t)(op0), (uint8_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i16m8((vint16m8_t)(op0), (uint8_t)(op1), (vint8m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i16m8_m((vint16m8_t)(op0), (uint8_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32mf2((vint32mf2_t)(op0), (uint16_t)(op1), (vint16mf4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32mf2_m((vint32mf2_t)(op0), (uint16_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m1((vint32m1_t)(op0), (uint16_t)(op1), (vint16mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m1_m((vint32m1_t)(op0), (uint16_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m2((vint32m2_t)(op0), (uint16_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m2_m((vint32m2_t)(op0), (uint16_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m4((vint32m4_t)(op0), (uint16_t)(op1), (vint16m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m4_m((vint32m4_t)(op0), (uint16_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i32m8((vint32m8_t)(op0), (uint16_t)(op1), (vint16m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i32m8_m((vint32m8_t)(op0), (uint16_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m1((vint64m1_t)(op0), (uint32_t)(op1), (vint32mf2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m1_m((vint64m1_t)(op0), (uint32_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m2((vint64m2_t)(op0), (uint32_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m2_m((vint64m2_t)(op0), (uint32_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m4((vint64m4_t)(op0), (uint32_t)(op1), (vint32m2_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m4_m((vint64m4_t)(op0), (uint32_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwmaccus_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vwmaccus_vx_i64m8((vint64m8_t)(op0), (uint32_t)(op1), (vint32m4_t)(op2), (size_t)(op3))
#define vwmaccus_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwmaccus_vx_i64m8_m((vint64m8_t)(op0), (uint32_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmerge_vvm_i8m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_i8mf8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_i16mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_i32m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_i32m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_i32m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_i32m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_i32mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_i64m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_i64m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_i64m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_i64m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8m1((vint8m1_t)(op0), (int8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8m2((vint8m2_t)(op0), (int8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8m4((vint8m4_t)(op0), (int8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8m8((vint8m8_t)(op0), (int8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_i8mf8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16m1((vint16m1_t)(op0), (int16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16m2((vint16m2_t)(op0), (int16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16m4((vint16m4_t)(op0), (int16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16m8((vint16m8_t)(op0), (int16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_i16mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_i32m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i32m1((vint32m1_t)(op0), (int32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_i32m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i32m2((vint32m2_t)(op0), (int32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_i32m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i32m4((vint32m4_t)(op0), (int32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_i32m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i32m8((vint32m8_t)(op0), (int32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_i32mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_i64m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i64m1((vint64m1_t)(op0), (int64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_i64m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i64m2((vint64m2_t)(op0), (int64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_i64m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i64m4((vint64m4_t)(op0), (int64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_i64m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_i64m8((vint64m8_t)(op0), (int64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_u8mf8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_u16mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_u32m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_u32m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_u32m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_u32m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_u32mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_u64m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_u64m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_u64m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_u64m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse64_v_u64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_u64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_u64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_u64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (size_t)(op2))
#define vse64_v_u64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_u8mf8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_u16mf4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_u32m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_u32m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_u32m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vxm_u32m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vxm_u32mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_u64m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vxm_u64m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vxm_u64m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vxm_u64m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vxm_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsaddu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vsaddu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vsaddu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vsaddu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsaddu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vsaddu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsaddu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vsaddu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vsaddu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsaddu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssubu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssubu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssubu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vssubu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssubu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vssubu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssubu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vssubu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssubu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssubu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vssubu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssubu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vssubu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vssubu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssubu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vssub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vssub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vssub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vssub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vssub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vssub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vssub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vssub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vssub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vssub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vssub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vssub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vssub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vssub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vssub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vssub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vssub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vssub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vssub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vssub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vssub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vssub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vssub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vssub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vssub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vaaddu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vaaddu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vaaddu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaaddu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vaaddu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaaddu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vaaddu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vaaddu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaaddu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vaadd_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vaadd_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vaadd_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vaadd_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vaadd_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vaadd_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vaadd_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vaadd_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vaadd_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vaadd_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vaadd_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vaadd_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vaadd_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vaadd_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vaadd_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vasubu_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vasubu_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vasubu_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vasubu_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vasubu_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m1((vuint8m1_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (uint8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m2((vuint8m2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (uint8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m4((vuint8m4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (uint8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8m8((vuint8m8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (uint8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf2((vuint8mf2_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (uint8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf4((vuint8mf4_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (uint8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u8mf8((vuint8mf8_t)(op0), (uint8_t)(op1), (size_t)(op2))
#define vasubu_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (uint8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m1((vuint16m1_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (uint16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m2((vuint16m2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (uint16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m4((vuint16m4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (uint16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16m8((vuint16m8_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (uint16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasubu_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16mf2((vuint16mf2_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (uint16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u16mf4((vuint16mf4_t)(op0), (uint16_t)(op1), (size_t)(op2))
#define vasubu_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (uint16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m1((vuint32m1_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (uint32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m2((vuint32m2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (uint32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m4((vuint32m4_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (uint32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasubu_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32m8((vuint32m8_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (uint32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasubu_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u32mf2((vuint32mf2_t)(op0), (uint32_t)(op1), (size_t)(op2))
#define vasubu_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (uint32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m1((vuint64m1_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (uint64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m2((vuint64m2_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (uint64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m4((vuint64m4_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (uint64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasubu_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vasubu_vx_u64m8((vuint64m8_t)(op0), (uint64_t)(op1), (size_t)(op2))
#define vasubu_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasubu_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (uint64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vasub_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vasub_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vasub_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vasub_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vasub_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vasub_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vasub_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vasub_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vasub_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vasub_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vasub_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vasub_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vasub_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vasub_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vasub_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vasub_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vasub_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vasub_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vasub_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vasub_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vasub_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vasub_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vasub_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vasub_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vasub_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vasub_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vasub_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vasub_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vasub_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vasub_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vasub_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vasub_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2))
#define vsmul_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2))
#define vsmul_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2))
#define vsmul_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vsmul_vv_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2))
#define vsmul_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vsmul_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsmul_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vsmul_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsmul_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsmul_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vsmul_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsmul_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vsmul_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vsmul_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vsmul_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssrl_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssrl_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssrl_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vssrl_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssrl_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse16_v_i16m1(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16m1((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse16_v_i16m2(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16m2((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse16_v_i16m4(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16m4((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse16_v_i16m8(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16m8((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vlse16_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16mf2((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse16_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vlse16_v_i16mf4((const int16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssrl_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssrl_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssrl_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssrl_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vssrl_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssrl_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssrl_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vssra_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vssra_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vssra_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vssra_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vssra_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vssra_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vssra_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vssra_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vssra_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vssra_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vssra_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vssra_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vssra_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vssra_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vssra_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vssra_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vssra_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vssra_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vssra_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vssra_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vssra_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vssra_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vssra_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vssra_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vssra_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vssra_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vssra_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vssra_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vssra_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m1((vuint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m2((vuint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8m4((vuint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf2((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf4((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u8mf8(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u8mf8((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnclipu_wv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m1((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m2((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16m4((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16mf2((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u16mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u16mf4((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m1((vuint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m2((vuint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32m4((vuint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wv_u32mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wv_u32mf2((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnclipu_wv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wv_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m1((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m1_m((vuint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m2((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m2_m((vuint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8m4((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8m4_m((vuint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf2((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf2_m((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf4((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf4_m((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u8mf8(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u8mf8((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u8mf8_m((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m1((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m1_m((vuint16m1_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m2((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m2_m((vuint16m2_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16m4((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16m4_m((vuint16m4_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16mf2((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16mf2_m((vuint16mf2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u16mf4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u16mf4((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u16mf4_m((vuint16mf4_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m1(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m1((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m1_m((vuint32m1_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m2((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m2_m((vuint32m2_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32m4(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32m4((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32m4_m((vuint32m4_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclipu_wx_u32mf2(op0, op1, op2) \
__builtin_rvv_vnclipu_wx_u32mf2((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclipu_wx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclipu_wx_u32mf2_m((vuint32mf2_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m1((vint16m2_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m2((vint16m4_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wv_i8m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8m4((vint16m8_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf2((vint16m1_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf4((vint16mf2_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i8mf8(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i8mf8((vint16mf4_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vnclip_wv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m1((vint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m2((vint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i16m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16m4((vint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wv_i16mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16mf2((vint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i16mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i16mf4((vint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vnclip_wv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m1(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m1((vint64m2_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m2((vint64m4_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wv_i32m4(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32m4((vint64m8_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vnclip_wv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wv_i32mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wv_i32mf2((vint64m1_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vnclip_wv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wv_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m1((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m1_m((vint8m1_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m2((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m2_m((vint8m2_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wx_i8m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8m4((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8m4_m((vint8m4_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf2((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf2_m((vint8mf2_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf4((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf4_m((vint8mf4_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i8mf8(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i8mf8((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i8mf8_m((vint8mf8_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m1((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m1_m((vint16m1_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m2((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m2_m((vint16m2_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i16m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16m4((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16m4_m((vint16m4_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vnclip_wx_i16mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16mf2((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16mf2_m((vint16mf2_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i16mf4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i16mf4((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i16mf4_m((vint16mf4_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m1(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m1((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m1_m((vint32m1_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m2((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m2_m((vint32m2_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vnclip_wx_i32m4(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32m4((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32m4_m((vint32m4_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vnclip_wx_i32mf2(op0, op1, op2) \
__builtin_rvv_vnclip_wx_i32mf2((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vnclip_wx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vnclip_wx_i32mf2_m((vint32mf2_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle8_v_u8m1(op0, op1) \
__builtin_rvv_vle8_v_u8m1((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle8_v_u8m2(op0, op1) \
__builtin_rvv_vle8_v_u8m2((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle8_v_u8m4(op0, op1) \
__builtin_rvv_vle8_v_u8m4((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vle8_v_u8m8(op0, op1) \
__builtin_rvv_vle8_v_u8m8((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vle8_v_u8mf2(op0, op1) \
__builtin_rvv_vle8_v_u8mf2((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle8_v_u8mf4(op0, op1) \
__builtin_rvv_vle8_v_u8mf4((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle8_v_u8mf8(op0, op1) \
__builtin_rvv_vle8_v_u8mf8((const uint8_t *)(op0), (size_t)(op1))
#define vle8_v_u8mf8_m(op2, op0, op1, op3) \
__builtin_rvv_vle8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vlse16_v_u16m1(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16m1((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse16_v_u16m2(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16m2((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse16_v_u16m4(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16m4((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse16_v_u16m8(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16m8((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vlse16_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16mf2((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse16_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vlse16_v_u16mf4((const uint16_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse16_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse32_v_i32m1(op0, op1, op2) \
__builtin_rvv_vlse32_v_i32m1((const int32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse32_v_i32m2(op0, op1, op2) \
__builtin_rvv_vlse32_v_i32m2((const int32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse32_v_i32m4(op0, op1, op2) \
__builtin_rvv_vlse32_v_i32m4((const int32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse32_v_i32m8(op0, op1, op2) \
__builtin_rvv_vlse32_v_i32m8((const int32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse32_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vlse32_v_i32mf2((const int32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse32_v_u32m1(op0, op1, op2) \
__builtin_rvv_vlse32_v_u32m1((const uint32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse32_v_u32m2(op0, op1, op2) \
__builtin_rvv_vlse32_v_u32m2((const uint32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse32_v_u32m4(op0, op1, op2) \
__builtin_rvv_vlse32_v_u32m4((const uint32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse32_v_u32m8(op0, op1, op2) \
__builtin_rvv_vlse32_v_u32m8((const uint32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse32_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vlse32_v_u32mf2((const uint32_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse64_v_i64m1(op0, op1, op2) \
__builtin_rvv_vlse64_v_i64m1((const int64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse64_v_i64m2(op0, op1, op2) \
__builtin_rvv_vlse64_v_i64m2((const int64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse64_v_i64m4(op0, op1, op2) \
__builtin_rvv_vlse64_v_i64m4((const int64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse64_v_i64m8(op0, op1, op2) \
__builtin_rvv_vlse64_v_i64m8((const int64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse64_v_u64m1(op0, op1, op2) \
__builtin_rvv_vlse64_v_u64m1((const uint64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse64_v_u64m2(op0, op1, op2) \
__builtin_rvv_vlse64_v_u64m2((const uint64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse64_v_u64m4(op0, op1, op2) \
__builtin_rvv_vlse64_v_u64m4((const uint64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse64_v_u64m8(op0, op1, op2) \
__builtin_rvv_vlse64_v_u64m8((const uint64_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredsum_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredsum_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredsum_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredsum_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredsum_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredsum_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredsum_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredsum_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredsum_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredsum_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredsum_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredsum_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredsum_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredsum_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmaxu_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmaxu_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredmaxu_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmaxu_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmax_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmax_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmax_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmax_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredmax_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmax_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmax_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmax_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmax_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmax_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmax_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmax_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmax_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmax_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmax_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmax_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmax_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmax_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmax_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmax_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmax_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmax_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmax_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmax_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmax_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredminu_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredminu_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredminu_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredminu_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredminu_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredminu_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredminu_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredminu_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredminu_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredminu_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredminu_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredminu_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredminu_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredminu_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredminu_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredminu_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredminu_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredminu_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredminu_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredminu_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredminu_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredminu_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredminu_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredminu_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredminu_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmin_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmin_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmin_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmin_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredmin_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmin_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmin_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmin_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmin_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmin_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmin_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredmin_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmin_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmin_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmin_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmin_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredmin_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredmin_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmin_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredmin_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredmin_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredmin_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredmin_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredmin_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredmin_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredand_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredand_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredand_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse16_v_i16m1(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16m1((vint16m1_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16m1_m((vint16m1_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse16_v_i16m2(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16m2((vint16m2_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16m2_m((vint16m2_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse16_v_i16m4(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16m4((vint16m4_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16m4_m((vint16m4_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse16_v_i16m8(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16m8((vint16m8_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16m8_m((vint16m8_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsse16_v_i16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16mf2((vint16mf2_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16mf2_m((vint16mf2_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse16_v_i16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_i16mf4((vint16mf4_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_i16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_i16mf4_m((vint16mf4_t)(op0), (int16_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredand_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredand_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredand_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredand_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredand_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredand_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredand_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredand_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredand_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredand_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredand_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredand_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredand_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredand_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredor_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredor_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredor_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredor_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredor_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredor_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredor_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredor_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredor_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredor_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredor_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredor_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredor_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredor_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredor_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredor_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredor_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_i8m1_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8m1_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8m1_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8m1_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_i8m2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8m2_i8m1((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8m2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8m2_i8m1_m((vint8m1_t)(op0), (vint8m2_t)(op1), (vint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_i8m4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8m4_i8m1((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8m4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8m4_i8m1_m((vint8m1_t)(op0), (vint8m4_t)(op1), (vint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredxor_vs_i8m8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8m8_i8m1((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8m8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8m8_i8m1_m((vint8m1_t)(op0), (vint8m8_t)(op1), (vint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredxor_vs_i8mf2_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8mf2_i8m1((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8mf2_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8mf2_i8m1_m((vint8m1_t)(op0), (vint8mf2_t)(op1), (vint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_i8mf4_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8mf4_i8m1((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8mf4_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8mf4_i8m1_m((vint8m1_t)(op0), (vint8mf4_t)(op1), (vint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_i8mf8_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i8mf8_i8m1((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i8mf8_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i8mf8_i8m1_m((vint8m1_t)(op0), (vint8mf8_t)(op1), (vint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_i16m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16m1_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16m1_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_i16m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16m2_i16m1((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16m2_i16m1_m((vint16m1_t)(op0), (vint16m2_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_i16m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16m4_i16m1((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16m4_i16m1_m((vint16m1_t)(op0), (vint16m4_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_i16m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16m8_i16m1((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16m8_i16m1_m((vint16m1_t)(op0), (vint16m8_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredxor_vs_i16mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16mf2_i16m1((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16mf2_i16m1_m((vint16m1_t)(op0), (vint16mf2_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_i16mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i16mf4_i16m1((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i16mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i16mf4_i16m1_m((vint16m1_t)(op0), (vint16mf4_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_i32m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i32m1_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i32m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i32m1_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_i32m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i32m2_i32m1((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i32m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i32m2_i32m1_m((vint32m1_t)(op0), (vint32m2_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_i32m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i32m4_i32m1((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i32m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i32m4_i32m1_m((vint32m1_t)(op0), (vint32m4_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_i32m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i32m8_i32m1((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i32m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i32m8_i32m1_m((vint32m1_t)(op0), (vint32m8_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_i32mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i32mf2_i32m1((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i32mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i32mf2_i32m1_m((vint32m1_t)(op0), (vint32mf2_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_i64m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i64m1_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i64m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i64m1_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_i64m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i64m2_i64m1((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i64m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i64m2_i64m1_m((vint64m1_t)(op0), (vint64m2_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_i64m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i64m4_i64m1((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i64m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i64m4_i64m1_m((vint64m1_t)(op0), (vint64m4_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_i64m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_i64m8_i64m1((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_i64m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_i64m8_i64m1_m((vint64m1_t)(op0), (vint64m8_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_u8m1_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8m1_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8m1_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8m1_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_u8m2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8m2_u8m1((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8m2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8m2_u8m1_m((vuint8m1_t)(op0), (vuint8m2_t)(op1), (vuint8m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_u8m4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8m4_u8m1((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8m4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8m4_u8m1_m((vuint8m1_t)(op0), (vuint8m4_t)(op1), (vuint8m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredxor_vs_u8m8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8m8_u8m1((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8m8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8m8_u8m1_m((vuint8m1_t)(op0), (vuint8m8_t)(op1), (vuint8m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vredxor_vs_u8mf2_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8mf2_u8m1((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8mf2_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8mf2_u8m1_m((vuint8m1_t)(op0), (vuint8mf2_t)(op1), (vuint8m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_u8mf4_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8mf4_u8m1((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8mf4_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8mf4_u8m1_m((vuint8m1_t)(op0), (vuint8mf4_t)(op1), (vuint8m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_u8mf8_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u8mf8_u8m1((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u8mf8_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u8mf8_u8m1_m((vuint8m1_t)(op0), (vuint8mf8_t)(op1), (vuint8m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_u16m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16m1_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16m1_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_u16m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16m2_u16m1((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16m2_u16m1_m((vuint16m1_t)(op0), (vuint16m2_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_u16m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16m4_u16m1((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16m4_u16m1_m((vuint16m1_t)(op0), (vuint16m4_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_u16m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16m8_u16m1((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16m8_u16m1_m((vuint16m1_t)(op0), (vuint16m8_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vredxor_vs_u16mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16mf2_u16m1((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16mf2_u16m1_m((vuint16m1_t)(op0), (vuint16mf2_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_u16mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u16mf4_u16m1((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u16mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u16mf4_u16m1_m((vuint16m1_t)(op0), (vuint16mf4_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_u32m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u32m1_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u32m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u32m1_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_u32m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u32m2_u32m1((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u32m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u32m2_u32m1_m((vuint32m1_t)(op0), (vuint32m2_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_u32m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u32m4_u32m1((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u32m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u32m4_u32m1_m((vuint32m1_t)(op0), (vuint32m4_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vredxor_vs_u32m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u32m8_u32m1((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u32m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u32m8_u32m1_m((vuint32m1_t)(op0), (vuint32m8_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vredxor_vs_u32mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u32mf2_u32m1((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u32mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u32mf2_u32m1_m((vuint32m1_t)(op0), (vuint32mf2_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_u64m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u64m1_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u64m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u64m1_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vredxor_vs_u64m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u64m2_u64m1((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u64m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u64m2_u64m1_m((vuint64m1_t)(op0), (vuint64m2_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vredxor_vs_u64m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u64m4_u64m1((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u64m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u64m4_u64m1_m((vuint64m1_t)(op0), (vuint64m4_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vredxor_vs_u64m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vredxor_vs_u64m8_u64m1((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vredxor_vs_u64m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vredxor_vs_u64m8_u64m1_m((vuint64m1_t)(op0), (vuint64m8_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8m1_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8m1_i16m1((vint16m1_t)(op0), (vint8m1_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8m1_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8m1_i16m1_m((vint16m1_t)(op0), (vint8m1_t)(op1), (vint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8m2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8m2_i16m1((vint16m1_t)(op0), (vint8m2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8m2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8m2_i16m1_m((vint16m1_t)(op0), (vint8m2_t)(op1), (vint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8m4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8m4_i16m1((vint16m1_t)(op0), (vint8m4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8m4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8m4_i16m1_m((vint16m1_t)(op0), (vint8m4_t)(op1), (vint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8m8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8m8_i16m1((vint16m1_t)(op0), (vint8m8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8m8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8m8_i16m1_m((vint16m1_t)(op0), (vint8m8_t)(op1), (vint16m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8mf2_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8mf2_i16m1((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8mf2_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8mf2_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8mf4_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8mf4_i16m1((vint16m1_t)(op0), (vint8mf4_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8mf4_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8mf4_i16m1_m((vint16m1_t)(op0), (vint8mf4_t)(op1), (vint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsum_vs_i8mf8_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i8mf8_i16m1((vint16m1_t)(op0), (vint8mf8_t)(op1), (vint16m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i8mf8_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i8mf8_i16m1_m((vint16m1_t)(op0), (vint8mf8_t)(op1), (vint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16m1_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16m1_i32m1((vint32m1_t)(op0), (vint16m1_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16m1_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16m1_i32m1_m((vint32m1_t)(op0), (vint16m1_t)(op1), (vint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16m2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16m2_i32m1((vint32m1_t)(op0), (vint16m2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16m2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16m2_i32m1_m((vint32m1_t)(op0), (vint16m2_t)(op1), (vint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16m4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16m4_i32m1((vint32m1_t)(op0), (vint16m4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16m4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16m4_i32m1_m((vint32m1_t)(op0), (vint16m4_t)(op1), (vint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16m8_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16m8_i32m1((vint32m1_t)(op0), (vint16m8_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16m8_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16m8_i32m1_m((vint32m1_t)(op0), (vint16m8_t)(op1), (vint32m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16mf2_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16mf2_i32m1((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16mf2_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16mf2_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsum_vs_i16mf4_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i16mf4_i32m1((vint32m1_t)(op0), (vint16mf4_t)(op1), (vint32m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i16mf4_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i16mf4_i32m1_m((vint32m1_t)(op0), (vint16mf4_t)(op1), (vint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwredsum_vs_i32m1_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i32m1_i64m1((vint64m1_t)(op0), (vint32m1_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i32m1_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i32m1_i64m1_m((vint64m1_t)(op0), (vint32m1_t)(op1), (vint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsum_vs_i32m2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i32m2_i64m1((vint64m1_t)(op0), (vint32m2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i32m2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i32m2_i64m1_m((vint64m1_t)(op0), (vint32m2_t)(op1), (vint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsum_vs_i32m4_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i32m4_i64m1((vint64m1_t)(op0), (vint32m4_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i32m4_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i32m4_i64m1_m((vint64m1_t)(op0), (vint32m4_t)(op1), (vint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsum_vs_i32m8_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i32m8_i64m1((vint64m1_t)(op0), (vint32m8_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i32m8_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i32m8_i64m1_m((vint64m1_t)(op0), (vint32m8_t)(op1), (vint64m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsum_vs_i32mf2_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsum_vs_i32mf2_i64m1((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint64m1_t)(op2), (size_t)(op3))
#define vwredsum_vs_i32mf2_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsum_vs_i32mf2_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8m1_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8m1_u16m1((vuint16m1_t)(op0), (vuint8m1_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8m1_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8m1_u16m1_m((vuint16m1_t)(op0), (vuint8m1_t)(op1), (vuint16m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8m2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8m2_u16m1((vuint16m1_t)(op0), (vuint8m2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8m2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8m2_u16m1_m((vuint16m1_t)(op0), (vuint8m2_t)(op1), (vuint16m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8m4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8m4_u16m1((vuint16m1_t)(op0), (vuint8m4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8m4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8m4_u16m1_m((vuint16m1_t)(op0), (vuint8m4_t)(op1), (vuint16m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8m8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8m8_u16m1((vuint16m1_t)(op0), (vuint8m8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8m8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8m8_u16m1_m((vuint16m1_t)(op0), (vuint8m8_t)(op1), (vuint16m1_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8mf2_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8mf2_u16m1((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8mf2_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8mf2_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8mf4_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8mf4_u16m1((vuint16m1_t)(op0), (vuint8mf4_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8mf4_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8mf4_u16m1_m((vuint16m1_t)(op0), (vuint8mf4_t)(op1), (vuint16m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u8mf8_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u8mf8_u16m1((vuint16m1_t)(op0), (vuint8mf8_t)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u8mf8_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u8mf8_u16m1_m((vuint16m1_t)(op0), (vuint8mf8_t)(op1), (vuint16m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16m1_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16m1_u32m1((vuint32m1_t)(op0), (vuint16m1_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16m1_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16m1_u32m1_m((vuint32m1_t)(op0), (vuint16m1_t)(op1), (vuint32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16m2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16m2_u32m1((vuint32m1_t)(op0), (vuint16m2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16m2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16m2_u32m1_m((vuint32m1_t)(op0), (vuint16m2_t)(op1), (vuint32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16m4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16m4_u32m1((vuint32m1_t)(op0), (vuint16m4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16m4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16m4_u32m1_m((vuint32m1_t)(op0), (vuint16m4_t)(op1), (vuint32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16m8_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16m8_u32m1((vuint32m1_t)(op0), (vuint16m8_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16m8_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16m8_u32m1_m((vuint32m1_t)(op0), (vuint16m8_t)(op1), (vuint32m1_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16mf2_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16mf2_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16mf2_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16mf2_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u16mf4_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u16mf4_u32m1((vuint32m1_t)(op0), (vuint16mf4_t)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u16mf4_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u16mf4_u32m1_m((vuint32m1_t)(op0), (vuint16mf4_t)(op1), (vuint32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u32m1_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u32m1_u64m1((vuint64m1_t)(op0), (vuint32m1_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u32m1_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u32m1_u64m1_m((vuint64m1_t)(op0), (vuint32m1_t)(op1), (vuint64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u32m2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u32m2_u64m1((vuint64m1_t)(op0), (vuint32m2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u32m2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u32m2_u64m1_m((vuint64m1_t)(op0), (vuint32m2_t)(op1), (vuint64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u32m4_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u32m4_u64m1((vuint64m1_t)(op0), (vuint32m4_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u32m4_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u32m4_u64m1_m((vuint64m1_t)(op0), (vuint32m4_t)(op1), (vuint64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u32m8_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u32m8_u64m1((vuint64m1_t)(op0), (vuint32m8_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u32m8_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u32m8_u64m1_m((vuint64m1_t)(op0), (vuint32m8_t)(op1), (vuint64m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vwredsumu_vs_u32mf2_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vwredsumu_vs_u32mf2_u64m1((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vwredsumu_vs_u32mf2_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vwredsumu_vs_u32mf2_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse16_v_u16m1(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16m1((vuint16m1_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16m1_m((vuint16m1_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse16_v_u16m2(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16m2((vuint16m2_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16m2_m((vuint16m2_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse16_v_u16m4(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16m4((vuint16m4_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16m4_m((vuint16m4_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse16_v_u16m8(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16m8((vuint16m8_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16m8_m((vuint16m8_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vsse16_v_u16mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16mf2((vuint16mf2_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16mf2_m((vuint16mf2_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse16_v_u16mf4(op1, op2, op0, op3) \
__builtin_rvv_vsse16_v_u16mf4((vuint16mf4_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse16_v_u16mf4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse16_v_u16mf4_m((vuint16mf4_t)(op0), (uint16_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define viota_m_u8m1(op0, op1) \
__builtin_rvv_viota_m_u8m1((vbool8_t)(op0), (size_t)(op1))
#define viota_m_u8m1_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8m1_m((vuint8m1_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define viota_m_u8m2(op0, op1) \
__builtin_rvv_viota_m_u8m2((vbool4_t)(op0), (size_t)(op1))
#define viota_m_u8m2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8m2_m((vuint8m2_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define viota_m_u8m4(op0, op1) \
__builtin_rvv_viota_m_u8m4((vbool2_t)(op0), (size_t)(op1))
#define viota_m_u8m4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8m4_m((vuint8m4_t)(op0), (vbool2_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define viota_m_u8m8(op0, op1) \
__builtin_rvv_viota_m_u8m8((vbool1_t)(op0), (size_t)(op1))
#define viota_m_u8m8_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8m8_m((vuint8m8_t)(op0), (vbool1_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define viota_m_u8mf2(op0, op1) \
__builtin_rvv_viota_m_u8mf2((vbool16_t)(op0), (size_t)(op1))
#define viota_m_u8mf2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8mf2_m((vuint8mf2_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define viota_m_u8mf4(op0, op1) \
__builtin_rvv_viota_m_u8mf4((vbool32_t)(op0), (size_t)(op1))
#define viota_m_u8mf4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8mf4_m((vuint8mf4_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define viota_m_u8mf8(op0, op1) \
__builtin_rvv_viota_m_u8mf8((vbool64_t)(op0), (size_t)(op1))
#define viota_m_u8mf8_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u8mf8_m((vuint8mf8_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define viota_m_u16m1(op0, op1) \
__builtin_rvv_viota_m_u16m1((vbool16_t)(op0), (size_t)(op1))
#define viota_m_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16m1_m((vuint16m1_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define viota_m_u16m2(op0, op1) \
__builtin_rvv_viota_m_u16m2((vbool8_t)(op0), (size_t)(op1))
#define viota_m_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16m2_m((vuint16m2_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define viota_m_u16m4(op0, op1) \
__builtin_rvv_viota_m_u16m4((vbool4_t)(op0), (size_t)(op1))
#define viota_m_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16m4_m((vuint16m4_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define viota_m_u16m8(op0, op1) \
__builtin_rvv_viota_m_u16m8((vbool2_t)(op0), (size_t)(op1))
#define viota_m_u16m8_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16m8_m((vuint16m8_t)(op0), (vbool2_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define viota_m_u16mf2(op0, op1) \
__builtin_rvv_viota_m_u16mf2((vbool32_t)(op0), (size_t)(op1))
#define viota_m_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16mf2_m((vuint16mf2_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define viota_m_u16mf4(op0, op1) \
__builtin_rvv_viota_m_u16mf4((vbool64_t)(op0), (size_t)(op1))
#define viota_m_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u16mf4_m((vuint16mf4_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define viota_m_u32m1(op0, op1) \
__builtin_rvv_viota_m_u32m1((vbool32_t)(op0), (size_t)(op1))
#define viota_m_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u32m1_m((vuint32m1_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define viota_m_u32m2(op0, op1) \
__builtin_rvv_viota_m_u32m2((vbool16_t)(op0), (size_t)(op1))
#define viota_m_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u32m2_m((vuint32m2_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define viota_m_u32m4(op0, op1) \
__builtin_rvv_viota_m_u32m4((vbool8_t)(op0), (size_t)(op1))
#define viota_m_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u32m4_m((vuint32m4_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define viota_m_u32m8(op0, op1) \
__builtin_rvv_viota_m_u32m8((vbool4_t)(op0), (size_t)(op1))
#define viota_m_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u32m8_m((vuint32m8_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define viota_m_u32mf2(op0, op1) \
__builtin_rvv_viota_m_u32mf2((vbool64_t)(op0), (size_t)(op1))
#define viota_m_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u32mf2_m((vuint32mf2_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define viota_m_u64m1(op0, op1) \
__builtin_rvv_viota_m_u64m1((vbool64_t)(op0), (size_t)(op1))
#define viota_m_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u64m1_m((vuint64m1_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define viota_m_u64m2(op0, op1) \
__builtin_rvv_viota_m_u64m2((vbool32_t)(op0), (size_t)(op1))
#define viota_m_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u64m2_m((vuint64m2_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define viota_m_u64m4(op0, op1) \
__builtin_rvv_viota_m_u64m4((vbool16_t)(op0), (size_t)(op1))
#define viota_m_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u64m4_m((vuint64m4_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define viota_m_u64m8(op0, op1) \
__builtin_rvv_viota_m_u64m8((vbool8_t)(op0), (size_t)(op1))
#define viota_m_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_viota_m_u64m8_m((vuint64m8_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vid_v_i8m1(op0) \
__builtin_rvv_vid_v_i8m1((size_t)(op0))
#define vid_v_i8m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8m1_m((vint8m1_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_i8m2(op0) \
__builtin_rvv_vid_v_i8m2((size_t)(op0))
#define vid_v_i8m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8m2_m((vint8m2_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_i8m4(op0) \
__builtin_rvv_vid_v_i8m4((size_t)(op0))
#define vid_v_i8m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8m4_m((vint8m4_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vid_v_i8m8(op0) \
__builtin_rvv_vid_v_i8m8((size_t)(op0))
#define vid_v_i8m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8m8_m((vint8m8_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vid_v_i8mf2(op0) \
__builtin_rvv_vid_v_i8mf2((size_t)(op0))
#define vid_v_i8mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8mf2_m((vint8mf2_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_i8mf4(op0) \
__builtin_rvv_vid_v_i8mf4((size_t)(op0))
#define vid_v_i8mf4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8mf4_m((vint8mf4_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_i8mf8(op0) \
__builtin_rvv_vid_v_i8mf8((size_t)(op0))
#define vid_v_i8mf8_m(op1, op0, op2) \
__builtin_rvv_vid_v_i8mf8_m((vint8mf8_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_i16m1(op0) \
__builtin_rvv_vid_v_i16m1((size_t)(op0))
#define vid_v_i16m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16m1_m((vint16m1_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_i16m2(op0) \
__builtin_rvv_vid_v_i16m2((size_t)(op0))
#define vid_v_i16m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16m2_m((vint16m2_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_i16m4(op0) \
__builtin_rvv_vid_v_i16m4((size_t)(op0))
#define vid_v_i16m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16m4_m((vint16m4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_i16m8(op0) \
__builtin_rvv_vid_v_i16m8((size_t)(op0))
#define vid_v_i16m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16m8_m((vint16m8_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vid_v_i16mf2(op0) \
__builtin_rvv_vid_v_i16mf2((size_t)(op0))
#define vid_v_i16mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16mf2_m((vint16mf2_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_i16mf4(op0) \
__builtin_rvv_vid_v_i16mf4((size_t)(op0))
#define vid_v_i16mf4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i16mf4_m((vint16mf4_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_i32m1(op0) \
__builtin_rvv_vid_v_i32m1((size_t)(op0))
#define vid_v_i32m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_i32m1_m((vint32m1_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_i32m2(op0) \
__builtin_rvv_vid_v_i32m2((size_t)(op0))
#define vid_v_i32m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i32m2_m((vint32m2_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_i32m4(op0) \
__builtin_rvv_vid_v_i32m4((size_t)(op0))
#define vid_v_i32m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i32m4_m((vint32m4_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_i32m8(op0) \
__builtin_rvv_vid_v_i32m8((size_t)(op0))
#define vid_v_i32m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_i32m8_m((vint32m8_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_i32mf2(op0) \
__builtin_rvv_vid_v_i32mf2((size_t)(op0))
#define vid_v_i32mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i32mf2_m((vint32mf2_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_i64m1(op0) \
__builtin_rvv_vid_v_i64m1((size_t)(op0))
#define vid_v_i64m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_i64m1_m((vint64m1_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_i64m2(op0) \
__builtin_rvv_vid_v_i64m2((size_t)(op0))
#define vid_v_i64m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_i64m2_m((vint64m2_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_i64m4(op0) \
__builtin_rvv_vid_v_i64m4((size_t)(op0))
#define vid_v_i64m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_i64m4_m((vint64m4_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_i64m8(op0) \
__builtin_rvv_vid_v_i64m8((size_t)(op0))
#define vid_v_i64m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_i64m8_m((vint64m8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_u8m1(op0) \
__builtin_rvv_vid_v_u8m1((size_t)(op0))
#define vid_v_u8m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8m1_m((vuint8m1_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_u8m2(op0) \
__builtin_rvv_vid_v_u8m2((size_t)(op0))
#define vid_v_u8m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8m2_m((vuint8m2_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_u8m4(op0) \
__builtin_rvv_vid_v_u8m4((size_t)(op0))
#define vid_v_u8m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8m4_m((vuint8m4_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vid_v_u8m8(op0) \
__builtin_rvv_vid_v_u8m8((size_t)(op0))
#define vid_v_u8m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8m8_m((vuint8m8_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vid_v_u8mf2(op0) \
__builtin_rvv_vid_v_u8mf2((size_t)(op0))
#define vid_v_u8mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8mf2_m((vuint8mf2_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_u8mf4(op0) \
__builtin_rvv_vid_v_u8mf4((size_t)(op0))
#define vid_v_u8mf4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8mf4_m((vuint8mf4_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_u8mf8(op0) \
__builtin_rvv_vid_v_u8mf8((size_t)(op0))
#define vid_v_u8mf8_m(op1, op0, op2) \
__builtin_rvv_vid_v_u8mf8_m((vuint8mf8_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_u16m1(op0) \
__builtin_rvv_vid_v_u16m1((size_t)(op0))
#define vid_v_u16m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16m1_m((vuint16m1_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_u16m2(op0) \
__builtin_rvv_vid_v_u16m2((size_t)(op0))
#define vid_v_u16m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16m2_m((vuint16m2_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_u16m4(op0) \
__builtin_rvv_vid_v_u16m4((size_t)(op0))
#define vid_v_u16m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16m4_m((vuint16m4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_u16m8(op0) \
__builtin_rvv_vid_v_u16m8((size_t)(op0))
#define vid_v_u16m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16m8_m((vuint16m8_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vid_v_u16mf2(op0) \
__builtin_rvv_vid_v_u16mf2((size_t)(op0))
#define vid_v_u16mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16mf2_m((vuint16mf2_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_u16mf4(op0) \
__builtin_rvv_vid_v_u16mf4((size_t)(op0))
#define vid_v_u16mf4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u16mf4_m((vuint16mf4_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_u32m1(op0) \
__builtin_rvv_vid_v_u32m1((size_t)(op0))
#define vid_v_u32m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_u32m1_m((vuint32m1_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_u32m2(op0) \
__builtin_rvv_vid_v_u32m2((size_t)(op0))
#define vid_v_u32m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u32m2_m((vuint32m2_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_u32m4(op0) \
__builtin_rvv_vid_v_u32m4((size_t)(op0))
#define vid_v_u32m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u32m4_m((vuint32m4_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vid_v_u32m8(op0) \
__builtin_rvv_vid_v_u32m8((size_t)(op0))
#define vid_v_u32m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_u32m8_m((vuint32m8_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vid_v_u32mf2(op0) \
__builtin_rvv_vid_v_u32mf2((size_t)(op0))
#define vid_v_u32mf2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u32mf2_m((vuint32mf2_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_u64m1(op0) \
__builtin_rvv_vid_v_u64m1((size_t)(op0))
#define vid_v_u64m1_m(op1, op0, op2) \
__builtin_rvv_vid_v_u64m1_m((vuint64m1_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vid_v_u64m2(op0) \
__builtin_rvv_vid_v_u64m2((size_t)(op0))
#define vid_v_u64m2_m(op1, op0, op2) \
__builtin_rvv_vid_v_u64m2_m((vuint64m2_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vid_v_u64m4(op0) \
__builtin_rvv_vid_v_u64m4((size_t)(op0))
#define vid_v_u64m4_m(op1, op0, op2) \
__builtin_rvv_vid_v_u64m4_m((vuint64m4_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vid_v_u64m8(op0) \
__builtin_rvv_vid_v_u64m8((size_t)(op0))
#define vid_v_u64m8_m(op1, op0, op2) \
__builtin_rvv_vid_v_u64m8_m((vuint64m8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vslideup_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslideup_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslideup_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslideup_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslideup_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslideup_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslideup_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8mf4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_i8mf8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_i16mf4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_i32m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_i32m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_i32m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_i32m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_i32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_i64m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_i64m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_i64m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_i64m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8mf4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_u8mf8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_u16mf4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_u32m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_u32m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_u32m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_u32m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_u32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_u64m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_u64m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_u64m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_u64m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse32_v_i32m1(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_i32m1((vint32m1_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_i32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_i32m1_m((vint32m1_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse32_v_i32m2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_i32m2((vint32m2_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_i32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_i32m2_m((vint32m2_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse32_v_i32m4(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_i32m4((vint32m4_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_i32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_i32m4_m((vint32m4_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse32_v_i32m8(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_i32m8((vint32m8_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_i32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_i32m8_m((vint32m8_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse32_v_i32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_i32mf2((vint32mf2_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_i32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_i32mf2_m((vint32mf2_t)(op0), (int32_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8m1((vuint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8m2((vuint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8m4((vuint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8m8((vuint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8mf2((vuint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8mf4((vuint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u8mf8((vuint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1up_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16m1((vuint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16m2((vuint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16m4((vuint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16m8((vuint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16mf2((vuint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u16mf4((vuint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1up_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u32m1((vuint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u32m2((vuint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u32m4((vuint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1up_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u32m8((vuint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1up_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u32mf2((vuint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1up_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u64m1((vuint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1up_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u64m2((vuint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1up_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u64m4((vuint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1up_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vslide1up_vx_u64m8((vuint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1up_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1up_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8m1((vint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8m2((vint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8m4((vint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8m8((vint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8mf2((vint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8mf4((vint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i8mf8((vint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16m1((vint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16m2((vint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16m4((vint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16m8((vint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16mf2((vint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i16mf4((vint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i32m1((vint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i32m2((vint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i32m4((vint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i32m8((vint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i32mf2((vint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i64m1((vint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i64m2((vint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i64m4((vint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_i64m8((vint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8m1((vuint8m1_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (int8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8m2((vuint8m2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (int8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8m4((vuint8m4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (int8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8m8((vuint8m8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (int8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8mf2((vuint8mf2_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (int8_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8mf4((vuint8mf4_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (int8_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u8mf8((vuint8mf8_t)(op0), (int8_t)(op1), (size_t)(op2))
#define vslide1down_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (int8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16m1((vuint16m1_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (int16_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16m2((vuint16m2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (int16_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16m4((vuint16m4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (int16_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16m8((vuint16m8_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (int16_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16mf2((vuint16mf2_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (int16_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u16mf4((vuint16mf4_t)(op0), (int16_t)(op1), (size_t)(op2))
#define vslide1down_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (int16_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u32m1((vuint32m1_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (int32_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u32m2((vuint32m2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (int32_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u32m4((vuint32m4_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (int32_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslide1down_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u32m8((vuint32m8_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (int32_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslide1down_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u32mf2((vuint32mf2_t)(op0), (int32_t)(op1), (size_t)(op2))
#define vslide1down_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (int32_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u64m1((vuint64m1_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (int64_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslide1down_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u64m2((vuint64m2_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (int64_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslide1down_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u64m4((vuint64m4_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (int64_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslide1down_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vslide1down_vx_u64m8((vuint64m8_t)(op0), (int64_t)(op1), (size_t)(op2))
#define vslide1down_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslide1down_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (int64_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8m1((vint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vrgather_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8m2((vint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vrgather_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8m4((vint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vrgather_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vv_i8m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8m8((vint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vrgather_vv_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrgather_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8mf2((vint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8mf4((vint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vrgather_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i8mf8((vint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vrgather_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgather_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgather_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgather_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgather_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgather_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i32m1((vint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vrgather_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i32m2((vint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vrgather_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i32m4((vint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vrgather_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i32m8((vint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vrgather_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i32mf2((vint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i64m1((vint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vrgather_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i64m2((vint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vrgather_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i64m4((vint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vrgather_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_i64m8((vint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vrgather_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_i8m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8m1((vint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_i8m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8m2((vint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_i8m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8m4((vint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vx_i8m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8m8((vint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8m8_m((vint8m8_t)(op0), (vint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrgather_vx_i8mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8mf2((vint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_i8mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8mf4((vint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_i8mf8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i8mf8((vint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_i16m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16m1((vint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_i16m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16m2((vint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_i16m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16m4((vint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_i16m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16m8((vint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vx_i16mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16mf2((vint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_i16mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i16mf4((vint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_i32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i32m1((vint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_i32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i32m2((vint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_i32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i32m4((vint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_i32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i32m8((vint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_i32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i32mf2((vint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_i64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i64m1((vint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_i64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i64m2((vint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_i64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i64m4((vint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_i64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_i64m8((vint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8m1((vint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8m1_m((vint8m1_t)(op0), (vint8m1_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8m2((vint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8m2_m((vint8m2_t)(op0), (vint8m2_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8m4((vint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8m4_m((vint8m4_t)(op0), (vint8m4_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8mf2((vint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8mf2_m((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8mf4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8mf4((vint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8mf4_m((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i8mf8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i8mf8((vint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i8mf8_m((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16m1((vint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16m1_m((vint16m1_t)(op0), (vint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16m2((vint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16m2_m((vint16m2_t)(op0), (vint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16m4((vint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16m4_m((vint16m4_t)(op0), (vint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16m8((vint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16m8_m((vint16m8_t)(op0), (vint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16mf2((vint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16mf2_m((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i16mf4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i16mf4((vint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i16mf4_m((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i32m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i32m1((vint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i32m1_m((vint32m1_t)(op0), (vint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i32m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i32m2((vint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i32m2_m((vint32m2_t)(op0), (vint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i32m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i32m4((vint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i32m4_m((vint32m4_t)(op0), (vint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i32m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i32m8((vint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i32m8_m((vint32m8_t)(op0), (vint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i32mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i32mf2((vint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i32mf2_m((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i64m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i64m1((vint64m1_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i64m1_m((vint64m1_t)(op0), (vint64m1_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i64m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i64m2((vint64m2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i64m2_m((vint64m2_t)(op0), (vint64m2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i64m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i64m4((vint64m4_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i64m4_m((vint64m4_t)(op0), (vint64m4_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_i64m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_i64m8((vint64m8_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_i64m8_m((vint64m8_t)(op0), (vint64m8_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vrgather_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vrgather_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vrgather_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vv_u8m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vrgather_vv_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrgather_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vrgather_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vrgather_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgather_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgather_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgather_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgather_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgather_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vrgather_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vrgather_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vrgather_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vrgather_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vrgather_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vrgather_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vrgather_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vrgather_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m1(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m1((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m2((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m4((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle8ff_v_i8m8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8m8((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf2((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf4((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle8ff_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_i8mf8((const int8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse32_v_u32m1(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_u32m1((vuint32m1_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_u32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_u32m1_m((vuint32m1_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse32_v_u32m2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_u32m2((vuint32m2_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_u32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_u32m2_m((vuint32m2_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse32_v_u32m4(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_u32m4((vuint32m4_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_u32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_u32m4_m((vuint32m4_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse32_v_u32m8(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_u32m8((vuint32m8_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_u32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_u32m8_m((vuint32m8_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse32_v_u32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_u32mf2((vuint32mf2_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_u32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_u32mf2_m((vuint32mf2_t)(op0), (uint32_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_u8m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8m1((vuint8m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_u8m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8m2((vuint8m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_u8m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8m4((vuint8m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vx_u8m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8m8((vuint8m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8m8_m((vuint8m8_t)(op0), (vuint8m8_t)(op1), (size_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vrgather_vx_u8mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8mf2((vuint8mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_u8mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8mf4((vuint8mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_u8mf8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u8mf8((vuint8mf8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_u16m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16m1((vuint16m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_u16m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16m2((vuint16m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_u16m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16m4((vuint16m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_u16m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16m8((vuint16m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgather_vx_u16mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16mf2((vuint16mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_u16mf4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u16mf4((vuint16mf4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_u32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u32m1((vuint32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_u32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u32m2((vuint32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_u32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u32m4((vuint32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_u32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u32m8((vuint32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_u32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u32mf2((vuint32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_u64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u64m1((vuint64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_u64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u64m2((vuint64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_u64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u64m4((vuint64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_u64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_u64m8((vuint64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8m1((vuint8m1_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8m1_m((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8m2((vuint8m2_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8m2_m((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8m4((vuint8m4_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8m4_m((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8mf2((vuint8mf2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8mf2_m((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8mf4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8mf4((vuint8mf4_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8mf4_m((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u8mf8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u8mf8((vuint8mf8_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u8mf8_m((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16m1_m((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16m2_m((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16m4_m((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16m8_m((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16mf2_m((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u16mf4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u16mf4_m((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u32m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u32m1((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u32m1_m((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u32m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u32m2((vuint32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u32m2_m((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u32m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u32m4((vuint32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u32m4_m((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u32m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u32m8((vuint32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u32m8_m((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u32mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u32mf2((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u32mf2_m((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u64m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u64m1((vuint64m1_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u64m1_m((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u64m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u64m2((vuint64m2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u64m2_m((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u64m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u64m4((vuint64m4_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u64m4_m((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_u64m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_u64m8((vuint64m8_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_u64m8_m((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vcompress_vm_i8m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8m1((vint8m1_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_i8m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8m2((vint8m2_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_i8m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8m4((vint8m4_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vcompress_vm_i8m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8m8((vint8m8_t)(op0), (vint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vcompress_vm_i8mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8mf2((vint8mf2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_i8mf4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8mf4((vint8mf4_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_i8mf8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i8mf8((vint8mf8_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_i16m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16m1((vint16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_i16m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16m2((vint16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_i16m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16m4((vint16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_i16m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16m8((vint16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vcompress_vm_i16mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16mf2((vint16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_i16mf4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i16mf4((vint16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_i32m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i32m1((vint32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_i32m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i32m2((vint32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_i32m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i32m4((vint32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_i32m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i32m8((vint32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_i32mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i32mf2((vint32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_i64m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i64m1((vint64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_i64m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i64m2((vint64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_i64m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i64m4((vint64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_i64m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_i64m8((vint64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_u8m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8m1((vuint8m1_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_u8m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8m2((vuint8m2_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_u8m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8m4((vuint8m4_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vcompress_vm_u8m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8m8((vuint8m8_t)(op0), (vuint8m8_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vcompress_vm_u8mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8mf2((vuint8mf2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_u8mf4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8mf4((vuint8mf4_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_u8mf8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u8mf8((vuint8mf8_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_u16m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16m1((vuint16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_u16m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16m2((vuint16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_u16m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16m4((vuint16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_u16m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16m8((vuint16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vcompress_vm_u16mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16mf2((vuint16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_u16mf4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u16mf4((vuint16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_u32m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u32m1((vuint32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_u32m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u32m2((vuint32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_u32m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u32m4((vuint32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_u32m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u32m8((vuint32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_u32mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u32mf2((vuint32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_u64m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u64m1((vuint64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_u64m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u64m2((vuint64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_u64m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u64m4((vuint64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_u64m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_u64m8((vuint64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsse64_v_i64m1(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_i64m1((vint64m1_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_i64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_i64m1_m((vint64m1_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse64_v_i64m2(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_i64m2((vint64m2_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_i64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_i64m2_m((vint64m2_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse64_v_i64m4(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_i64m4((vint64m4_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_i64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_i64m4_m((vint64m4_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse64_v_i64m8(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_i64m8((vint64m8_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_i64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_i64m8_m((vint64m8_t)(op0), (int64_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse64_v_u64m1(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_u64m1((vuint64m1_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_u64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_u64m1_m((vuint64m1_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse64_v_u64m2(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_u64m2((vuint64m2_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_u64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_u64m2_m((vuint64m2_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse64_v_u64m4(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_u64m4((vuint64m4_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_u64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_u64m4_m((vuint64m4_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse64_v_u64m8(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_u64m8((vuint64m8_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_u64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_u64m8_m((vuint64m8_t)(op0), (uint64_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m1((const int8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m2((const int8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i8m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8m4((const int8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf2((const int8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf4((const int8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i8mf8((const int8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m1((const uint8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m2((const uint8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u8m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8m4((const uint8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf2((const uint8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf4((const uint8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u8mf8((const uint8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8m1((const int8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8m2((const int8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf2((const int8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf4((const int8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i8mf8((const int8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8m1((const uint8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u8m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8m2((const uint8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf2((const uint8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf4((const uint8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u8mf8((const uint8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m1(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m1((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m2((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m4((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vle8ff_v_u8m8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8m8((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf2((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf4((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle8ff_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vle8ff_v_u8mf8((const uint8_t *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle8ff_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle8ff_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8m1((const int8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf2((const int8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf4((const int8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i8mf8((const int8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u8m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8m1((const uint8_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf2((const uint8_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf4((const uint8_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u8mf8((const uint8_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m1((const int16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m2((const int16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m4((const int16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i16m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16m8((const int16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16mf2((const int16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i16mf4((const int16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m1((const uint16_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m2((const uint16_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m4((const uint16_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u16m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16m8((const uint16_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16mf2((const uint16_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u16mf4((const uint16_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m1((const int16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m2((const int16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m4((const int16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i16m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16m8((const int16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_i16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16m8_m((vint16m8_t)(op0), (const int16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16mf2((const int16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i16mf4((const int16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m1((const uint16_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m2((const uint16_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m4((const uint16_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u16m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16m8((const uint16_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vluxei16_v_u16m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16m8_m((vuint16m8_t)(op0), (const uint16_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei16_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16mf2((const uint16_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u16mf4((const uint16_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m1((const int16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m2((const int16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i16m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16m4((const int16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16m4_m((vint16m4_t)(op0), (const int16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16mf2((const int16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i16mf4((const int16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m1((const uint16_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m2((const uint16_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u16m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16m4((const uint16_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u16m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16m4_m((vuint16m4_t)(op0), (const uint16_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16mf2((const uint16_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u16mf4((const uint16_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i16m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16m1((const int16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16m1_m((vint16m1_t)(op0), (const int16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i16m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16m2((const int16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16m2_m((vint16m2_t)(op0), (const int16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i16mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16mf2((const int16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16mf2_m((vint16mf2_t)(op0), (const int16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i16mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i16mf4((const int16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i16mf4_m((vint16mf4_t)(op0), (const int16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u16m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16m1((const uint16_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u16m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16m1_m((vuint16m1_t)(op0), (const uint16_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u16m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16m2((const uint16_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u16m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16m2_m((vuint16m2_t)(op0), (const uint16_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u16mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16mf2((const uint16_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u16mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16mf2_m((vuint16mf2_t)(op0), (const uint16_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u16mf4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u16mf4((const uint16_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u16mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u16mf4_m((vuint16mf4_t)(op0), (const uint16_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse8_v_i8m1(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8m1((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse8_v_i8m2(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8m2((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse8_v_i8m4(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8m4((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vlse8_v_i8m8(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8m8((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vlse8_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8mf2((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse8_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8mf4((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse8_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vlse8_v_i8mf8((const int8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m1((const int32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m2((const int32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m4((const int32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32m8((const int32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i32mf2((const int32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m1((const uint32_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m2((const uint32_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m4((const uint32_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32m8((const uint32_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u32mf2((const uint32_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m1((const int32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m2((const int32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m4((const int32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32m8((const int32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i32mf2((const int32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m1((const uint32_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m2((const uint32_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m4((const uint32_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32m8((const uint32_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u32mf2((const uint32_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m1((const int32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m2((const int32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m4((const int32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32m8((const int32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_i32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32m8_m((vint32m8_t)(op0), (const int32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i32mf2((const int32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m1((const uint32_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m2((const uint32_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m4((const uint32_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32m8((const uint32_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_u32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32m8_m((vuint32m8_t)(op0), (const uint32_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u32mf2((const uint32_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m1((const int32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m1_m((vint32m1_t)(op0), (const int32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m2((const int32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m2_m((vint32m2_t)(op0), (const int32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32m4((const int32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32m4_m((vint32m4_t)(op0), (const int32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i32mf2((const int32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i32mf2_m((vint32mf2_t)(op0), (const int32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m1((const uint32_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m1_m((vuint32m1_t)(op0), (const uint32_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m2((const uint32_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m2_m((vuint32m2_t)(op0), (const uint32_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32m4((const uint32_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32m4_m((vuint32m4_t)(op0), (const uint32_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u32mf2((const uint32_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u32mf2_m((vuint32mf2_t)(op0), (const uint32_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m1((const int64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m2((const int64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m4((const int64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i64m8((const int64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m1((const uint64_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m2((const uint64_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m4((const uint64_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_u64m8((const uint64_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse8_v_u8m1(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8m1((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse8_v_u8m2(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8m2((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse8_v_u8m4(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8m4((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vlse8_v_u8m8(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8m8((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vlse8_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8mf2((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse8_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8mf4((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse8_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vlse8_v_u8mf8((const uint8_t *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse8_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m1((const int64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m2((const int64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m4((const int64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_i64m8((const int64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m1((const uint64_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m2((const uint64_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m4((const uint64_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_u64m8((const uint64_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m1((const int64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m2((const int64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m4((const int64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_i64m8((const int64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m1((const uint64_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m2((const uint64_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m4((const uint64_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_u64m8((const uint64_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m1((const int64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m1_m((vint64m1_t)(op0), (const int64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m2((const int64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m2_m((vint64m2_t)(op0), (const int64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m4((const int64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m4_m((vint64m4_t)(op0), (const int64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_i64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_i64m8((const int64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_i64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_i64m8_m((vint64m8_t)(op0), (const int64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m1((const uint64_t *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m1_m((vuint64m1_t)(op0), (const uint64_t *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m2((const uint64_t *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m2_m((vuint64m2_t)(op0), (const uint64_t *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m4((const uint64_t *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m4_m((vuint64m4_t)(op0), (const uint64_t *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_u64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_u64m8((const uint64_t *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_u64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_u64m8_m((vuint64m8_t)(op0), (const uint64_t *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m1((const int8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m2((const int8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m4((const int8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vluxei8_v_i8m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8m8((const int8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vluxei8_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf2((const int8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf4((const int8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_i8mf8((const int8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m1((const int8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m2((const int8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m4((const int8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_i8m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8m8((const int8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vloxei8_v_i8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8m8_m((vint8m8_t)(op0), (const int8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf2((const int8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf4((const int8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_i8mf8((const int8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m1((const uint8_t *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m2((const uint8_t *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m4((const uint8_t *)(op0), (vuint8m4_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint8m4_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei8_v_u8m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8m8((const uint8_t *)(op0), (vuint8m8_t)(op1), (size_t)(op2))
#define vloxei8_v_u8m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8m8_m((vuint8m8_t)(op0), (const uint8_t *)(op1), (vuint8m8_t)(op2), (vbool1_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf2((const uint8_t *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf4((const uint8_t *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_u8mf8((const uint8_t *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m1((const int8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m2((const int8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_i8m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8m4((const int8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_i8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8m4_m((vint8m4_t)(op0), (const int8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf2((const int8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf4((const int8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_i8mf8((const int8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m1((const uint8_t *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m1_m((vuint8m1_t)(op0), (const uint8_t *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m2((const uint8_t *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m2_m((vuint8m2_t)(op0), (const uint8_t *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_u8m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8m4((const uint8_t *)(op0), (vuint16m8_t)(op1), (size_t)(op2))
#define vloxei16_v_u8m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8m4_m((vuint8m4_t)(op0), (const uint8_t *)(op1), (vuint16m8_t)(op2), (vbool2_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf2((const uint8_t *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf2_m((vuint8mf2_t)(op0), (const uint8_t *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf4((const uint8_t *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf4_m((vuint8mf4_t)(op0), (const uint8_t *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_u8mf8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_u8mf8((const uint8_t *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_u8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_u8mf8_m((vuint8mf8_t)(op0), (const uint8_t *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_i8m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8m1((const int8_t *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_i8m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8m1_m((vint8m1_t)(op0), (const int8_t *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_i8m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8m2((const int8_t *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_i8m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8m2_m((vint8m2_t)(op0), (const int8_t *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf2((const int8_t *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf2_m((vint8mf2_t)(op0), (const int8_t *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf4((const int8_t *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf4_m((vint8mf4_t)(op0), (const int8_t *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_i8mf8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_i8mf8((const int8_t *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_i8mf8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_i8mf8_m((vint8mf8_t)(op0), (const int8_t *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfirst_m_b8(op0, op1) \
__builtin_rvv_vfirst_m_b8((vbool8_t)(op0), (size_t)(op1))
#define vfirst_m_b8_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b8_m((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vfirst_m_b4(op0, op1) \
__builtin_rvv_vfirst_m_b4((vbool4_t)(op0), (size_t)(op1))
#define vfirst_m_b4_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b4_m((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vfirst_m_b2(op0, op1) \
__builtin_rvv_vfirst_m_b2((vbool2_t)(op0), (size_t)(op1))
#define vfirst_m_b2_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b2_m((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vfirst_m_b1(op0, op1) \
__builtin_rvv_vfirst_m_b1((vbool1_t)(op0), (size_t)(op1))
#define vfirst_m_b1_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b1_m((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vfirst_m_b16(op0, op1) \
__builtin_rvv_vfirst_m_b16((vbool16_t)(op0), (size_t)(op1))
#define vfirst_m_b16_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b16_m((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vfirst_m_b32(op0, op1) \
__builtin_rvv_vfirst_m_b32((vbool32_t)(op0), (size_t)(op1))
#define vfirst_m_b32_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b32_m((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vfirst_m_b64(op0, op1) \
__builtin_rvv_vfirst_m_b64((vbool64_t)(op0), (size_t)(op1))
#define vfirst_m_b64_m(op1, op0, op2) \
__builtin_rvv_vfirst_m_b64_m((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vle1_v_b8(op0, op1) \
__builtin_rvv_vle1_v_b8((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b4(op0, op1) \
__builtin_rvv_vle1_v_b4((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b2(op0, op1) \
__builtin_rvv_vle1_v_b2((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b1(op0, op1) \
__builtin_rvv_vle1_v_b1((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b16(op0, op1) \
__builtin_rvv_vle1_v_b16((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b32(op0, op1) \
__builtin_rvv_vle1_v_b32((const uint8_t *)(op0), (size_t)(op1))
#define vle1_v_b64(op0, op1) \
__builtin_rvv_vle1_v_b64((const uint8_t *)(op0), (size_t)(op1))
#define vmand_mm_b8(op0, op1, op2) \
__builtin_rvv_vmand_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmand_mm_b4(op0, op1, op2) \
__builtin_rvv_vmand_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmand_mm_b2(op0, op1, op2) \
__builtin_rvv_vmand_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmand_mm_b1(op0, op1, op2) \
__builtin_rvv_vmand_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmand_mm_b16(op0, op1, op2) \
__builtin_rvv_vmand_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmand_mm_b32(op0, op1, op2) \
__builtin_rvv_vmand_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmand_mm_b64(op0, op1, op2) \
__builtin_rvv_vmand_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmandnot_mm_b8(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmandnot_mm_b4(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmandnot_mm_b2(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmandnot_mm_b1(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmandnot_mm_b16(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmandnot_mm_b32(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmandnot_mm_b64(op0, op1, op2) \
__builtin_rvv_vmandnot_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmclr_m_b8(op0) \
__builtin_rvv_vmclr_m_b8((size_t)(op0))
#define vmclr_m_b4(op0) \
__builtin_rvv_vmclr_m_b4((size_t)(op0))
#define vmclr_m_b2(op0) \
__builtin_rvv_vmclr_m_b2((size_t)(op0))
#define vmclr_m_b1(op0) \
__builtin_rvv_vmclr_m_b1((size_t)(op0))
#define vmclr_m_b16(op0) \
__builtin_rvv_vmclr_m_b16((size_t)(op0))
#define vmclr_m_b32(op0) \
__builtin_rvv_vmclr_m_b32((size_t)(op0))
#define vmclr_m_b64(op0) \
__builtin_rvv_vmclr_m_b64((size_t)(op0))
#define vmnand_mm_b8(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmnand_mm_b4(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmnand_mm_b2(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmnand_mm_b1(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmnand_mm_b16(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmnand_mm_b32(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmnand_mm_b64(op0, op1, op2) \
__builtin_rvv_vmnand_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmnor_mm_b8(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmnor_mm_b4(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmnor_mm_b2(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmnor_mm_b1(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmnor_mm_b16(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmnor_mm_b32(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmnor_mm_b64(op0, op1, op2) \
__builtin_rvv_vmnor_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmor_mm_b8(op0, op1, op2) \
__builtin_rvv_vmor_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmor_mm_b4(op0, op1, op2) \
__builtin_rvv_vmor_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmor_mm_b2(op0, op1, op2) \
__builtin_rvv_vmor_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmor_mm_b1(op0, op1, op2) \
__builtin_rvv_vmor_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmor_mm_b16(op0, op1, op2) \
__builtin_rvv_vmor_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmor_mm_b32(op0, op1, op2) \
__builtin_rvv_vmor_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmor_mm_b64(op0, op1, op2) \
__builtin_rvv_vmor_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmornot_mm_b8(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmornot_mm_b4(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmornot_mm_b2(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmornot_mm_b1(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmornot_mm_b16(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmornot_mm_b32(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmornot_mm_b64(op0, op1, op2) \
__builtin_rvv_vmornot_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmsbf_m_b8(op0, op1) \
__builtin_rvv_vmsbf_m_b8((vbool8_t)(op0), (size_t)(op1))
#define vmsbf_m_b8_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b8_m((vbool8_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsbf_m_b4(op0, op1) \
__builtin_rvv_vmsbf_m_b4((vbool4_t)(op0), (size_t)(op1))
#define vmsbf_m_b4_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b4_m((vbool4_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsbf_m_b2(op0, op1) \
__builtin_rvv_vmsbf_m_b2((vbool2_t)(op0), (size_t)(op1))
#define vmsbf_m_b2_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b2_m((vbool2_t)(op0), (vbool2_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsbf_m_b1(op0, op1) \
__builtin_rvv_vmsbf_m_b1((vbool1_t)(op0), (size_t)(op1))
#define vmsbf_m_b1_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b1_m((vbool1_t)(op0), (vbool1_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsbf_m_b16(op0, op1) \
__builtin_rvv_vmsbf_m_b16((vbool16_t)(op0), (size_t)(op1))
#define vmsbf_m_b16_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b16_m((vbool16_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsbf_m_b32(op0, op1) \
__builtin_rvv_vmsbf_m_b32((vbool32_t)(op0), (size_t)(op1))
#define vmsbf_m_b32_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b32_m((vbool32_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsbf_m_b64(op0, op1) \
__builtin_rvv_vmsbf_m_b64((vbool64_t)(op0), (size_t)(op1))
#define vmsbf_m_b64_m(op2, op0, op1, op3) \
__builtin_rvv_vmsbf_m_b64_m((vbool64_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmset_m_b8(op0) \
__builtin_rvv_vmset_m_b8((size_t)(op0))
#define vmset_m_b4(op0) \
__builtin_rvv_vmset_m_b4((size_t)(op0))
#define vmset_m_b2(op0) \
__builtin_rvv_vmset_m_b2((size_t)(op0))
#define vmset_m_b1(op0) \
__builtin_rvv_vmset_m_b1((size_t)(op0))
#define vmset_m_b16(op0) \
__builtin_rvv_vmset_m_b16((size_t)(op0))
#define vmset_m_b32(op0) \
__builtin_rvv_vmset_m_b32((size_t)(op0))
#define vmset_m_b64(op0) \
__builtin_rvv_vmset_m_b64((size_t)(op0))
#define vmsif_m_b8(op0, op1) \
__builtin_rvv_vmsif_m_b8((vbool8_t)(op0), (size_t)(op1))
#define vmsif_m_b8_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b8_m((vbool8_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsif_m_b4(op0, op1) \
__builtin_rvv_vmsif_m_b4((vbool4_t)(op0), (size_t)(op1))
#define vmsif_m_b4_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b4_m((vbool4_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsif_m_b2(op0, op1) \
__builtin_rvv_vmsif_m_b2((vbool2_t)(op0), (size_t)(op1))
#define vmsif_m_b2_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b2_m((vbool2_t)(op0), (vbool2_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsif_m_b1(op0, op1) \
__builtin_rvv_vmsif_m_b1((vbool1_t)(op0), (size_t)(op1))
#define vmsif_m_b1_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b1_m((vbool1_t)(op0), (vbool1_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsif_m_b16(op0, op1) \
__builtin_rvv_vmsif_m_b16((vbool16_t)(op0), (size_t)(op1))
#define vmsif_m_b16_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b16_m((vbool16_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsif_m_b32(op0, op1) \
__builtin_rvv_vmsif_m_b32((vbool32_t)(op0), (size_t)(op1))
#define vmsif_m_b32_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b32_m((vbool32_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsif_m_b64(op0, op1) \
__builtin_rvv_vmsif_m_b64((vbool64_t)(op0), (size_t)(op1))
#define vmsif_m_b64_m(op2, op0, op1, op3) \
__builtin_rvv_vmsif_m_b64_m((vbool64_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmsof_m_b8(op0, op1) \
__builtin_rvv_vmsof_m_b8((vbool8_t)(op0), (size_t)(op1))
#define vmsof_m_b8_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b8_m((vbool8_t)(op0), (vbool8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmsof_m_b4(op0, op1) \
__builtin_rvv_vmsof_m_b4((vbool4_t)(op0), (size_t)(op1))
#define vmsof_m_b4_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b4_m((vbool4_t)(op0), (vbool4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmsof_m_b2(op0, op1) \
__builtin_rvv_vmsof_m_b2((vbool2_t)(op0), (size_t)(op1))
#define vmsof_m_b2_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b2_m((vbool2_t)(op0), (vbool2_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vmsof_m_b1(op0, op1) \
__builtin_rvv_vmsof_m_b1((vbool1_t)(op0), (size_t)(op1))
#define vmsof_m_b1_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b1_m((vbool1_t)(op0), (vbool1_t)(op1), (vbool1_t)(op2), (size_t)(op3))
#define vmsof_m_b16(op0, op1) \
__builtin_rvv_vmsof_m_b16((vbool16_t)(op0), (size_t)(op1))
#define vmsof_m_b16_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b16_m((vbool16_t)(op0), (vbool16_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmsof_m_b32(op0, op1) \
__builtin_rvv_vmsof_m_b32((vbool32_t)(op0), (size_t)(op1))
#define vmsof_m_b32_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b32_m((vbool32_t)(op0), (vbool32_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmsof_m_b64(op0, op1) \
__builtin_rvv_vmsof_m_b64((vbool64_t)(op0), (size_t)(op1))
#define vmsof_m_b64_m(op2, op0, op1, op3) \
__builtin_rvv_vmsof_m_b64_m((vbool64_t)(op0), (vbool64_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmxnor_mm_b8(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmxnor_mm_b4(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmxnor_mm_b2(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmxnor_mm_b1(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmxnor_mm_b16(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmxnor_mm_b32(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmxnor_mm_b64(op0, op1, op2) \
__builtin_rvv_vmxnor_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vmxor_mm_b8(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b8((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vmxor_mm_b4(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b4((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vmxor_mm_b2(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b2((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vmxor_mm_b1(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b1((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vmxor_mm_b16(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b16((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vmxor_mm_b32(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b32((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vmxor_mm_b64(op0, op1, op2) \
__builtin_rvv_vmxor_mm_b64((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vpopc_m_b8(op0, op1) \
__builtin_rvv_vpopc_m_b8((vbool8_t)(op0), (size_t)(op1))
#define vpopc_m_b8_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b8_m((vbool8_t)(op0), (vbool8_t)(op1), (size_t)(op2))
#define vpopc_m_b4(op0, op1) \
__builtin_rvv_vpopc_m_b4((vbool4_t)(op0), (size_t)(op1))
#define vpopc_m_b4_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b4_m((vbool4_t)(op0), (vbool4_t)(op1), (size_t)(op2))
#define vpopc_m_b2(op0, op1) \
__builtin_rvv_vpopc_m_b2((vbool2_t)(op0), (size_t)(op1))
#define vpopc_m_b2_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b2_m((vbool2_t)(op0), (vbool2_t)(op1), (size_t)(op2))
#define vpopc_m_b1(op0, op1) \
__builtin_rvv_vpopc_m_b1((vbool1_t)(op0), (size_t)(op1))
#define vpopc_m_b1_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b1_m((vbool1_t)(op0), (vbool1_t)(op1), (size_t)(op2))
#define vpopc_m_b16(op0, op1) \
__builtin_rvv_vpopc_m_b16((vbool16_t)(op0), (size_t)(op1))
#define vpopc_m_b16_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b16_m((vbool16_t)(op0), (vbool16_t)(op1), (size_t)(op2))
#define vpopc_m_b32(op0, op1) \
__builtin_rvv_vpopc_m_b32((vbool32_t)(op0), (size_t)(op1))
#define vpopc_m_b32_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b32_m((vbool32_t)(op0), (vbool32_t)(op1), (size_t)(op2))
#define vpopc_m_b64(op0, op1) \
__builtin_rvv_vpopc_m_b64((vbool64_t)(op0), (size_t)(op1))
#define vpopc_m_b64_m(op1, op0, op2) \
__builtin_rvv_vpopc_m_b64_m((vbool64_t)(op0), (vbool64_t)(op1), (size_t)(op2))
#define vse1_v_b8(op1, op0, op2) \
__builtin_rvv_vse1_v_b8((vbool8_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b4(op1, op0, op2) \
__builtin_rvv_vse1_v_b4((vbool4_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b2(op1, op0, op2) \
__builtin_rvv_vse1_v_b2((vbool2_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b1(op1, op0, op2) \
__builtin_rvv_vse1_v_b1((vbool1_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b16(op1, op0, op2) \
__builtin_rvv_vse1_v_b16((vbool16_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b32(op1, op0, op2) \
__builtin_rvv_vse1_v_b32((vbool32_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vse1_v_b64(op1, op0, op2) \
__builtin_rvv_vse1_v_b64((vbool64_t)(op0), (uint8_t *)(op1), (size_t)(op2))
#define vsext_vf2_i16mf4(op0, op1) \
__builtin_rvv_vsext_vf2_i16mf4((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf2_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16mf4_m((vint16mf4_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i16mf2(op0, op1) \
__builtin_rvv_vsext_vf2_i16mf2((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf2_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16mf2_m((vint16mf2_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m1(op0, op1) \
__builtin_rvv_vsext_vf2_i16m1((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m1_m((vint16m1_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m2(op0, op1) \
__builtin_rvv_vsext_vf2_i16m2((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m2_m((vint16m2_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m4(op0, op1) \
__builtin_rvv_vsext_vf2_i16m4((vint8m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m4_m((vint16m4_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf2_i16m8(op0, op1) \
__builtin_rvv_vsext_vf2_i16m8((vint8m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i16m8_m((vint16m8_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vsext_vf2_i32mf2(op0, op1) \
__builtin_rvv_vsext_vf2_i32mf2((vint16mf4_t)(op0), (size_t)(op1))
#define vsext_vf2_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32mf2_m((vint32mf2_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m1(op0, op1) \
__builtin_rvv_vsext_vf2_i32m1((vint16mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m1_m((vint32m1_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m2(op0, op1) \
__builtin_rvv_vsext_vf2_i32m2((vint16m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m2_m((vint32m2_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m4(op0, op1) \
__builtin_rvv_vsext_vf2_i32m4((vint16m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m4_m((vint32m4_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf2_i32m8(op0, op1) \
__builtin_rvv_vsext_vf2_i32m8((vint16m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i32m8_m((vint32m8_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m1(op0, op1) \
__builtin_rvv_vsext_vf2_i64m1((vint32mf2_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m1_m((vint64m1_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m2(op0, op1) \
__builtin_rvv_vsext_vf2_i64m2((vint32m1_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m2_m((vint64m2_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m4(op0, op1) \
__builtin_rvv_vsext_vf2_i64m4((vint32m2_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m4_m((vint64m4_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf2_i64m8(op0, op1) \
__builtin_rvv_vsext_vf2_i64m8((vint32m4_t)(op0), (size_t)(op1))
#define vsext_vf2_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf2_i64m8_m((vint64m8_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf4_i32mf2(op0, op1) \
__builtin_rvv_vsext_vf4_i32mf2((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf4_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32mf2_m((vint32mf2_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m1(op0, op1) \
__builtin_rvv_vsext_vf4_i32m1((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m1_m((vint32m1_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m2(op0, op1) \
__builtin_rvv_vsext_vf4_i32m2((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m2_m((vint32m2_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m4(op0, op1) \
__builtin_rvv_vsext_vf4_i32m4((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m4_m((vint32m4_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf4_i32m8(op0, op1) \
__builtin_rvv_vsext_vf4_i32m8((vint8m2_t)(op0), (size_t)(op1))
#define vsext_vf4_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i32m8_m((vint32m8_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m1(op0, op1) \
__builtin_rvv_vsext_vf4_i64m1((vint16mf4_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m1_m((vint64m1_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m2(op0, op1) \
__builtin_rvv_vsext_vf4_i64m2((vint16mf2_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m2_m((vint64m2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m4(op0, op1) \
__builtin_rvv_vsext_vf4_i64m4((vint16m1_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m4_m((vint64m4_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf4_i64m8(op0, op1) \
__builtin_rvv_vsext_vf4_i64m8((vint16m2_t)(op0), (size_t)(op1))
#define vsext_vf4_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf4_i64m8_m((vint64m8_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m1(op0, op1) \
__builtin_rvv_vsext_vf8_i64m1((vint8mf8_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m1_m((vint64m1_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m2(op0, op1) \
__builtin_rvv_vsext_vf8_i64m2((vint8mf4_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m2_m((vint64m2_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m4(op0, op1) \
__builtin_rvv_vsext_vf8_i64m4((vint8mf2_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m4_m((vint64m4_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vsext_vf8_i64m8(op0, op1) \
__builtin_rvv_vsext_vf8_i64m8((vint8m1_t)(op0), (size_t)(op1))
#define vsext_vf8_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vsext_vf8_i64m8_m((vint64m8_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u16mf4(op0, op1) \
__builtin_rvv_vzext_vf2_u16mf4((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf2_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16mf4_m((vuint16mf4_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u16mf2(op0, op1) \
__builtin_rvv_vzext_vf2_u16mf2((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf2_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16mf2_m((vuint16mf2_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m1(op0, op1) \
__builtin_rvv_vzext_vf2_u16m1((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m1_m((vuint16m1_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m2(op0, op1) \
__builtin_rvv_vzext_vf2_u16m2((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m2_m((vuint16m2_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m4(op0, op1) \
__builtin_rvv_vzext_vf2_u16m4((vuint8m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m4_m((vuint16m4_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf2_u16m8(op0, op1) \
__builtin_rvv_vzext_vf2_u16m8((vuint8m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u16m8_m((vuint16m8_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vzext_vf2_u32mf2(op0, op1) \
__builtin_rvv_vzext_vf2_u32mf2((vuint16mf4_t)(op0), (size_t)(op1))
#define vzext_vf2_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32mf2_m((vuint32mf2_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m1(op0, op1) \
__builtin_rvv_vzext_vf2_u32m1((vuint16mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m1_m((vuint32m1_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m2(op0, op1) \
__builtin_rvv_vzext_vf2_u32m2((vuint16m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m2_m((vuint32m2_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m4(op0, op1) \
__builtin_rvv_vzext_vf2_u32m4((vuint16m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m4_m((vuint32m4_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf2_u32m8(op0, op1) \
__builtin_rvv_vzext_vf2_u32m8((vuint16m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u32m8_m((vuint32m8_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m1(op0, op1) \
__builtin_rvv_vzext_vf2_u64m1((vuint32mf2_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m1_m((vuint64m1_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m2(op0, op1) \
__builtin_rvv_vzext_vf2_u64m2((vuint32m1_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m2_m((vuint64m2_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m4(op0, op1) \
__builtin_rvv_vzext_vf2_u64m4((vuint32m2_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m4_m((vuint64m4_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf2_u64m8(op0, op1) \
__builtin_rvv_vzext_vf2_u64m8((vuint32m4_t)(op0), (size_t)(op1))
#define vzext_vf2_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf2_u64m8_m((vuint64m8_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf4_u32mf2(op0, op1) \
__builtin_rvv_vzext_vf4_u32mf2((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf4_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32mf2_m((vuint32mf2_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m1(op0, op1) \
__builtin_rvv_vzext_vf4_u32m1((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m1_m((vuint32m1_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m2(op0, op1) \
__builtin_rvv_vzext_vf4_u32m2((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m2_m((vuint32m2_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m4(op0, op1) \
__builtin_rvv_vzext_vf4_u32m4((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m4_m((vuint32m4_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf4_u32m8(op0, op1) \
__builtin_rvv_vzext_vf4_u32m8((vuint8m2_t)(op0), (size_t)(op1))
#define vzext_vf4_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u32m8_m((vuint32m8_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m1(op0, op1) \
__builtin_rvv_vzext_vf4_u64m1((vuint16mf4_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m1_m((vuint64m1_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m2(op0, op1) \
__builtin_rvv_vzext_vf4_u64m2((vuint16mf2_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m2_m((vuint64m2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m4(op0, op1) \
__builtin_rvv_vzext_vf4_u64m4((vuint16m1_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m4_m((vuint64m4_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf4_u64m8(op0, op1) \
__builtin_rvv_vzext_vf4_u64m8((vuint16m2_t)(op0), (size_t)(op1))
#define vzext_vf4_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf4_u64m8_m((vuint64m8_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m1(op0, op1) \
__builtin_rvv_vzext_vf8_u64m1((vuint8mf8_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m1_m((vuint64m1_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m2(op0, op1) \
__builtin_rvv_vzext_vf8_u64m2((vuint8mf4_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m2_m((vuint64m2_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m4(op0, op1) \
__builtin_rvv_vzext_vf8_u64m4((vuint8mf2_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m4_m((vuint64m4_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vzext_vf8_u64m8(op0, op1) \
__builtin_rvv_vzext_vf8_u64m8((vuint8m1_t)(op0), (size_t)(op1))
#define vzext_vf8_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vzext_vf8_u64m8_m((vuint64m8_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#if defined(__riscv_f)
#define vloxei8_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m1((const float *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m2((const float *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m4((const float *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei8_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32m8((const float *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vloxei8_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei8_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f32mf2((const float *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m1((const float *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m2((const float *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m4((const float *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32m8((const float *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vloxei16_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei16_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f32mf2((const float *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m1((const float *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m2((const float *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m4((const float *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_f32m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32m8((const float *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vloxei32_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vloxei32_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f32mf2((const float *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m1((const float *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m2((const float *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_f32m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32m4((const float *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f32mf2((const float *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsuxei8_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei8_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsuxei16_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei16_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsuxei32_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsuxei32_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint8m2_t)(op2), (size_t)(op3))
#define vsoxei8_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei8_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint16m4_t)(op2), (size_t)(op3))
#define vsoxei16_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei16_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (vuint32m8_t)(op2), (size_t)(op3))
#define vsoxei32_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsoxei32_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m1(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m1((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m2((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m4(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m4((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle32ff_v_f32m8(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32m8((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vle32ff_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vle32ff_v_f32mf2((const float *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle32ff_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle32ff_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle32_v_f32m1(op0, op1) \
__builtin_rvv_vle32_v_f32m1((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle32_v_f32m2(op0, op1) \
__builtin_rvv_vle32_v_f32m2((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle32_v_f32m4(op0, op1) \
__builtin_rvv_vle32_v_f32m4((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vle32_v_f32m8(op0, op1) \
__builtin_rvv_vle32_v_f32m8((const float *)(op0), (size_t)(op1))
#define vle32_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vle32_v_f32mf2(op0, op1) \
__builtin_rvv_vle32_v_f32mf2((const float *)(op0), (size_t)(op1))
#define vle32_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vle32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse32_v_f32m1(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse32_v_f32m2(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse32_v_f32m4(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse32_v_f32m8(op1, op0, op2) \
__builtin_rvv_vse32_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vse32_v_f32mf2(op1, op0, op2) \
__builtin_rvv_vse32_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (size_t)(op2))
#define vse32_v_f32mf2_m(op2, op1, op0, op3) \
__builtin_rvv_vse32_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfadd_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfadd_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfadd_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfadd_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfadd_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfadd_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsub_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfsub_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsub_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfsub_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsub_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfsub_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsub_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfsub_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsub_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfsub_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsub_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfsub_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsub_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsub_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsub_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfsub_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsub_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfsub_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsub_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsub_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfrsub_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfrsub_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfrsub_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfrsub_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfrsub_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfrsub_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfrsub_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfrsub_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfrsub_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfrsub_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmul_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfmul_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmul_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfmul_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmul_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfmul_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmul_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfmul_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmul_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfmul_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmul_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfmul_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmul_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmul_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmul_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfmul_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmul_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfmul_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmul_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmul_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfdiv_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfdiv_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfdiv_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfdiv_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfdiv_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfdiv_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfdiv_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfdiv_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfdiv_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfdiv_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfdiv_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfdiv_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfdiv_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfdiv_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfdiv_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfdiv_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfdiv_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfdiv_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfdiv_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfdiv_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfrdiv_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfrdiv_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfrdiv_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfrdiv_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfrdiv_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmacc_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmacc_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmacc_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmacc_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmacc_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmacc_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmacc_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmacc_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmacc_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmacc_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmacc_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmacc_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmacc_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmacc_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmacc_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmacc_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmacc_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmacc_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmacc_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmacc_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsac_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmsac_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsac_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmsac_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsac_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmsac_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsac_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmsac_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmsac_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmsac_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsac_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmsac_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsac_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmsac_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsac_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmsac_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsac_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmsac_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmsac_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmsac_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmadd_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmadd_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmadd_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmadd_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmadd_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmadd_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmadd_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmadd_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmadd_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmadd_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmadd_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmadd_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmadd_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmadd_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmadd_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmadd_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmadd_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmadd_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmadd_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmadd_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsub_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmsub_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsub_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmsub_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsub_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmsub_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsub_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmsub_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmsub_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmsub_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse32_v_f32m1(op0, op1, op2) \
__builtin_rvv_vlse32_v_f32m1((const float *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse32_v_f32m2(op0, op1, op2) \
__builtin_rvv_vlse32_v_f32m2((const float *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse32_v_f32m4(op0, op1, op2) \
__builtin_rvv_vlse32_v_f32m4((const float *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse32_v_f32m8(op0, op1, op2) \
__builtin_rvv_vlse32_v_f32m8((const float *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vlse32_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vlse32_v_f32mf2((const float *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse32_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsub_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfmsub_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsub_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfmsub_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsub_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfmsub_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsub_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfmsub_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmsub_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfmsub_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f32m1_m((vfloat32m1_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f32m2_m((vfloat32m2_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f32m4_m((vfloat32m4_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f32m8_m((vfloat32m8_t)(op0), (float)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f32mf2_m((vfloat32mf2_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmin_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfmin_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmin_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfmin_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmin_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfmin_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmin_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfmin_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmin_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfmin_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmin_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfmin_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmin_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmin_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmin_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfmin_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmin_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfmin_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmin_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmin_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmax_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfmax_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmax_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfmax_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmax_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfmax_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmax_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfmax_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmax_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfmax_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmax_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfmax_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmax_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmax_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmax_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfmax_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmax_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfmax_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfmax_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfmax_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnj_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnj_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnj_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnj_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnj_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjn_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjn_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjn_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjn_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjn_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjx_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjx_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjx_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjx_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfsgnjx_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfeq_vv_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f32m1_b32((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vmfeq_vv_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfeq_vv_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f32m2_b16((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vmfeq_vv_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfeq_vv_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f32m4_b8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vmfeq_vv_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfeq_vv_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f32m8_b4((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vmfeq_vv_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfeq_vv_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f32mf2_b64((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vmfeq_vv_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfeq_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmfeq_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfeq_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfeq_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfeq_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmfeq_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfeq_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmfeq_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfeq_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfeq_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfne_vv_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f32m1_b32((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vmfne_vv_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfne_vv_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f32m2_b16((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vmfne_vv_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfne_vv_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f32m4_b8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vmfne_vv_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfne_vv_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f32m8_b4((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vmfne_vv_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfne_vv_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f32mf2_b64((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vmfne_vv_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfne_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmfne_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfne_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfne_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfne_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmfne_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfne_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmfne_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfne_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfne_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmflt_vv_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f32m1_b32((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vmflt_vv_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmflt_vv_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f32m2_b16((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vmflt_vv_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmflt_vv_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f32m4_b8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vmflt_vv_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmflt_vv_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f32m8_b4((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vmflt_vv_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmflt_vv_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f32mf2_b64((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vmflt_vv_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmflt_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmflt_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmflt_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmflt_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmflt_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmflt_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmflt_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmflt_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmflt_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmflt_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfle_vv_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f32m1_b32((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vmfle_vv_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfle_vv_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f32m2_b16((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vmfle_vv_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfle_vv_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f32m4_b8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vmfle_vv_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfle_vv_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f32m8_b4((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2))
#define vmfle_vv_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (vfloat32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfle_vv_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f32mf2_b64((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vmfle_vv_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfle_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmfle_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfle_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfle_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfle_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmfle_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfle_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmfle_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfle_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfle_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfgt_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmfgt_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfgt_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfgt_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfgt_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmfgt_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfgt_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmfgt_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfgt_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfgt_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfge_vf_f32m1_b32(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f32m1_b32((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vmfge_vf_f32m1_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f32m1_b32_m((vbool32_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfge_vf_f32m2_b16(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f32m2_b16((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfge_vf_f32m2_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f32m2_b16_m((vbool16_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfge_vf_f32m4_b8(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f32m4_b8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vmfge_vf_f32m4_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f32m4_b8_m((vbool8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfge_vf_f32m8_b4(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f32m8_b4((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vmfge_vf_f32m8_b4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f32m8_b4_m((vbool4_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vmfge_vf_f32mf2_b64(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f32mf2_b64((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vmfge_vf_f32mf2_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f32mf2_b64_m((vbool64_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmerge_vvm_f32m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_f32m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_f32m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vmerge_vvm_f32m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vmerge_vvm_f32mf2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f32m1(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f32m1((vfloat32m1_t)(op0), (float)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f32m2(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f32m2((vfloat32m2_t)(op0), (float)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f32m4(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f32m4((vfloat32m4_t)(op0), (float)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f32m8(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f32m8((vfloat32m8_t)(op0), (float)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f32mf2(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32m1_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f32m1_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32m1_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f32m1_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredmax_vs_f32m2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f32m2_f32m1((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32m2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f32m2_f32m1_m((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredmax_vs_f32m4_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f32m4_f32m1((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32m4_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f32m4_f32m1_m((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredmax_vs_f32m8_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f32m8_f32m1((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32m8_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f32m8_f32m1_m((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfredmax_vs_f32mf2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f32mf2_f32m1((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f32mf2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f32mf2_f32m1_m((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredmin_vs_f32m1_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f32m1_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f32m1_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f32m1_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredmin_vs_f32m2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f32m2_f32m1((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f32m2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f32m2_f32m1_m((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredmin_vs_f32m4_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f32m4_f32m1((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f32m4_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f32m4_f32m1_m((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredmin_vs_f32m8_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f32m8_f32m1((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f32m8_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f32m8_f32m1_m((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfredmin_vs_f32mf2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f32mf2_f32m1((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f32mf2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f32mf2_f32m1_m((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredsum_vs_f32m1_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f32m1_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f32m1_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f32m1_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredsum_vs_f32m2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f32m2_f32m1((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f32m2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f32m2_f32m1_m((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredsum_vs_f32m4_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f32m4_f32m1((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f32m4_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f32m4_f32m1_m((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredsum_vs_f32m8_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f32m8_f32m1((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f32m8_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f32m8_f32m1_m((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfredsum_vs_f32mf2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f32mf2_f32m1((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f32mf2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f32mf2_f32m1_m((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredosum_vs_f32m1_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f32m1_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f32m1_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f32m1_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredosum_vs_f32m2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f32m2_f32m1((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f32m2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f32m2_f32m1_m((vfloat32m1_t)(op0), (vfloat32m2_t)(op1), (vfloat32m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredosum_vs_f32m4_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f32m4_f32m1((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f32m4_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f32m4_f32m1_m((vfloat32m1_t)(op0), (vfloat32m4_t)(op1), (vfloat32m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredosum_vs_f32m8_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f32m8_f32m1((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f32m8_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f32m8_f32m1_m((vfloat32m1_t)(op0), (vfloat32m8_t)(op1), (vfloat32m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfredosum_vs_f32mf2_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f32mf2_f32m1((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f32mf2_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f32mf2_f32m1_m((vfloat32m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslideup_vx_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_f32m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_f32m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_f32m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_f32m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vslidedown_vx_f32mf2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1up_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1up_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1up_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1up_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1up_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f32m1(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f32m1((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1down_vf_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f32m2(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f32m2((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1down_vf_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f32m4(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f32m4((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1down_vf_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f32m8(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f32m8((vfloat32m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1down_vf_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (float)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f32mf2(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f32mf2((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfslide1down_vf_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f32m1((vfloat32m1_t)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vrgather_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f32m2((vfloat32m2_t)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vrgather_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f32m4((vfloat32m4_t)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vrgather_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f32m8((vfloat32m8_t)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vrgather_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f32mf2((vfloat32mf2_t)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vrgather_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_f32m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f32m1((vfloat32m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_f32m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f32m2((vfloat32m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_f32m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f32m4((vfloat32m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_f32m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f32m8((vfloat32m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (size_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgather_vx_f32mf2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f32mf2((vfloat32mf2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f32m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f32m1((vfloat32m1_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f32m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f32m2((vfloat32m2_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f32m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f32m4((vfloat32m4_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f32m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f32m8((vfloat32m8_t)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f32mf2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f32mf2((vfloat32mf2_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vcompress_vm_f32m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f32m1((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_f32m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f32m2((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_f32m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f32m4((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vcompress_vm_f32m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f32m8((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vcompress_vm_f32mf2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f32mf2((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vsse32_v_f32m1(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_f32m1((vfloat32m1_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_f32m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_f32m1_m((vfloat32m1_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse32_v_f32m2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_f32m2((vfloat32m2_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_f32m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_f32m2_m((vfloat32m2_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse32_v_f32m4(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_f32m4((vfloat32m4_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_f32m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_f32m4_m((vfloat32m4_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsse32_v_f32m8(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_f32m8((vfloat32m8_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_f32m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_f32m8_m((vfloat32m8_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vsse32_v_f32mf2(op1, op2, op0, op3) \
__builtin_rvv_vsse32_v_f32mf2((vfloat32mf2_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse32_v_f32mf2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse32_v_f32mf2_m((vfloat32mf2_t)(op0), (float *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m1((const float *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m2((const float *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m4((const float *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32m8((const float *)(op0), (vuint8m2_t)(op1), (size_t)(op2))
#define vluxei8_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint8m2_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei8_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f32mf2((const float *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m1((const float *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m2((const float *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m4((const float *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32m8((const float *)(op0), (vuint16m4_t)(op1), (size_t)(op2))
#define vluxei16_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint16m4_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei16_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f32mf2((const float *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m1((const float *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m2((const float *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m4((const float *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_f32m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32m8((const float *)(op0), (vuint32m8_t)(op1), (size_t)(op2))
#define vluxei32_v_f32m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32m8_m((vfloat32m8_t)(op0), (const float *)(op1), (vuint32m8_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vluxei32_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f32mf2((const float *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m1((const float *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m1_m((vfloat32m1_t)(op0), (const float *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m2((const float *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m2_m((vfloat32m2_t)(op0), (const float *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_f32m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32m4((const float *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_f32m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32m4_m((vfloat32m4_t)(op0), (const float *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_f32mf2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f32mf2((const float *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_f32mf2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f32mf2_m((vfloat32mf2_t)(op0), (const float *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfclass_v_u32m1(op0, op1) \
__builtin_rvv_vfclass_v_u32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfclass_v_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u32m1_m((vuint32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfclass_v_u32m2(op0, op1) \
__builtin_rvv_vfclass_v_u32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfclass_v_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u32m2_m((vuint32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfclass_v_u32m4(op0, op1) \
__builtin_rvv_vfclass_v_u32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfclass_v_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u32m4_m((vuint32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfclass_v_u32m8(op0, op1) \
__builtin_rvv_vfclass_v_u32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfclass_v_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u32m8_m((vuint32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfclass_v_u32mf2(op0, op1) \
__builtin_rvv_vfclass_v_u32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfclass_v_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u32mf2_m((vuint32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f32m1(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f32m1((vint32m1_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f32m1_m((vfloat32m1_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f32m2(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f32m2((vint32m2_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f32m2_m((vfloat32m2_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f32m4(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f32m4((vint32m4_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f32m4_m((vfloat32m4_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f32m8(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f32m8((vint32m8_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f32m8_m((vfloat32m8_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f32mf2(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f32mf2((vint32mf2_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f32mf2_m((vfloat32mf2_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f32m1(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f32m1((vuint32m1_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f32m1_m((vfloat32m1_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f32m2(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f32m2((vuint32m2_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f32m2_m((vfloat32m2_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f32m4(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f32m4((vuint32m4_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f32m4_m((vfloat32m4_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f32m8(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f32m8((vuint32m8_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f32m8_m((vfloat32m8_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f32mf2(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f32mf2((vuint32mf2_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f32mf2_m((vfloat32mf2_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i32m1(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m1_m((vint32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i32m2(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m2_m((vint32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i32m4(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m4_m((vint32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i32m8(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32m8_m((vint32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i32mf2(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i32mf2_m((vint32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u32m1(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m1_m((vuint32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u32m2(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m2_m((vuint32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u32m4(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m4_m((vuint32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u32m8(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32m8_m((vuint32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u32mf2(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u32mf2_m((vuint32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i32m1(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i32m1_m((vint32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i32m2(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i32m2_m((vint32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i32m4(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i32m4_m((vint32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i32m8(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i32m8_m((vint32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i32mf2(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i32mf2_m((vint32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u32m1(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u32m1_m((vuint32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u32m2(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u32m2_m((vuint32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u32m4(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u32m4_m((vuint32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u32m8(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u32m8_m((vuint32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u32mf2(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u32mf2_m((vuint32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f32mf2(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f32mf2((vint64m1_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f32mf2_m((vfloat32mf2_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f32m1(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f32m1((vint64m2_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f32m1_m((vfloat32m1_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f32m2(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f32m2((vint64m4_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f32m2_m((vfloat32m2_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f32m4(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f32m4((vint64m8_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f32m4_m((vfloat32m4_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f32mf2(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f32mf2((vuint64m1_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f32mf2_m((vfloat32mf2_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f32m1(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f32m1((vuint64m2_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f32m1_m((vfloat32m1_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f32m2(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f32m2((vuint64m4_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f32m2_m((vfloat32m2_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f32m4(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f32m4((vuint64m8_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f32m4_m((vfloat32m4_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i16mf4(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16mf4((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16mf4_m((vint16mf4_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i16mf2(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16mf2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16mf2_m((vint16mf2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i16m1(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m1((vfloat32m2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m1_m((vint16m1_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i16m2(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m2((vfloat32m4_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m2_m((vint16m2_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i16m4(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m4((vfloat32m8_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i16m4_m((vint16m4_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u16mf4(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16mf4((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16mf4_m((vuint16mf4_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u16mf2(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16mf2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16mf2_m((vuint16mf2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u16m1(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m1((vfloat32m2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m1_m((vuint16m1_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u16m2(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m2((vfloat32m4_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m2_m((vuint16m2_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u16m4(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m4((vfloat32m8_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u16m4_m((vuint16m4_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i16mf4(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i16mf4((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i16mf4_m((vint16mf4_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i16mf2(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i16mf2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i16mf2_m((vint16mf2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i16m1(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i16m1((vfloat32m2_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i16m1_m((vint16m1_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i16m2(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i16m2((vfloat32m4_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i16m2_m((vint16m2_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i16m4(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i16m4((vfloat32m8_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i16m4_m((vint16m4_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u16mf4(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u16mf4((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u16mf4_m((vuint16mf4_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u16mf2(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u16mf2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u16mf2_m((vuint16mf2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u16m1(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u16m1((vfloat32m2_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u16m1_m((vuint16m1_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u16m2(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u16m2((vfloat32m4_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u16m2_m((vuint16m2_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u16m4(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u16m4((vfloat32m8_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u16m4_m((vuint16m4_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfrec7_v_f32m1(op0, op1) \
__builtin_rvv_vfrec7_v_f32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfrec7_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfrec7_v_f32m2(op0, op1) \
__builtin_rvv_vfrec7_v_f32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfrec7_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfrec7_v_f32m4(op0, op1) \
__builtin_rvv_vfrec7_v_f32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfrec7_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfrec7_v_f32m8(op0, op1) \
__builtin_rvv_vfrec7_v_f32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfrec7_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfrec7_v_f32mf2(op0, op1) \
__builtin_rvv_vfrec7_v_f32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfrec7_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f32m1(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f32m2(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f32m4(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f32m8(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f32mf2(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfsqrt_v_f32m1(op0, op1) \
__builtin_rvv_vfsqrt_v_f32m1((vfloat32m1_t)(op0), (size_t)(op1))
#define vfsqrt_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f32m1_m((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfsqrt_v_f32m2(op0, op1) \
__builtin_rvv_vfsqrt_v_f32m2((vfloat32m2_t)(op0), (size_t)(op1))
#define vfsqrt_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f32m2_m((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfsqrt_v_f32m4(op0, op1) \
__builtin_rvv_vfsqrt_v_f32m4((vfloat32m4_t)(op0), (size_t)(op1))
#define vfsqrt_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f32m4_m((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfsqrt_v_f32m8(op0, op1) \
__builtin_rvv_vfsqrt_v_f32m8((vfloat32m8_t)(op0), (size_t)(op1))
#define vfsqrt_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f32m8_m((vfloat32m8_t)(op0), (vfloat32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfsqrt_v_f32mf2(op0, op1) \
__builtin_rvv_vfsqrt_v_f32mf2((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfsqrt_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f32mf2_m((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f32mf2(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f32mf2((vint16mf4_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f32mf2_m((vfloat32mf2_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f32m1(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f32m1((vint16mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f32m1_m((vfloat32m1_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f32m2(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f32m2((vint16m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f32m2_m((vfloat32m2_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f32m4(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f32m4((vint16m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f32m4_m((vfloat32m4_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f32m8(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f32m8((vint16m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f32m8_m((vfloat32m8_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f32mf2(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f32mf2((vuint16mf4_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f32mf2_m((vfloat32mf2_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f32m1(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f32m1((vuint16mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f32m1_m((vfloat32m1_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f32m2(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f32m2((vuint16m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f32m2_m((vfloat32m2_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f32m4(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f32m4((vuint16m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f32m4_m((vfloat32m4_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f32m8(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f32m8((vuint16m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f32m8_m((vfloat32m8_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_x_f_v_i64m1(op0, op1) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m1((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_x_f_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m1_m((vint64m1_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_x_f_v_i64m2(op0, op1) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_x_f_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m2_m((vint64m2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_x_f_v_i64m4(op0, op1) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m4((vfloat32m2_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_x_f_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m4_m((vint64m4_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_x_f_v_i64m8(op0, op1) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m8((vfloat32m4_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_x_f_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_x_f_v_i64m8_m((vint64m8_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_xu_f_v_u64m1(op0, op1) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m1((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_xu_f_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m1_m((vuint64m1_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_xu_f_v_u64m2(op0, op1) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_xu_f_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m2_m((vuint64m2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_xu_f_v_u64m4(op0, op1) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m4((vfloat32m2_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_xu_f_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m4_m((vuint64m4_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_rtz_xu_f_v_u64m8(op0, op1) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m8((vfloat32m4_t)(op0), (size_t)(op1))
#define vfwcvt_rtz_xu_f_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_rtz_xu_f_v_u64m8_m((vuint64m8_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_x_f_v_i64m1(op0, op1) \
__builtin_rvv_vfwcvt_x_f_v_i64m1((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_x_f_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_x_f_v_i64m1_m((vint64m1_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_x_f_v_i64m2(op0, op1) \
__builtin_rvv_vfwcvt_x_f_v_i64m2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfwcvt_x_f_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_x_f_v_i64m2_m((vint64m2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_x_f_v_i64m4(op0, op1) \
__builtin_rvv_vfwcvt_x_f_v_i64m4((vfloat32m2_t)(op0), (size_t)(op1))
#define vfwcvt_x_f_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_x_f_v_i64m4_m((vint64m4_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_x_f_v_i64m8(op0, op1) \
__builtin_rvv_vfwcvt_x_f_v_i64m8((vfloat32m4_t)(op0), (size_t)(op1))
#define vfwcvt_x_f_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_x_f_v_i64m8_m((vint64m8_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_xu_f_v_u64m1(op0, op1) \
__builtin_rvv_vfwcvt_xu_f_v_u64m1((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_xu_f_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_xu_f_v_u64m1_m((vuint64m1_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_xu_f_v_u64m2(op0, op1) \
__builtin_rvv_vfwcvt_xu_f_v_u64m2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfwcvt_xu_f_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_xu_f_v_u64m2_m((vuint64m2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_xu_f_v_u64m4(op0, op1) \
__builtin_rvv_vfwcvt_xu_f_v_u64m4((vfloat32m2_t)(op0), (size_t)(op1))
#define vfwcvt_xu_f_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_xu_f_v_u64m4_m((vuint64m4_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_xu_f_v_u64m8(op0, op1) \
__builtin_rvv_vfwcvt_xu_f_v_u64m8((vfloat32m4_t)(op0), (size_t)(op1))
#define vfwcvt_xu_f_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_xu_f_v_u64m8_m((vuint64m8_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#endif

#if defined(__riscv_d)
#define vloxei8_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m1((const double *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m2((const double *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m4((const double *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei8_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei8_v_f64m8((const double *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vloxei8_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei8_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m1((const double *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m2((const double *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m4((const double *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei16_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei16_v_f64m8((const double *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vloxei16_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei16_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m1((const double *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m2((const double *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m4((const double *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei32_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei32_v_f64m8((const double *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vloxei32_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei32_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m1(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m1((const double *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m2(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m2((const double *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m4(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m4((const double *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vloxei64_v_f64m8(op0, op1, op2) \
__builtin_rvv_vloxei64_v_f64m8((const double *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vloxei64_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vloxei64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei8_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsuxei8_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei8_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsuxei8_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei8_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsuxei8_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei8_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei8_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsuxei8_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei8_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei16_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsuxei16_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei16_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsuxei16_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei16_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsuxei16_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei16_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei16_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsuxei16_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei16_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei32_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsuxei32_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei32_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsuxei32_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei32_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsuxei32_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei32_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei32_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsuxei32_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei32_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsuxei64_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsuxei64_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsuxei64_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsuxei64_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsuxei64_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsuxei64_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsuxei64_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsuxei64_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsuxei64_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsuxei64_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei8_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint8mf8_t)(op2), (size_t)(op3))
#define vsoxei8_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei8_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint8mf4_t)(op2), (size_t)(op3))
#define vsoxei8_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei8_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint8mf2_t)(op2), (size_t)(op3))
#define vsoxei8_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei8_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei8_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint8m1_t)(op2), (size_t)(op3))
#define vsoxei8_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei8_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei16_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint16mf4_t)(op2), (size_t)(op3))
#define vsoxei16_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei16_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint16mf2_t)(op2), (size_t)(op3))
#define vsoxei16_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei16_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint16m1_t)(op2), (size_t)(op3))
#define vsoxei16_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei16_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei16_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint16m2_t)(op2), (size_t)(op3))
#define vsoxei16_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei16_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei32_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint32mf2_t)(op2), (size_t)(op3))
#define vsoxei32_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei32_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint32m1_t)(op2), (size_t)(op3))
#define vsoxei32_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei32_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint32m2_t)(op2), (size_t)(op3))
#define vsoxei32_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei32_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei32_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint32m4_t)(op2), (size_t)(op3))
#define vsoxei32_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei32_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vsoxei64_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (vuint64m1_t)(op2), (size_t)(op3))
#define vsoxei64_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsoxei64_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (vuint64m2_t)(op2), (size_t)(op3))
#define vsoxei64_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsoxei64_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (vuint64m4_t)(op2), (size_t)(op3))
#define vsoxei64_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsoxei64_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsoxei64_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (vuint64m8_t)(op2), (size_t)(op3))
#define vsoxei64_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsoxei64_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m1(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m1((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m2(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m2((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m4(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m4((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vle64ff_v_f64m8(op0, op1, op2) \
__builtin_rvv_vle64ff_v_f64m8((const double *)(op0), (size_t *)(op1), (size_t)(op2))
#define vle64ff_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vle64ff_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (size_t *)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vle64_v_f64m1(op0, op1) \
__builtin_rvv_vle64_v_f64m1((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vle64_v_f64m2(op0, op1) \
__builtin_rvv_vle64_v_f64m2((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vle64_v_f64m4(op0, op1) \
__builtin_rvv_vle64_v_f64m4((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vle64_v_f64m8(op0, op1) \
__builtin_rvv_vle64_v_f64m8((const double *)(op0), (size_t)(op1))
#define vle64_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vle64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vse64_v_f64m1(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m1_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vse64_v_f64m2(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m2_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vse64_v_f64m4(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m4_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vse64_v_f64m8(op1, op0, op2) \
__builtin_rvv_vse64_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (size_t)(op2))
#define vse64_v_f64m8_m(op2, op1, op0, op3) \
__builtin_rvv_vse64_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfadd_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfadd_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfadd_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfadd_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfadd_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfadd_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfadd_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsub_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfsub_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsub_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfsub_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsub_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfsub_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsub_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfsub_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfsub_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsub_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfsub_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsub_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfsub_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsub_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfsub_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsub_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfsub_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfsub_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsub_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfrsub_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfrsub_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfrsub_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfrsub_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfrsub_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfrsub_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfrsub_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfrsub_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfrsub_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrsub_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwadd_wf_f64m1(op0, op1, op2) \
__builtin_rvv_vfwadd_wf_f64m1((vfloat64m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_wf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwadd_wf_f64m2(op0, op1, op2) \
__builtin_rvv_vfwadd_wf_f64m2((vfloat64m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_wf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwadd_wf_f64m4(op0, op1, op2) \
__builtin_rvv_vfwadd_wf_f64m4((vfloat64m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_wf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwadd_wf_f64m8(op0, op1, op2) \
__builtin_rvv_vfwadd_wf_f64m8((vfloat64m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_wf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwsub_wf_f64m1(op0, op1, op2) \
__builtin_rvv_vfwsub_wf_f64m1((vfloat64m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_wf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwsub_wf_f64m2(op0, op1, op2) \
__builtin_rvv_vfwsub_wf_f64m2((vfloat64m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_wf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwsub_wf_f64m4(op0, op1, op2) \
__builtin_rvv_vfwsub_wf_f64m4((vfloat64m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_wf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwsub_wf_f64m8(op0, op1, op2) \
__builtin_rvv_vfwsub_wf_f64m8((vfloat64m8_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_wf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmul_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfmul_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmul_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfmul_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmul_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfmul_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmul_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfmul_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfmul_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmul_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfmul_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmul_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfmul_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmul_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfmul_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmul_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfmul_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfmul_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmul_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfdiv_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfdiv_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfdiv_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfdiv_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfdiv_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfdiv_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfdiv_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfdiv_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfdiv_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfdiv_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfdiv_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfdiv_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfdiv_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfdiv_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfdiv_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfdiv_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfdiv_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfdiv_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfdiv_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfrdiv_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfrdiv_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfrdiv_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfrdiv_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfrdiv_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfrdiv_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfrdiv_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmacc_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmacc_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmacc_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmacc_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmacc_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmacc_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmacc_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmacc_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmacc_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmacc_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmacc_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmacc_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmacc_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmacc_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmacc_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmacc_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmacc_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmacc_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmacc_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmacc_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmacc_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmacc_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmacc_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmacc_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsac_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmsac_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsac_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmsac_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsac_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmsac_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsac_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmsac_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsac_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmsac_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsac_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmsac_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsac_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmsac_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsac_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsac_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmsac_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsac_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsac_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmsac_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsac_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsac_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmsac_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsac_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmadd_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmadd_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmadd_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmadd_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmadd_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmadd_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmadd_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmadd_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmadd_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmadd_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmadd_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmadd_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmadd_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmadd_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmadd_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmadd_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmadd_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmadd_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmadd_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmadd_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmadd_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmadd_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmadd_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmadd_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsub_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmsub_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsub_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmsub_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsub_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmsub_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsub_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmsub_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmsub_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfmsub_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmsub_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfmsub_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmsub_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfmsub_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmsub_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfmsub_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfmsub_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmsub_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsub_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmsub_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f64m1_m((vfloat64m1_t)(op0), (double)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f64m2_m((vfloat64m2_t)(op0), (double)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f64m4_m((vfloat64m4_t)(op0), (double)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfnmsub_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfnmsub_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (size_t)(op3))
#define vfnmsub_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfnmsub_vf_f64m8_m((vfloat64m8_t)(op0), (double)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmin_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfmin_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmin_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfmin_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmin_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfmin_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmin_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfmin_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfmin_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmin_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfmin_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmin_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfmin_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmin_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfmin_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmin_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfmin_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfmin_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmin_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmax_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfmax_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmax_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfmax_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmax_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfmax_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmax_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfmax_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfmax_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfmax_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfmax_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfmax_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfmax_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfmax_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfmax_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfmax_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfmax_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfmax_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfmax_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnj_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnj_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfsgnj_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnj_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnj_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnj_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnj_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnj_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnj_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnj_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjn_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfsgnjn_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjn_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjn_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjn_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjn_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnjn_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjn_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjn_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjx_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vv_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vfsgnjx_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjx_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjx_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjx_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfsgnjx_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfsgnjx_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfsgnjx_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfsgnjx_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfeq_vv_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f64m1_b64((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vmfeq_vv_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfeq_vv_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f64m2_b32((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vmfeq_vv_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfeq_vv_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f64m4_b16((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vmfeq_vv_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfeq_vv_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfeq_vv_f64m8_b8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vmfeq_vv_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vv_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfeq_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmfeq_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfeq_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmfeq_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfeq_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmfeq_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfeq_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfeq_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmfeq_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfeq_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfne_vv_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f64m1_b64((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vmfne_vv_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfne_vv_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f64m2_b32((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vmfne_vv_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfne_vv_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f64m4_b16((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vmfne_vv_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfne_vv_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfne_vv_f64m8_b8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vmfne_vv_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vv_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfne_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmfne_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfne_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmfne_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfne_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmfne_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfne_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfne_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmfne_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfne_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmflt_vv_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f64m1_b64((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vmflt_vv_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmflt_vv_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f64m2_b32((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vmflt_vv_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmflt_vv_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f64m4_b16((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vmflt_vv_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmflt_vv_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmflt_vv_f64m8_b8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vmflt_vv_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vv_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmflt_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmflt_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmflt_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmflt_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmflt_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmflt_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmflt_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmflt_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmflt_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmflt_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfle_vv_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f64m1_b64((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2))
#define vmfle_vv_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfle_vv_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f64m2_b32((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2))
#define vmfle_vv_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (vfloat64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfle_vv_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f64m4_b16((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2))
#define vmfle_vv_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (vfloat64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfle_vv_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfle_vv_f64m8_b8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2))
#define vmfle_vv_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vv_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (vfloat64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfle_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmfle_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfle_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmfle_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfle_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmfle_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfle_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfle_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmfle_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfle_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfgt_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmfgt_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfgt_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmfgt_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfgt_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmfgt_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfgt_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfgt_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmfgt_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfgt_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vlse64_v_f64m1(op0, op1, op2) \
__builtin_rvv_vlse64_v_f64m1((const double *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vlse64_v_f64m2(op0, op1, op2) \
__builtin_rvv_vlse64_v_f64m2((const double *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vlse64_v_f64m4(op0, op1, op2) \
__builtin_rvv_vlse64_v_f64m4((const double *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vlse64_v_f64m8(op0, op1, op2) \
__builtin_rvv_vlse64_v_f64m8((const double *)(op0), (ptrdiff_t)(op1), (size_t)(op2))
#define vlse64_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vlse64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmfge_vf_f64m1_b64(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f64m1_b64((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vmfge_vf_f64m1_b64_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f64m1_b64_m((vbool64_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vmfge_vf_f64m2_b32(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f64m2_b32((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vmfge_vf_f64m2_b32_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f64m2_b32_m((vbool32_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vmfge_vf_f64m4_b16(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f64m4_b16((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vmfge_vf_f64m4_b16_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f64m4_b16_m((vbool16_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vmfge_vf_f64m8_b8(op0, op1, op2) \
__builtin_rvv_vmfge_vf_f64m8_b8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vmfge_vf_f64m8_b8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vmfge_vf_f64m8_b8_m((vbool8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vmerge_vvm_f64m1(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vmerge_vvm_f64m2(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vmerge_vvm_f64m4(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vmerge_vvm_f64m8(op2, op0, op1, op3) \
__builtin_rvv_vmerge_vvm_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f64m1(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f64m1((vfloat64m1_t)(op0), (double)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f64m2(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f64m2((vfloat64m2_t)(op0), (double)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f64m4(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f64m4((vfloat64m4_t)(op0), (double)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfmerge_vfm_f64m8(op2, op0, op1, op3) \
__builtin_rvv_vfmerge_vfm_f64m8((vfloat64m8_t)(op0), (double)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfredmax_vs_f64m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f64m1_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f64m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f64m1_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredmax_vs_f64m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f64m2_f64m1((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f64m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f64m2_f64m1_m((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredmax_vs_f64m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f64m4_f64m1((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f64m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f64m4_f64m1_m((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredmax_vs_f64m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmax_vs_f64m8_f64m1((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmax_vs_f64m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmax_vs_f64m8_f64m1_m((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredmin_vs_f64m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f64m1_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f64m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f64m1_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredmin_vs_f64m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f64m2_f64m1((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f64m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f64m2_f64m1_m((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredmin_vs_f64m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f64m4_f64m1((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f64m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f64m4_f64m1_m((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredmin_vs_f64m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredmin_vs_f64m8_f64m1((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredmin_vs_f64m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredmin_vs_f64m8_f64m1_m((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredsum_vs_f64m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f64m1_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f64m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f64m1_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredsum_vs_f64m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f64m2_f64m1((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f64m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f64m2_f64m1_m((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredsum_vs_f64m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f64m4_f64m1((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f64m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f64m4_f64m1_m((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredsum_vs_f64m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredsum_vs_f64m8_f64m1((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredsum_vs_f64m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredsum_vs_f64m8_f64m1_m((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfredosum_vs_f64m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f64m1_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f64m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f64m1_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfredosum_vs_f64m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f64m2_f64m1((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f64m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f64m2_f64m1_m((vfloat64m1_t)(op0), (vfloat64m2_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfredosum_vs_f64m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f64m4_f64m1((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f64m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f64m4_f64m1_m((vfloat64m1_t)(op0), (vfloat64m4_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfredosum_vs_f64m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfredosum_vs_f64m8_f64m1((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfredosum_vs_f64m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfredosum_vs_f64m8_f64m1_m((vfloat64m1_t)(op0), (vfloat64m8_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslideup_vx_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslideup_vx_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslideup_vx_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslideup_vx_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vslideup_vx_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslideup_vx_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslideup_vx_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vslidedown_vx_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vslidedown_vx_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vslidedown_vx_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vslidedown_vx_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vslidedown_vx_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2), (size_t)(op3))
#define vslidedown_vx_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vslidedown_vx_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1up_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1up_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1up_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfslide1up_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfslide1up_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1up_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1up_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f64m1((vfloat64m1_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1down_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (double)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f64m2((vfloat64m2_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1down_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (double)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f64m4((vfloat64m4_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1down_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (double)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfslide1down_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfslide1down_vf_f64m8((vfloat64m8_t)(op0), (double)(op1), (size_t)(op2))
#define vfslide1down_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfslide1down_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (double)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f64m1((vfloat64m1_t)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vrgather_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f64m2((vfloat64m2_t)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vrgather_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f64m4((vfloat64m4_t)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vrgather_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vv_f64m8((vfloat64m8_t)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vrgather_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgather_vx_f64m1(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f64m1((vfloat64m1_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (size_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgather_vx_f64m2(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f64m2((vfloat64m2_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (size_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgather_vx_f64m4(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f64m4((vfloat64m4_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (size_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgather_vx_f64m8(op0, op1, op2) \
__builtin_rvv_vrgather_vx_f64m8((vfloat64m8_t)(op0), (size_t)(op1), (size_t)(op2))
#define vrgather_vx_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgather_vx_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (size_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f64m1((vfloat64m1_t)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f64m2((vfloat64m2_t)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f64m4((vfloat64m4_t)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vrgatherei16_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vrgatherei16_vv_f64m8((vfloat64m8_t)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vrgatherei16_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vrgatherei16_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vcompress_vm_f64m1(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f64m1((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vcompress_vm_f64m2(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f64m2((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vcompress_vm_f64m4(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f64m4((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vcompress_vm_f64m8(op2, op0, op1, op3) \
__builtin_rvv_vcompress_vm_f64m8((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vsse64_v_f64m1(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_f64m1((vfloat64m1_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_f64m1_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_f64m1_m((vfloat64m1_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vsse64_v_f64m2(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_f64m2((vfloat64m2_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_f64m2_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_f64m2_m((vfloat64m2_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vsse64_v_f64m4(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_f64m4((vfloat64m4_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_f64m4_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_f64m4_m((vfloat64m4_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vsse64_v_f64m8(op1, op2, op0, op3) \
__builtin_rvv_vsse64_v_f64m8((vfloat64m8_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (size_t)(op3))
#define vsse64_v_f64m8_m(op3, op1, op2, op0, op4) \
__builtin_rvv_vsse64_v_f64m8_m((vfloat64m8_t)(op0), (double *)(op1), (ptrdiff_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m1((const double *)(op0), (vuint8mf8_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint8mf8_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m2((const double *)(op0), (vuint8mf4_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint8mf4_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m4((const double *)(op0), (vuint8mf2_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint8mf2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei8_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei8_v_f64m8((const double *)(op0), (vuint8m1_t)(op1), (size_t)(op2))
#define vluxei8_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei8_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint8m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m1((const double *)(op0), (vuint16mf4_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint16mf4_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m2((const double *)(op0), (vuint16mf2_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint16mf2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m4((const double *)(op0), (vuint16m1_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint16m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei16_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei16_v_f64m8((const double *)(op0), (vuint16m2_t)(op1), (size_t)(op2))
#define vluxei16_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei16_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint16m2_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m1((const double *)(op0), (vuint32mf2_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m2((const double *)(op0), (vuint32m1_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m4((const double *)(op0), (vuint32m2_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei32_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei32_v_f64m8((const double *)(op0), (vuint32m4_t)(op1), (size_t)(op2))
#define vluxei32_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei32_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m1(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m1((const double *)(op0), (vuint64m1_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m1_m((vfloat64m1_t)(op0), (const double *)(op1), (vuint64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m2(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m2((const double *)(op0), (vuint64m2_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m2_m((vfloat64m2_t)(op0), (const double *)(op1), (vuint64m2_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m4(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m4((const double *)(op0), (vuint64m4_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m4_m((vfloat64m4_t)(op0), (const double *)(op1), (vuint64m4_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vluxei64_v_f64m8(op0, op1, op2) \
__builtin_rvv_vluxei64_v_f64m8((const double *)(op0), (vuint64m8_t)(op1), (size_t)(op2))
#define vluxei64_v_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vluxei64_v_f64m8_m((vfloat64m8_t)(op0), (const double *)(op1), (vuint64m8_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfclass_v_u64m1(op0, op1) \
__builtin_rvv_vfclass_v_u64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfclass_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u64m1_m((vuint64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfclass_v_u64m2(op0, op1) \
__builtin_rvv_vfclass_v_u64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfclass_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u64m2_m((vuint64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfclass_v_u64m4(op0, op1) \
__builtin_rvv_vfclass_v_u64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfclass_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u64m4_m((vuint64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfclass_v_u64m8(op0, op1) \
__builtin_rvv_vfclass_v_u64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfclass_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfclass_v_u64m8_m((vuint64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f64m1(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f64m1((vint64m1_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f64m1_m((vfloat64m1_t)(op0), (vint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f64m2(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f64m2((vint64m2_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f64m2_m((vfloat64m2_t)(op0), (vint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f64m4(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f64m4((vint64m4_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f64m4_m((vfloat64m4_t)(op0), (vint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f64m8(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f64m8((vint64m8_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f64m8_m((vfloat64m8_t)(op0), (vint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f64m1(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f64m1((vuint64m1_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f64m1_m((vfloat64m1_t)(op0), (vuint64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f64m2(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f64m2((vuint64m2_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f64m2_m((vfloat64m2_t)(op0), (vuint64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f64m4(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f64m4((vuint64m4_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f64m4_m((vfloat64m4_t)(op0), (vuint64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f64m8(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f64m8((vuint64m8_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f64m8_m((vfloat64m8_t)(op0), (vuint64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i64m1(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m1_m((vint64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i64m2(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m2_m((vint64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i64m4(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m4_m((vint64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_rtz_x_f_v_i64m8(op0, op1) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfcvt_rtz_x_f_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_x_f_v_i64m8_m((vint64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u64m1(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m1_m((vuint64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u64m2(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m2_m((vuint64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u64m4(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m4_m((vuint64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_rtz_xu_f_v_u64m8(op0, op1) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfcvt_rtz_xu_f_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_rtz_xu_f_v_u64m8_m((vuint64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i64m1(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i64m1_m((vint64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i64m2(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i64m2_m((vint64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i64m4(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i64m4_m((vint64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_x_f_v_i64m8(op0, op1) \
__builtin_rvv_vfcvt_x_f_v_i64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfcvt_x_f_v_i64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_x_f_v_i64m8_m((vint64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u64m1(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u64m1_m((vuint64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u64m2(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u64m2_m((vuint64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u64m4(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u64m4_m((vuint64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_xu_f_v_u64m8(op0, op1) \
__builtin_rvv_vfcvt_xu_f_v_u64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfcvt_xu_f_v_u64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_xu_f_v_u64m8_m((vuint64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i32mf2(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32mf2_m((vint32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i32m1(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m1_m((vint32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i32m2(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m2_m((vint32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_rtz_x_f_w_i32m4(op0, op1) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_rtz_x_f_w_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_x_f_w_i32m4_m((vint32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u32mf2(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32mf2_m((vuint32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u32m1(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m1_m((vuint32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u32m2(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m2_m((vuint32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_rtz_xu_f_w_u32m4(op0, op1) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_rtz_xu_f_w_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rtz_xu_f_w_u32m4_m((vuint32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i32mf2(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i32mf2_m((vint32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i32m1(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i32m1_m((vint32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i32m2(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i32m2_m((vint32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_x_f_w_i32m4(op0, op1) \
__builtin_rvv_vfncvt_x_f_w_i32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_x_f_w_i32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_x_f_w_i32m4_m((vint32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u32mf2(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u32mf2_m((vuint32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u32m1(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u32m1_m((vuint32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u32m2(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u32m2_m((vuint32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_xu_f_w_u32m4(op0, op1) \
__builtin_rvv_vfncvt_xu_f_w_u32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_xu_f_w_u32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_xu_f_w_u32m4_m((vuint32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfrec7_v_f64m1(op0, op1) \
__builtin_rvv_vfrec7_v_f64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfrec7_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfrec7_v_f64m2(op0, op1) \
__builtin_rvv_vfrec7_v_f64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfrec7_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfrec7_v_f64m4(op0, op1) \
__builtin_rvv_vfrec7_v_f64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfrec7_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfrec7_v_f64m8(op0, op1) \
__builtin_rvv_vfrec7_v_f64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfrec7_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfrec7_v_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f64m1(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f64m2(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f64m4(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfrsqrt7_v_f64m8(op0, op1) \
__builtin_rvv_vfrsqrt7_v_f64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfrsqrt7_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfrsqrt7_v_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfsqrt_v_f64m1(op0, op1) \
__builtin_rvv_vfsqrt_v_f64m1((vfloat64m1_t)(op0), (size_t)(op1))
#define vfsqrt_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfsqrt_v_f64m2(op0, op1) \
__builtin_rvv_vfsqrt_v_f64m2((vfloat64m2_t)(op0), (size_t)(op1))
#define vfsqrt_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfsqrt_v_f64m4(op0, op1) \
__builtin_rvv_vfsqrt_v_f64m4((vfloat64m4_t)(op0), (size_t)(op1))
#define vfsqrt_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfsqrt_v_f64m8(op0, op1) \
__builtin_rvv_vfsqrt_v_f64m8((vfloat64m8_t)(op0), (size_t)(op1))
#define vfsqrt_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfsqrt_v_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f64m1(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f64m1((vint32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f64m1_m((vfloat64m1_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f64m2(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f64m2((vint32m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f64m2_m((vfloat64m2_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f64m4(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f64m4((vint32m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f64m4_m((vfloat64m4_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f64m8(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f64m8((vint32m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f64m8_m((vfloat64m8_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f64m1(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f64m1((vuint32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f64m1_m((vfloat64m1_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f64m2(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f64m2((vuint32m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f64m2_m((vfloat64m2_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f64m4(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f64m4((vuint32m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f64m4_m((vfloat64m4_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f64m8(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f64m8((vuint32m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f64m8_m((vfloat64m8_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#endif

#if defined(__riscv_f) && defined(__riscv_d)
#define vfwadd_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfwadd_vv_f64m1((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfwadd_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwadd_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfwadd_vv_f64m2((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfwadd_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwadd_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfwadd_vv_f64m4((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfwadd_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwadd_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfwadd_vv_f64m8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfwadd_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwadd_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfwadd_vf_f64m1((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwadd_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfwadd_vf_f64m2((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwadd_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfwadd_vf_f64m4((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwadd_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfwadd_vf_f64m8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfwadd_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwsub_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfwsub_vv_f64m1((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfwsub_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwsub_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfwsub_vv_f64m2((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfwsub_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwsub_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfwsub_vv_f64m4((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfwsub_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwsub_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfwsub_vv_f64m8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfwsub_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwsub_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfwsub_vf_f64m1((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwsub_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfwsub_vf_f64m2((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwsub_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfwsub_vf_f64m4((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwsub_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfwsub_vf_f64m8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfwsub_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwadd_wv_f64m1(op0, op1, op2) \
__builtin_rvv_vfwadd_wv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfwadd_wv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwadd_wv_f64m2(op0, op1, op2) \
__builtin_rvv_vfwadd_wv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfwadd_wv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwadd_wv_f64m4(op0, op1, op2) \
__builtin_rvv_vfwadd_wv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfwadd_wv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwadd_wv_f64m8(op0, op1, op2) \
__builtin_rvv_vfwadd_wv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfwadd_wv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwadd_wv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwsub_wv_f64m1(op0, op1, op2) \
__builtin_rvv_vfwsub_wv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfwsub_wv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wv_f64m1_m((vfloat64m1_t)(op0), (vfloat64m1_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwsub_wv_f64m2(op0, op1, op2) \
__builtin_rvv_vfwsub_wv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfwsub_wv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wv_f64m2_m((vfloat64m2_t)(op0), (vfloat64m2_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwsub_wv_f64m4(op0, op1, op2) \
__builtin_rvv_vfwsub_wv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfwsub_wv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wv_f64m4_m((vfloat64m4_t)(op0), (vfloat64m4_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwsub_wv_f64m8(op0, op1, op2) \
__builtin_rvv_vfwsub_wv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfwsub_wv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwsub_wv_f64m8_m((vfloat64m8_t)(op0), (vfloat64m8_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmul_vv_f64m1(op0, op1, op2) \
__builtin_rvv_vfwmul_vv_f64m1((vfloat32mf2_t)(op0), (vfloat32mf2_t)(op1), (size_t)(op2))
#define vfwmul_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmul_vv_f64m2(op0, op1, op2) \
__builtin_rvv_vfwmul_vv_f64m2((vfloat32m1_t)(op0), (vfloat32m1_t)(op1), (size_t)(op2))
#define vfwmul_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmul_vv_f64m4(op0, op1, op2) \
__builtin_rvv_vfwmul_vv_f64m4((vfloat32m2_t)(op0), (vfloat32m2_t)(op1), (size_t)(op2))
#define vfwmul_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmul_vv_f64m8(op0, op1, op2) \
__builtin_rvv_vfwmul_vv_f64m8((vfloat32m4_t)(op0), (vfloat32m4_t)(op1), (size_t)(op2))
#define vfwmul_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmul_vf_f64m1(op0, op1, op2) \
__builtin_rvv_vfwmul_vf_f64m1((vfloat32mf2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwmul_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vf_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (float)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmul_vf_f64m2(op0, op1, op2) \
__builtin_rvv_vfwmul_vf_f64m2((vfloat32m1_t)(op0), (float)(op1), (size_t)(op2))
#define vfwmul_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vf_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (float)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmul_vf_f64m4(op0, op1, op2) \
__builtin_rvv_vfwmul_vf_f64m4((vfloat32m2_t)(op0), (float)(op1), (size_t)(op2))
#define vfwmul_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vf_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (float)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmul_vf_f64m8(op0, op1, op2) \
__builtin_rvv_vfwmul_vf_f64m8((vfloat32m4_t)(op0), (float)(op1), (size_t)(op2))
#define vfwmul_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmul_vf_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (float)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmacc_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwmacc_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmacc_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwmacc_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmacc_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwmacc_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmacc_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwmacc_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmacc_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vf_f64m1((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwmacc_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vf_f64m1_m((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmacc_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vf_f64m2((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwmacc_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vf_f64m2_m((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmacc_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vf_f64m4((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwmacc_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vf_f64m4_m((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmacc_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwmacc_vf_f64m8((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwmacc_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmacc_vf_f64m8_m((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwnmacc_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwnmacc_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwnmacc_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwnmacc_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwnmacc_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwnmacc_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwnmacc_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwnmacc_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwnmacc_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vf_f64m1((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwnmacc_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vf_f64m1_m((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwnmacc_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vf_f64m2((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwnmacc_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vf_f64m2_m((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwnmacc_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vf_f64m4((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwnmacc_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vf_f64m4_m((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwnmacc_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwnmacc_vf_f64m8((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwnmacc_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmacc_vf_f64m8_m((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmsac_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwmsac_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmsac_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwmsac_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmsac_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwmsac_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmsac_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwmsac_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwmsac_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vf_f64m1((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwmsac_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vf_f64m1_m((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwmsac_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vf_f64m2((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwmsac_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vf_f64m2_m((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwmsac_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vf_f64m4((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwmsac_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vf_f64m4_m((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwmsac_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwmsac_vf_f64m8((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwmsac_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwmsac_vf_f64m8_m((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwnmsac_vv_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vv_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwnmsac_vv_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vv_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwnmsac_vv_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vv_f64m2((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwnmsac_vv_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vv_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwnmsac_vv_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vv_f64m4((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwnmsac_vv_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vv_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwnmsac_vv_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vv_f64m8((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwnmsac_vv_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vv_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwnmsac_vf_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vf_f64m1((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (size_t)(op3))
#define vfwnmsac_vf_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vf_f64m1_m((vfloat64m1_t)(op0), (float)(op1), (vfloat32mf2_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwnmsac_vf_f64m2(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vf_f64m2((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (size_t)(op3))
#define vfwnmsac_vf_f64m2_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vf_f64m2_m((vfloat64m2_t)(op0), (float)(op1), (vfloat32m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwnmsac_vf_f64m4(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vf_f64m4((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (size_t)(op3))
#define vfwnmsac_vf_f64m4_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vf_f64m4_m((vfloat64m4_t)(op0), (float)(op1), (vfloat32m2_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwnmsac_vf_f64m8(op0, op1, op2, op3) \
__builtin_rvv_vfwnmsac_vf_f64m8((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (size_t)(op3))
#define vfwnmsac_vf_f64m8_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwnmsac_vf_f64m8_m((vfloat64m8_t)(op0), (float)(op1), (vfloat32m4_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwredsum_vs_f32m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredsum_vs_f32m1_f64m1((vfloat64m1_t)(op0), (vfloat32m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredsum_vs_f32m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredsum_vs_f32m1_f64m1_m((vfloat64m1_t)(op0), (vfloat32m1_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwredsum_vs_f32m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredsum_vs_f32m2_f64m1((vfloat64m1_t)(op0), (vfloat32m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredsum_vs_f32m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredsum_vs_f32m2_f64m1_m((vfloat64m1_t)(op0), (vfloat32m2_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwredsum_vs_f32m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredsum_vs_f32m4_f64m1((vfloat64m1_t)(op0), (vfloat32m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredsum_vs_f32m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredsum_vs_f32m4_f64m1_m((vfloat64m1_t)(op0), (vfloat32m4_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwredsum_vs_f32m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredsum_vs_f32m8_f64m1((vfloat64m1_t)(op0), (vfloat32m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredsum_vs_f32m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredsum_vs_f32m8_f64m1_m((vfloat64m1_t)(op0), (vfloat32m8_t)(op1), (vfloat64m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfwredsum_vs_f32mf2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredsum_vs_f32mf2_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredsum_vs_f32mf2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredsum_vs_f32mf2_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfwredosum_vs_f32m1_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredosum_vs_f32m1_f64m1((vfloat64m1_t)(op0), (vfloat32m1_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredosum_vs_f32m1_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredosum_vs_f32m1_f64m1_m((vfloat64m1_t)(op0), (vfloat32m1_t)(op1), (vfloat64m1_t)(op2), (vbool32_t)(op3), (size_t)(op4))
#define vfwredosum_vs_f32m2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredosum_vs_f32m2_f64m1((vfloat64m1_t)(op0), (vfloat32m2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredosum_vs_f32m2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredosum_vs_f32m2_f64m1_m((vfloat64m1_t)(op0), (vfloat32m2_t)(op1), (vfloat64m1_t)(op2), (vbool16_t)(op3), (size_t)(op4))
#define vfwredosum_vs_f32m4_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredosum_vs_f32m4_f64m1((vfloat64m1_t)(op0), (vfloat32m4_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredosum_vs_f32m4_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredosum_vs_f32m4_f64m1_m((vfloat64m1_t)(op0), (vfloat32m4_t)(op1), (vfloat64m1_t)(op2), (vbool8_t)(op3), (size_t)(op4))
#define vfwredosum_vs_f32m8_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredosum_vs_f32m8_f64m1((vfloat64m1_t)(op0), (vfloat32m8_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredosum_vs_f32m8_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredosum_vs_f32m8_f64m1_m((vfloat64m1_t)(op0), (vfloat32m8_t)(op1), (vfloat64m1_t)(op2), (vbool4_t)(op3), (size_t)(op4))
#define vfwredosum_vs_f32mf2_f64m1(op0, op1, op2, op3) \
__builtin_rvv_vfwredosum_vs_f32mf2_f64m1((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat64m1_t)(op2), (size_t)(op3))
#define vfwredosum_vs_f32mf2_f64m1_m(op3, op0, op1, op2, op4) \
__builtin_rvv_vfwredosum_vs_f32mf2_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vfloat64m1_t)(op2), (vbool64_t)(op3), (size_t)(op4))
#define vfncvt_f_f_w_f32mf2(op0, op1) \
__builtin_rvv_vfncvt_f_f_w_f32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_f_f_w_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_f_w_f32mf2_m((vfloat32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_f_w_f32m1(op0, op1) \
__builtin_rvv_vfncvt_f_f_w_f32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_f_f_w_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_f_w_f32m1_m((vfloat32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_f_f_w_f32m2(op0, op1) \
__builtin_rvv_vfncvt_f_f_w_f32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_f_f_w_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_f_w_f32m2_m((vfloat32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_f_f_w_f32m4(op0, op1) \
__builtin_rvv_vfncvt_f_f_w_f32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_f_f_w_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_f_w_f32m4_m((vfloat32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_rod_f_f_w_f32mf2(op0, op1) \
__builtin_rvv_vfncvt_rod_f_f_w_f32mf2((vfloat64m1_t)(op0), (size_t)(op1))
#define vfncvt_rod_f_f_w_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rod_f_f_w_f32mf2_m((vfloat32mf2_t)(op0), (vfloat64m1_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_rod_f_f_w_f32m1(op0, op1) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m1((vfloat64m2_t)(op0), (size_t)(op1))
#define vfncvt_rod_f_f_w_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m1_m((vfloat32m1_t)(op0), (vfloat64m2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_rod_f_f_w_f32m2(op0, op1) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m2((vfloat64m4_t)(op0), (size_t)(op1))
#define vfncvt_rod_f_f_w_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m2_m((vfloat32m2_t)(op0), (vfloat64m4_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_rod_f_f_w_f32m4(op0, op1) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m4((vfloat64m8_t)(op0), (size_t)(op1))
#define vfncvt_rod_f_f_w_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_rod_f_f_w_f32m4_m((vfloat32m4_t)(op0), (vfloat64m8_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f64m1(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f64m1((vfloat32mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f64m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f64m1_m((vfloat64m1_t)(op0), (vfloat32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f64m2(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f64m2((vfloat32m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f64m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f64m2_m((vfloat64m2_t)(op0), (vfloat32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f64m4(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f64m4((vfloat32m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f64m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f64m4_m((vfloat64m4_t)(op0), (vfloat32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f64m8(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f64m8((vfloat32m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f64m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f64m8_m((vfloat64m8_t)(op0), (vfloat32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#endif

#if defined(__riscv_zfh)
#define vfcvt_f_x_v_f16m1(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16m1((vint16m1_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16m1_m((vfloat16m1_t)(op0), (vint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f16m2(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16m2((vint16m2_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16m2_m((vfloat16m2_t)(op0), (vint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f16m4(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16m4((vint16m4_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16m4_m((vfloat16m4_t)(op0), (vint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f16m8(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16m8((vint16m8_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16m8_m((vfloat16m8_t)(op0), (vint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f16mf2(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16mf2((vint16mf2_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16mf2_m((vfloat16mf2_t)(op0), (vint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_x_v_f16mf4(op0, op1) \
__builtin_rvv_vfcvt_f_x_v_f16mf4((vint16mf4_t)(op0), (size_t)(op1))
#define vfcvt_f_x_v_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_x_v_f16mf4_m((vfloat16mf4_t)(op0), (vint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16m1(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16m1((vuint16m1_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16m1_m((vfloat16m1_t)(op0), (vuint16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16m2(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16m2((vuint16m2_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16m2_m((vfloat16m2_t)(op0), (vuint16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16m4(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16m4((vuint16m4_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16m4_m((vfloat16m4_t)(op0), (vuint16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16m8(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16m8((vuint16m8_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16m8_m((vfloat16m8_t)(op0), (vuint16m8_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16mf2(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16mf2((vuint16mf2_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16mf2_m((vfloat16mf2_t)(op0), (vuint16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfcvt_f_xu_v_f16mf4(op0, op1) \
__builtin_rvv_vfcvt_f_xu_v_f16mf4((vuint16mf4_t)(op0), (size_t)(op1))
#define vfcvt_f_xu_v_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfcvt_f_xu_v_f16mf4_m((vfloat16mf4_t)(op0), (vuint16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f16mf4(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f16mf4((vint32mf2_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f16mf4_m((vfloat16mf4_t)(op0), (vint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f16mf2(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f16mf2((vint32m1_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f16mf2_m((vfloat16mf2_t)(op0), (vint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f16m1(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f16m1((vint32m2_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f16m1_m((vfloat16m1_t)(op0), (vint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f16m2(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f16m2((vint32m4_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f16m2_m((vfloat16m2_t)(op0), (vint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_f_x_w_f16m4(op0, op1) \
__builtin_rvv_vfncvt_f_x_w_f16m4((vint32m8_t)(op0), (size_t)(op1))
#define vfncvt_f_x_w_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_x_w_f16m4_m((vfloat16m4_t)(op0), (vint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f16mf4(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f16mf4((vuint32mf2_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f16mf4_m((vfloat16mf4_t)(op0), (vuint32mf2_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f16mf2(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f16mf2((vuint32m1_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f16mf2_m((vfloat16mf2_t)(op0), (vuint32m1_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f16m1(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f16m1((vuint32m2_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f16m1_m((vfloat16m1_t)(op0), (vuint32m2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f16m2(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f16m2((vuint32m4_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f16m2_m((vfloat16m2_t)(op0), (vuint32m4_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfncvt_f_xu_w_f16m4(op0, op1) \
__builtin_rvv_vfncvt_f_xu_w_f16m4((vuint32m8_t)(op0), (size_t)(op1))
#define vfncvt_f_xu_w_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfncvt_f_xu_w_f16m4_m((vfloat16m4_t)(op0), (vuint32m8_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16mf4(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16mf4((vint8mf8_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16mf4_m((vfloat16mf4_t)(op0), (vint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16mf2(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16mf2((vint8mf4_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16mf2_m((vfloat16mf2_t)(op0), (vint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16m1(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16m1((vint8mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16m1_m((vfloat16m1_t)(op0), (vint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16m2(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16m2((vint8m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16m2_m((vfloat16m2_t)(op0), (vint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16m4(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16m4((vint8m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16m4_m((vfloat16m4_t)(op0), (vint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfwcvt_f_x_v_f16m8(op0, op1) \
__builtin_rvv_vfwcvt_f_x_v_f16m8((vint8m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_x_v_f16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_x_v_f16m8_m((vfloat16m8_t)(op0), (vint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16mf4(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16mf4((vuint8mf8_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16mf4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16mf4_m((vfloat16mf4_t)(op0), (vuint8mf8_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16mf2(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16mf2((vuint8mf4_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16mf2_m((vfloat16mf2_t)(op0), (vuint8mf4_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16m1(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16m1((vuint8mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16m1_m((vfloat16m1_t)(op0), (vuint8mf2_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16m2(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16m2((vuint8m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16m2_m((vfloat16m2_t)(op0), (vuint8m1_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16m4(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16m4((vuint8m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16m4_m((vfloat16m4_t)(op0), (vuint8m2_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#define vfwcvt_f_xu_v_f16m8(op0, op1) \
__builtin_rvv_vfwcvt_f_xu_v_f16m8((vuint8m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_xu_v_f16m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_xu_v_f16m8_m((vfloat16m8_t)(op0), (vuint8m4_t)(op1), (vbool2_t)(op2), (size_t)(op3))
#endif

#if defined(__riscv_f) && defined(__riscv_zfh)
#define vfwcvt_f_f_v_f32mf2(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f32mf2((vfloat16mf4_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f32mf2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f32mf2_m((vfloat32mf2_t)(op0), (vfloat16mf4_t)(op1), (vbool64_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f32m1(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f32m1((vfloat16mf2_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f32m1_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f32m1_m((vfloat32m1_t)(op0), (vfloat16mf2_t)(op1), (vbool32_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f32m2(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f32m2((vfloat16m1_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f32m2_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f32m2_m((vfloat32m2_t)(op0), (vfloat16m1_t)(op1), (vbool16_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f32m4(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f32m4((vfloat16m2_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f32m4_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f32m4_m((vfloat32m4_t)(op0), (vfloat16m2_t)(op1), (vbool8_t)(op2), (size_t)(op3))
#define vfwcvt_f_f_v_f32m8(op0, op1) \
__builtin_rvv_vfwcvt_f_f_v_f32m8((vfloat16m4_t)(op0), (size_t)(op1))
#define vfwcvt_f_f_v_f32m8_m(op2, op0, op1, op3) \
__builtin_rvv_vfwcvt_f_f_v_f32m8_m((vfloat32m8_t)(op0), (vfloat16m4_t)(op1), (vbool4_t)(op2), (size_t)(op3))
#endif

#define __riscv_v_intrinsic_overloading 1
#define __rvv_overloaded static inline __attribute__((__always_inline__, __nodebug__, __overloadable__))
__rvv_overloaded vint8m1_t vadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwaddu_vv(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwaddu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwaddu_vv(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwaddu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwaddu_vv(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwaddu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwaddu_vv(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwaddu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwaddu_vv(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwaddu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwaddu_vv(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwaddu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwaddu_vv(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwaddu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwaddu_vv(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwaddu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwaddu_vv(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwaddu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwaddu_vv(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwaddu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwaddu_vv(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwaddu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwaddu_vv(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwaddu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwaddu_vv(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwaddu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwaddu_vv(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwaddu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwaddu_vv(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwaddu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwaddu_vv(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwaddu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwaddu_vv(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwaddu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwaddu_vv(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwaddu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwaddu_vv(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwaddu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwaddu_vv(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwaddu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwaddu_vv(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwaddu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwaddu_vv(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwaddu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwaddu_vv(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwaddu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwaddu_vv(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwaddu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwaddu_vv(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwaddu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwaddu_vv(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwaddu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwaddu_vv(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwaddu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwaddu_vv(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwaddu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwaddu_vv(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwaddu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwaddu_vv(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwaddu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei8(const uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei8(const uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vluxei8(const uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vluxei8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vluxei8(const uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vluxei8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vluxei8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, vuint8m8_t op3, size_t op4){
  return vluxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei8(const uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei8(const uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei8(const uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei32(const uint8_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei32(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei32(const uint8_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei32(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei32(const uint8_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei32(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei32(const uint8_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei32(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei32(const uint8_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei32(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei64(const int8_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei64(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei64(const int8_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei64(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei64(const int8_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei64(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei64(const int8_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei64(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei64(const uint8_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei64(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei64(const uint8_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei64(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei64(const uint8_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei64(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei64(const uint8_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei64(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei8(const int16_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei8(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei8(const int16_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei8(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei8(const int16_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei8(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vloxei8(const int16_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vloxei8(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei8(const int16_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei8(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei8(const int16_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei8(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei8(const uint16_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei8(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei8(const uint16_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei8(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei8(const uint16_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei8(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vloxei8(const uint16_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vloxei8(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei8(const uint16_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei8(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei8(const uint16_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei8(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei16(const int16_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei16(const int16_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei16(const int16_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vloxei16(const int16_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vloxei16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei16(const int16_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei16(const int16_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei16(const uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei16(const uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei16(const uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vloxei16(const uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vloxei16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei16(const uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei16(const uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei32(const int16_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei32(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei32(const int16_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei32(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vloxei32(const int16_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vloxei32(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei32(const int16_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei32(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei32(const int16_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei32(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei32(const uint16_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei32(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei32(const uint16_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei32(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vloxei32(const uint16_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vloxei32(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei32(const uint16_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei32(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei32(const uint16_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei32(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vloxei64(const int16_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vloxei64(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vloxei64(const int16_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vloxei64(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vloxei64(const int16_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vloxei64(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vloxei64(const int16_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vloxei64(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vloxei64(const uint16_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vloxei64(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vloxei64(const uint16_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vloxei64(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vloxei64(const uint16_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vloxei64(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vloxei64(const uint16_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vloxei64(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei8(const int32_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei8(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei8(const int32_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei8(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei8(const int32_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei8(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei8(const int32_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei8(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei8(const int32_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei8(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei8(const uint32_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei8(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei8(const uint32_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei8(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei8(const uint32_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei8(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei8(const uint32_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei8(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei8(const uint32_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei8(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei16(const int32_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei16(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei16(const int32_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei16(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei16(const int32_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei16(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei16(const int32_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei16(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei16(const int32_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei16(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei16(const uint32_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei16(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei16(const uint32_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei16(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei16(const uint32_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei16(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei16(const uint32_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei16(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei16(const uint32_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei16(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei32(const int32_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei32(const int32_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei32(const int32_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vloxei32(const int32_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vloxei32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei32(const int32_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei32(const uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei32(const uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei32(const uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vloxei32(const uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vloxei32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei32(const uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vloxei64(const int32_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vloxei64(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vloxei64(const int32_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vloxei64(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vloxei64(const int32_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vloxei64(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vloxei64(const int32_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vloxei64(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vloxei64(const uint32_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vloxei64(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vloxei64(const uint32_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vloxei64(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vloxei64(const uint32_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vloxei64(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vloxei64(const uint32_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vloxei64(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei8(const int64_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei8(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei8(const int64_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei8(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei8(const int64_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei8(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei8(const int64_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei8(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei8(const uint64_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei8(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei8(const uint64_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei8(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei8(const uint64_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei8(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei8(const uint64_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei8(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei16(const int64_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei16(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei16(const int64_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei16(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei16(const int64_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei16(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei16(const int64_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei16(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei16(const uint64_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei16(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei16(const uint64_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei16(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei16(const uint64_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei16(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei16(const uint64_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei16(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei32(const int64_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei32(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei32(const int64_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei32(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei32(const int64_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei32(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei32(const int64_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei32(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei32(const uint64_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei32(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei32(const uint64_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei32(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei32(const uint64_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei32(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei32(const uint64_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei32(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vloxei64(const int64_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vloxei64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vloxei64(const int64_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vloxei64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vloxei64(const int64_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vloxei64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vloxei64(const int64_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vloxei64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vloxei64(const uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vloxei64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vloxei64(const uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vloxei64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vloxei64(const uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vloxei64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vloxei64(const uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vloxei64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16m2_t op1, vint8m1_t op2, size_t op3){
  return vsuxei16_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, int8_t * op1, vuint16m2_t op2, vint8m1_t op3, size_t op4){
  return vsuxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16m4_t op1, vint8m2_t op2, size_t op3){
  return vsuxei16_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, int8_t * op1, vuint16m4_t op2, vint8m2_t op3, size_t op4){
  return vsuxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16m8_t op1, vint8m4_t op2, size_t op3){
  return vsuxei16_v_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool2_t op0, int8_t * op1, vuint16m8_t op2, vint8m4_t op3, size_t op4){
  return vsuxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16m1_t op1, vint8mf2_t op2, size_t op3){
  return vsuxei16_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, int8_t * op1, vuint16m1_t op2, vint8mf2_t op3, size_t op4){
  return vsuxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16mf2_t op1, vint8mf4_t op2, size_t op3){
  return vsuxei16_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, int8_t * op1, vuint16mf2_t op2, vint8mf4_t op3, size_t op4){
  return vsuxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int8_t * op0, vuint16mf4_t op1, vint8mf8_t op2, size_t op3){
  return vsuxei16_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, int8_t * op1, vuint16mf4_t op2, vint8mf8_t op3, size_t op4){
  return vsuxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16m2_t op1, vuint8m1_t op2, size_t op3){
  return vsuxei16_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, uint8_t * op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vsuxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16m4_t op1, vuint8m2_t op2, size_t op3){
  return vsuxei16_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, uint8_t * op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vsuxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16m8_t op1, vuint8m4_t op2, size_t op3){
  return vsuxei16_v_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool2_t op0, uint8_t * op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vsuxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16m1_t op1, vuint8mf2_t op2, size_t op3){
  return vsuxei16_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, uint8_t * op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vsuxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16mf2_t op1, vuint8mf4_t op2, size_t op3){
  return vsuxei16_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, uint8_t * op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vsuxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint8_t * op0, vuint16mf4_t op1, vuint8mf8_t op2, size_t op3){
  return vsuxei16_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, uint8_t * op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vsuxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int8_t * op0, vuint32m4_t op1, vint8m1_t op2, size_t op3){
  return vsuxei32_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, int8_t * op1, vuint32m4_t op2, vint8m1_t op3, size_t op4){
  return vsuxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int8_t * op0, vuint32m8_t op1, vint8m2_t op2, size_t op3){
  return vsuxei32_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, int8_t * op1, vuint32m8_t op2, vint8m2_t op3, size_t op4){
  return vsuxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int8_t * op0, vuint32m2_t op1, vint8mf2_t op2, size_t op3){
  return vsuxei32_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, int8_t * op1, vuint32m2_t op2, vint8mf2_t op3, size_t op4){
  return vsuxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int8_t * op0, vuint32m1_t op1, vint8mf4_t op2, size_t op3){
  return vsuxei32_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, int8_t * op1, vuint32m1_t op2, vint8mf4_t op3, size_t op4){
  return vsuxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int8_t * op0, vuint32mf2_t op1, vint8mf8_t op2, size_t op3){
  return vsuxei32_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, int8_t * op1, vuint32mf2_t op2, vint8mf8_t op3, size_t op4){
  return vsuxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint8_t * op0, vuint32m4_t op1, vuint8m1_t op2, size_t op3){
  return vsuxei32_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, uint8_t * op1, vuint32m4_t op2, vuint8m1_t op3, size_t op4){
  return vsuxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint8_t * op0, vuint32m8_t op1, vuint8m2_t op2, size_t op3){
  return vsuxei32_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, uint8_t * op1, vuint32m8_t op2, vuint8m2_t op3, size_t op4){
  return vsuxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint8_t * op0, vuint32m2_t op1, vuint8mf2_t op2, size_t op3){
  return vsuxei32_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, uint8_t * op1, vuint32m2_t op2, vuint8mf2_t op3, size_t op4){
  return vsuxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint8_t * op0, vuint32m1_t op1, vuint8mf4_t op2, size_t op3){
  return vsuxei32_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, uint8_t * op1, vuint32m1_t op2, vuint8mf4_t op3, size_t op4){
  return vsuxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint8_t * op0, vuint32mf2_t op1, vuint8mf8_t op2, size_t op3){
  return vsuxei32_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, uint8_t * op1, vuint32mf2_t op2, vuint8mf8_t op3, size_t op4){
  return vsuxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int8_t * op0, vuint64m8_t op1, vint8m1_t op2, size_t op3){
  return vsuxei64_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, int8_t * op1, vuint64m8_t op2, vint8m1_t op3, size_t op4){
  return vsuxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int8_t * op0, vuint64m4_t op1, vint8mf2_t op2, size_t op3){
  return vsuxei64_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, int8_t * op1, vuint64m4_t op2, vint8mf2_t op3, size_t op4){
  return vsuxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int8_t * op0, vuint64m2_t op1, vint8mf4_t op2, size_t op3){
  return vsuxei64_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, int8_t * op1, vuint64m2_t op2, vint8mf4_t op3, size_t op4){
  return vsuxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int8_t * op0, vuint64m1_t op1, vint8mf8_t op2, size_t op3){
  return vsuxei64_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, int8_t * op1, vuint64m1_t op2, vint8mf8_t op3, size_t op4){
  return vsuxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint8_t * op0, vuint64m8_t op1, vuint8m1_t op2, size_t op3){
  return vsuxei64_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, uint8_t * op1, vuint64m8_t op2, vuint8m1_t op3, size_t op4){
  return vsuxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint8_t * op0, vuint64m4_t op1, vuint8mf2_t op2, size_t op3){
  return vsuxei64_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, uint8_t * op1, vuint64m4_t op2, vuint8mf2_t op3, size_t op4){
  return vsuxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint8_t * op0, vuint64m2_t op1, vuint8mf4_t op2, size_t op3){
  return vsuxei64_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, uint8_t * op1, vuint64m2_t op2, vuint8mf4_t op3, size_t op4){
  return vsuxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint8_t * op0, vuint64m1_t op1, vuint8mf8_t op2, size_t op3){
  return vsuxei64_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, uint8_t * op1, vuint64m1_t op2, vuint8mf8_t op3, size_t op4){
  return vsuxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8mf2_t op1, vint16m1_t op2, size_t op3){
  return vsuxei8_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, int16_t * op1, vuint8mf2_t op2, vint16m1_t op3, size_t op4){
  return vsuxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8m1_t op1, vint16m2_t op2, size_t op3){
  return vsuxei8_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, int16_t * op1, vuint8m1_t op2, vint16m2_t op3, size_t op4){
  return vsuxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8m2_t op1, vint16m4_t op2, size_t op3){
  return vsuxei8_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, int16_t * op1, vuint8m2_t op2, vint16m4_t op3, size_t op4){
  return vsuxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8m4_t op1, vint16m8_t op2, size_t op3){
  return vsuxei8_v_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool2_t op0, int16_t * op1, vuint8m4_t op2, vint16m8_t op3, size_t op4){
  return vsuxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8mf4_t op1, vint16mf2_t op2, size_t op3){
  return vsuxei8_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, int16_t * op1, vuint8mf4_t op2, vint16mf2_t op3, size_t op4){
  return vsuxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int16_t * op0, vuint8mf8_t op1, vint16mf4_t op2, size_t op3){
  return vsuxei8_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, int16_t * op1, vuint8mf8_t op2, vint16mf4_t op3, size_t op4){
  return vsuxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3){
  return vsuxei8_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, uint16_t * op1, vuint8mf2_t op2, vuint16m1_t op3, size_t op4){
  return vsuxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3){
  return vsuxei8_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, uint16_t * op1, vuint8m1_t op2, vuint16m2_t op3, size_t op4){
  return vsuxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3){
  return vsuxei8_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, uint16_t * op1, vuint8m2_t op2, vuint16m4_t op3, size_t op4){
  return vsuxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3){
  return vsuxei8_v_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool2_t op0, uint16_t * op1, vuint8m4_t op2, vuint16m8_t op3, size_t op4){
  return vsuxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3){
  return vsuxei8_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, uint16_t * op1, vuint8mf4_t op2, vuint16mf2_t op3, size_t op4){
  return vsuxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint16_t * op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3){
  return vsuxei8_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, uint16_t * op1, vuint8mf8_t op2, vuint16mf4_t op3, size_t op4){
  return vsuxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16m1_t op1, vint16m1_t op2, size_t op3){
  return vsuxei16_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, int16_t * op1, vuint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsuxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16m2_t op1, vint16m2_t op2, size_t op3){
  return vsuxei16_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, int16_t * op1, vuint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsuxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16m4_t op1, vint16m4_t op2, size_t op3){
  return vsuxei16_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, int16_t * op1, vuint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsuxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16m8_t op1, vint16m8_t op2, size_t op3){
  return vsuxei16_v_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool2_t op0, int16_t * op1, vuint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsuxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vsuxei16_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, int16_t * op1, vuint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsuxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int16_t * op0, vuint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vsuxei16_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, int16_t * op1, vuint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsuxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vsuxei16_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, uint16_t * op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsuxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vsuxei16_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, uint16_t * op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsuxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vsuxei16_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, uint16_t * op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsuxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vsuxei16_v_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool2_t op0, uint16_t * op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsuxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vsuxei16_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, uint16_t * op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsuxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint16_t * op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vsuxei16_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, uint16_t * op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsuxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int16_t * op0, vuint32m2_t op1, vint16m1_t op2, size_t op3){
  return vsuxei32_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, int16_t * op1, vuint32m2_t op2, vint16m1_t op3, size_t op4){
  return vsuxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int16_t * op0, vuint32m4_t op1, vint16m2_t op2, size_t op3){
  return vsuxei32_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, int16_t * op1, vuint32m4_t op2, vint16m2_t op3, size_t op4){
  return vsuxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int16_t * op0, vuint32m8_t op1, vint16m4_t op2, size_t op3){
  return vsuxei32_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, int16_t * op1, vuint32m8_t op2, vint16m4_t op3, size_t op4){
  return vsuxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int16_t * op0, vuint32m1_t op1, vint16mf2_t op2, size_t op3){
  return vsuxei32_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, int16_t * op1, vuint32m1_t op2, vint16mf2_t op3, size_t op4){
  return vsuxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int16_t * op0, vuint32mf2_t op1, vint16mf4_t op2, size_t op3){
  return vsuxei32_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, int16_t * op1, vuint32mf2_t op2, vint16mf4_t op3, size_t op4){
  return vsuxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint16_t * op0, vuint32m2_t op1, vuint16m1_t op2, size_t op3){
  return vsuxei32_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, uint16_t * op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vsuxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint16_t * op0, vuint32m4_t op1, vuint16m2_t op2, size_t op3){
  return vsuxei32_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, uint16_t * op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vsuxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint16_t * op0, vuint32m8_t op1, vuint16m4_t op2, size_t op3){
  return vsuxei32_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, uint16_t * op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vsuxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint16_t * op0, vuint32m1_t op1, vuint16mf2_t op2, size_t op3){
  return vsuxei32_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, uint16_t * op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vsuxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint16_t * op0, vuint32mf2_t op1, vuint16mf4_t op2, size_t op3){
  return vsuxei32_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, uint16_t * op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vsuxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int16_t * op0, vuint64m4_t op1, vint16m1_t op2, size_t op3){
  return vsuxei64_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, int16_t * op1, vuint64m4_t op2, vint16m1_t op3, size_t op4){
  return vsuxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int16_t * op0, vuint64m8_t op1, vint16m2_t op2, size_t op3){
  return vsuxei64_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, int16_t * op1, vuint64m8_t op2, vint16m2_t op3, size_t op4){
  return vsuxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int16_t * op0, vuint64m2_t op1, vint16mf2_t op2, size_t op3){
  return vsuxei64_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, int16_t * op1, vuint64m2_t op2, vint16mf2_t op3, size_t op4){
  return vsuxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int16_t * op0, vuint64m1_t op1, vint16mf4_t op2, size_t op3){
  return vsuxei64_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, int16_t * op1, vuint64m1_t op2, vint16mf4_t op3, size_t op4){
  return vsuxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint16_t * op0, vuint64m4_t op1, vuint16m1_t op2, size_t op3){
  return vsuxei64_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, uint16_t * op1, vuint64m4_t op2, vuint16m1_t op3, size_t op4){
  return vsuxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint16_t * op0, vuint64m8_t op1, vuint16m2_t op2, size_t op3){
  return vsuxei64_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, uint16_t * op1, vuint64m8_t op2, vuint16m2_t op3, size_t op4){
  return vsuxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint16_t * op0, vuint64m2_t op1, vuint16mf2_t op2, size_t op3){
  return vsuxei64_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, uint16_t * op1, vuint64m2_t op2, vuint16mf2_t op3, size_t op4){
  return vsuxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint16_t * op0, vuint64m1_t op1, vuint16mf4_t op2, size_t op3){
  return vsuxei64_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, uint16_t * op1, vuint64m1_t op2, vuint16mf4_t op3, size_t op4){
  return vsuxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int32_t * op0, vuint8mf4_t op1, vint32m1_t op2, size_t op3){
  return vsuxei8_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, int32_t * op1, vuint8mf4_t op2, vint32m1_t op3, size_t op4){
  return vsuxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int32_t * op0, vuint8mf2_t op1, vint32m2_t op2, size_t op3){
  return vsuxei8_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, int32_t * op1, vuint8mf2_t op2, vint32m2_t op3, size_t op4){
  return vsuxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int32_t * op0, vuint8m1_t op1, vint32m4_t op2, size_t op3){
  return vsuxei8_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, int32_t * op1, vuint8m1_t op2, vint32m4_t op3, size_t op4){
  return vsuxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int32_t * op0, vuint8m2_t op1, vint32m8_t op2, size_t op3){
  return vsuxei8_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, int32_t * op1, vuint8m2_t op2, vint32m8_t op3, size_t op4){
  return vsuxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int32_t * op0, vuint8mf8_t op1, vint32mf2_t op2, size_t op3){
  return vsuxei8_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, int32_t * op1, vuint8mf8_t op2, vint32mf2_t op3, size_t op4){
  return vsuxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint32_t * op0, vuint8mf4_t op1, vuint32m1_t op2, size_t op3){
  return vsuxei8_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, uint32_t * op1, vuint8mf4_t op2, vuint32m1_t op3, size_t op4){
  return vsuxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint32_t * op0, vuint8mf2_t op1, vuint32m2_t op2, size_t op3){
  return vsuxei8_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, uint32_t * op1, vuint8mf2_t op2, vuint32m2_t op3, size_t op4){
  return vsuxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint32_t * op0, vuint8m1_t op1, vuint32m4_t op2, size_t op3){
  return vsuxei8_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, uint32_t * op1, vuint8m1_t op2, vuint32m4_t op3, size_t op4){
  return vsuxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint32_t * op0, vuint8m2_t op1, vuint32m8_t op2, size_t op3){
  return vsuxei8_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, uint32_t * op1, vuint8m2_t op2, vuint32m8_t op3, size_t op4){
  return vsuxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint32_t * op0, vuint8mf8_t op1, vuint32mf2_t op2, size_t op3){
  return vsuxei8_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, uint32_t * op1, vuint8mf8_t op2, vuint32mf2_t op3, size_t op4){
  return vsuxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int32_t * op0, vuint16mf2_t op1, vint32m1_t op2, size_t op3){
  return vsuxei16_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, int32_t * op1, vuint16mf2_t op2, vint32m1_t op3, size_t op4){
  return vsuxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int32_t * op0, vuint16m1_t op1, vint32m2_t op2, size_t op3){
  return vsuxei16_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, int32_t * op1, vuint16m1_t op2, vint32m2_t op3, size_t op4){
  return vsuxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int32_t * op0, vuint16m2_t op1, vint32m4_t op2, size_t op3){
  return vsuxei16_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, int32_t * op1, vuint16m2_t op2, vint32m4_t op3, size_t op4){
  return vsuxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int32_t * op0, vuint16m4_t op1, vint32m8_t op2, size_t op3){
  return vsuxei16_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, int32_t * op1, vuint16m4_t op2, vint32m8_t op3, size_t op4){
  return vsuxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int32_t * op0, vuint16mf4_t op1, vint32mf2_t op2, size_t op3){
  return vsuxei16_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, int32_t * op1, vuint16mf4_t op2, vint32mf2_t op3, size_t op4){
  return vsuxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint32_t * op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3){
  return vsuxei16_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, uint32_t * op1, vuint16mf2_t op2, vuint32m1_t op3, size_t op4){
  return vsuxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint32_t * op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3){
  return vsuxei16_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, uint32_t * op1, vuint16m1_t op2, vuint32m2_t op3, size_t op4){
  return vsuxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint32_t * op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3){
  return vsuxei16_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, uint32_t * op1, vuint16m2_t op2, vuint32m4_t op3, size_t op4){
  return vsuxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint32_t * op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3){
  return vsuxei16_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, uint32_t * op1, vuint16m4_t op2, vuint32m8_t op3, size_t op4){
  return vsuxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint32_t * op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3){
  return vsuxei16_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, uint32_t * op1, vuint16mf4_t op2, vuint32mf2_t op3, size_t op4){
  return vsuxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int32_t * op0, vuint32m1_t op1, vint32m1_t op2, size_t op3){
  return vsuxei32_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, int32_t * op1, vuint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsuxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int32_t * op0, vuint32m2_t op1, vint32m2_t op2, size_t op3){
  return vsuxei32_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, int32_t * op1, vuint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsuxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int32_t * op0, vuint32m4_t op1, vint32m4_t op2, size_t op3){
  return vsuxei32_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, int32_t * op1, vuint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsuxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int32_t * op0, vuint32m8_t op1, vint32m8_t op2, size_t op3){
  return vsuxei32_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, int32_t * op1, vuint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsuxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int32_t * op0, vuint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vsuxei32_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, int32_t * op1, vuint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsuxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint32_t * op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vsuxei32_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, uint32_t * op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsuxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint32_t * op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vsuxei32_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, uint32_t * op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsuxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint32_t * op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vsuxei32_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, uint32_t * op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsuxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint32_t * op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vsuxei32_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, uint32_t * op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsuxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint32_t * op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vsuxei32_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, uint32_t * op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsuxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int32_t * op0, vuint64m2_t op1, vint32m1_t op2, size_t op3){
  return vsuxei64_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, int32_t * op1, vuint64m2_t op2, vint32m1_t op3, size_t op4){
  return vsuxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int32_t * op0, vuint64m4_t op1, vint32m2_t op2, size_t op3){
  return vsuxei64_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, int32_t * op1, vuint64m4_t op2, vint32m2_t op3, size_t op4){
  return vsuxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int32_t * op0, vuint64m8_t op1, vint32m4_t op2, size_t op3){
  return vsuxei64_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, int32_t * op1, vuint64m8_t op2, vint32m4_t op3, size_t op4){
  return vsuxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int32_t * op0, vuint64m1_t op1, vint32mf2_t op2, size_t op3){
  return vsuxei64_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, int32_t * op1, vuint64m1_t op2, vint32mf2_t op3, size_t op4){
  return vsuxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint32_t * op0, vuint64m2_t op1, vuint32m1_t op2, size_t op3){
  return vsuxei64_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, uint32_t * op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vsuxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint32_t * op0, vuint64m4_t op1, vuint32m2_t op2, size_t op3){
  return vsuxei64_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, uint32_t * op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vsuxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint32_t * op0, vuint64m8_t op1, vuint32m4_t op2, size_t op3){
  return vsuxei64_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, uint32_t * op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vsuxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint32_t * op0, vuint64m1_t op1, vuint32mf2_t op2, size_t op3){
  return vsuxei64_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, uint32_t * op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vsuxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int64_t * op0, vuint8mf8_t op1, vint64m1_t op2, size_t op3){
  return vsuxei8_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, int64_t * op1, vuint8mf8_t op2, vint64m1_t op3, size_t op4){
  return vsuxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int64_t * op0, vuint8mf4_t op1, vint64m2_t op2, size_t op3){
  return vsuxei8_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, int64_t * op1, vuint8mf4_t op2, vint64m2_t op3, size_t op4){
  return vsuxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int64_t * op0, vuint8mf2_t op1, vint64m4_t op2, size_t op3){
  return vsuxei8_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, int64_t * op1, vuint8mf2_t op2, vint64m4_t op3, size_t op4){
  return vsuxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int64_t * op0, vuint8m1_t op1, vint64m8_t op2, size_t op3){
  return vsuxei8_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, int64_t * op1, vuint8m1_t op2, vint64m8_t op3, size_t op4){
  return vsuxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint64_t * op0, vuint8mf8_t op1, vuint64m1_t op2, size_t op3){
  return vsuxei8_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, uint64_t * op1, vuint8mf8_t op2, vuint64m1_t op3, size_t op4){
  return vsuxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint64_t * op0, vuint8mf4_t op1, vuint64m2_t op2, size_t op3){
  return vsuxei8_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, uint64_t * op1, vuint8mf4_t op2, vuint64m2_t op3, size_t op4){
  return vsuxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint64_t * op0, vuint8mf2_t op1, vuint64m4_t op2, size_t op3){
  return vsuxei8_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, uint64_t * op1, vuint8mf2_t op2, vuint64m4_t op3, size_t op4){
  return vsuxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint64_t * op0, vuint8m1_t op1, vuint64m8_t op2, size_t op3){
  return vsuxei8_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, uint64_t * op1, vuint8m1_t op2, vuint64m8_t op3, size_t op4){
  return vsuxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int64_t * op0, vuint16mf4_t op1, vint64m1_t op2, size_t op3){
  return vsuxei16_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, int64_t * op1, vuint16mf4_t op2, vint64m1_t op3, size_t op4){
  return vsuxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int64_t * op0, vuint16mf2_t op1, vint64m2_t op2, size_t op3){
  return vsuxei16_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, int64_t * op1, vuint16mf2_t op2, vint64m2_t op3, size_t op4){
  return vsuxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int64_t * op0, vuint16m1_t op1, vint64m4_t op2, size_t op3){
  return vsuxei16_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, int64_t * op1, vuint16m1_t op2, vint64m4_t op3, size_t op4){
  return vsuxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(int64_t * op0, vuint16m2_t op1, vint64m8_t op2, size_t op3){
  return vsuxei16_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, int64_t * op1, vuint16m2_t op2, vint64m8_t op3, size_t op4){
  return vsuxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint64_t * op0, vuint16mf4_t op1, vuint64m1_t op2, size_t op3){
  return vsuxei16_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, uint64_t * op1, vuint16mf4_t op2, vuint64m1_t op3, size_t op4){
  return vsuxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint64_t * op0, vuint16mf2_t op1, vuint64m2_t op2, size_t op3){
  return vsuxei16_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, uint64_t * op1, vuint16mf2_t op2, vuint64m2_t op3, size_t op4){
  return vsuxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint64_t * op0, vuint16m1_t op1, vuint64m4_t op2, size_t op3){
  return vsuxei16_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, uint64_t * op1, vuint16m1_t op2, vuint64m4_t op3, size_t op4){
  return vsuxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(uint64_t * op0, vuint16m2_t op1, vuint64m8_t op2, size_t op3){
  return vsuxei16_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, uint64_t * op1, vuint16m2_t op2, vuint64m8_t op3, size_t op4){
  return vsuxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int64_t * op0, vuint32mf2_t op1, vint64m1_t op2, size_t op3){
  return vsuxei32_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, int64_t * op1, vuint32mf2_t op2, vint64m1_t op3, size_t op4){
  return vsuxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int64_t * op0, vuint32m1_t op1, vint64m2_t op2, size_t op3){
  return vsuxei32_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, int64_t * op1, vuint32m1_t op2, vint64m2_t op3, size_t op4){
  return vsuxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int64_t * op0, vuint32m2_t op1, vint64m4_t op2, size_t op3){
  return vsuxei32_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, int64_t * op1, vuint32m2_t op2, vint64m4_t op3, size_t op4){
  return vsuxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(int64_t * op0, vuint32m4_t op1, vint64m8_t op2, size_t op3){
  return vsuxei32_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, int64_t * op1, vuint32m4_t op2, vint64m8_t op3, size_t op4){
  return vsuxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint64_t * op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3){
  return vsuxei32_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, uint64_t * op1, vuint32mf2_t op2, vuint64m1_t op3, size_t op4){
  return vsuxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint64_t * op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3){
  return vsuxei32_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, uint64_t * op1, vuint32m1_t op2, vuint64m2_t op3, size_t op4){
  return vsuxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint64_t * op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3){
  return vsuxei32_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, uint64_t * op1, vuint32m2_t op2, vuint64m4_t op3, size_t op4){
  return vsuxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(uint64_t * op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3){
  return vsuxei32_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, uint64_t * op1, vuint32m4_t op2, vuint64m8_t op3, size_t op4){
  return vsuxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int64_t * op0, vuint64m1_t op1, vint64m1_t op2, size_t op3){
  return vsuxei64_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, int64_t * op1, vuint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsuxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int64_t * op0, vuint64m2_t op1, vint64m2_t op2, size_t op3){
  return vsuxei64_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, int64_t * op1, vuint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsuxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int64_t * op0, vuint64m4_t op1, vint64m4_t op2, size_t op3){
  return vsuxei64_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, int64_t * op1, vuint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsuxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(int64_t * op0, vuint64m8_t op1, vint64m8_t op2, size_t op3){
  return vsuxei64_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, int64_t * op1, vuint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsuxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint64_t * op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vsuxei64_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, uint64_t * op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsuxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint64_t * op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vsuxei64_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, uint64_t * op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsuxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint64_t * op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vsuxei64_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, uint64_t * op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsuxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(uint64_t * op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vsuxei64_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, uint64_t * op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsuxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m1_t op1, size_t op2){
  return vse8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool8_t op0, int8_t * op1, vint8m1_t op2, size_t op3){
  return vse8_v_i8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m2_t op1, size_t op2){
  return vse8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool4_t op0, int8_t * op1, vint8m2_t op2, size_t op3){
  return vse8_v_i8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m4_t op1, size_t op2){
  return vse8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool2_t op0, int8_t * op1, vint8m4_t op2, size_t op3){
  return vse8_v_i8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8m8_t op1, size_t op2){
  return vse8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool1_t op0, int8_t * op1, vint8m8_t op2, size_t op3){
  return vse8_v_i8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf2_t op1, size_t op2){
  return vse8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool16_t op0, int8_t * op1, vint8mf2_t op2, size_t op3){
  return vse8_v_i8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf4_t op1, size_t op2){
  return vse8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool32_t op0, int8_t * op1, vint8mf4_t op2, size_t op3){
  return vse8_v_i8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(int8_t * op0, vint8mf8_t op1, size_t op2){
  return vse8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool64_t op0, int8_t * op1, vint8mf8_t op2, size_t op3){
  return vse8_v_i8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8m1_t op1, vint8m1_t op2, size_t op3){
  return vsoxei8_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, int8_t * op1, vuint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsoxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8m2_t op1, vint8m2_t op2, size_t op3){
  return vsoxei8_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, int8_t * op1, vuint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsoxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8m4_t op1, vint8m4_t op2, size_t op3){
  return vsoxei8_v_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool2_t op0, int8_t * op1, vuint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsoxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8m8_t op1, vint8m8_t op2, size_t op3){
  return vsoxei8_v_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool1_t op0, int8_t * op1, vuint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsoxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vsoxei8_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, int8_t * op1, vuint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsoxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vsoxei8_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, int8_t * op1, vuint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsoxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int8_t * op0, vuint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vsoxei8_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, int8_t * op1, vuint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsoxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vsoxei8_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, uint8_t * op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsoxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vsoxei8_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, uint8_t * op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsoxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vsoxei8_v_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool2_t op0, uint8_t * op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsoxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vsoxei8_v_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool1_t op0, uint8_t * op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsoxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vsoxei8_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, uint8_t * op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsoxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vsoxei8_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, uint8_t * op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsoxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint8_t * op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vsoxei8_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, uint8_t * op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsoxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16m2_t op1, vint8m1_t op2, size_t op3){
  return vsoxei16_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, int8_t * op1, vuint16m2_t op2, vint8m1_t op3, size_t op4){
  return vsoxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16m4_t op1, vint8m2_t op2, size_t op3){
  return vsoxei16_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, int8_t * op1, vuint16m4_t op2, vint8m2_t op3, size_t op4){
  return vsoxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16m8_t op1, vint8m4_t op2, size_t op3){
  return vsoxei16_v_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool2_t op0, int8_t * op1, vuint16m8_t op2, vint8m4_t op3, size_t op4){
  return vsoxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16m1_t op1, vint8mf2_t op2, size_t op3){
  return vsoxei16_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, int8_t * op1, vuint16m1_t op2, vint8mf2_t op3, size_t op4){
  return vsoxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16mf2_t op1, vint8mf4_t op2, size_t op3){
  return vsoxei16_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, int8_t * op1, vuint16mf2_t op2, vint8mf4_t op3, size_t op4){
  return vsoxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int8_t * op0, vuint16mf4_t op1, vint8mf8_t op2, size_t op3){
  return vsoxei16_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, int8_t * op1, vuint16mf4_t op2, vint8mf8_t op3, size_t op4){
  return vsoxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16m2_t op1, vuint8m1_t op2, size_t op3){
  return vsoxei16_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, uint8_t * op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vsoxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16m4_t op1, vuint8m2_t op2, size_t op3){
  return vsoxei16_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, uint8_t * op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vsoxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16m8_t op1, vuint8m4_t op2, size_t op3){
  return vsoxei16_v_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool2_t op0, uint8_t * op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vsoxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16m1_t op1, vuint8mf2_t op2, size_t op3){
  return vsoxei16_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, uint8_t * op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vsoxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16mf2_t op1, vuint8mf4_t op2, size_t op3){
  return vsoxei16_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, uint8_t * op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vsoxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint8_t * op0, vuint16mf4_t op1, vuint8mf8_t op2, size_t op3){
  return vsoxei16_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, uint8_t * op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vsoxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int8_t * op0, vuint32m4_t op1, vint8m1_t op2, size_t op3){
  return vsoxei32_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, int8_t * op1, vuint32m4_t op2, vint8m1_t op3, size_t op4){
  return vsoxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int8_t * op0, vuint32m8_t op1, vint8m2_t op2, size_t op3){
  return vsoxei32_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, int8_t * op1, vuint32m8_t op2, vint8m2_t op3, size_t op4){
  return vsoxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int8_t * op0, vuint32m2_t op1, vint8mf2_t op2, size_t op3){
  return vsoxei32_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, int8_t * op1, vuint32m2_t op2, vint8mf2_t op3, size_t op4){
  return vsoxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int8_t * op0, vuint32m1_t op1, vint8mf4_t op2, size_t op3){
  return vsoxei32_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, int8_t * op1, vuint32m1_t op2, vint8mf4_t op3, size_t op4){
  return vsoxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int8_t * op0, vuint32mf2_t op1, vint8mf8_t op2, size_t op3){
  return vsoxei32_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, int8_t * op1, vuint32mf2_t op2, vint8mf8_t op3, size_t op4){
  return vsoxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vse8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool8_t op0, uint8_t * op1, vuint8m1_t op2, size_t op3){
  return vse8_v_u8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vse8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool4_t op0, uint8_t * op1, vuint8m2_t op2, size_t op3){
  return vse8_v_u8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vse8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool2_t op0, uint8_t * op1, vuint8m4_t op2, size_t op3){
  return vse8_v_u8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vse8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool1_t op0, uint8_t * op1, vuint8m8_t op2, size_t op3){
  return vse8_v_u8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vse8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool16_t op0, uint8_t * op1, vuint8mf2_t op2, size_t op3){
  return vse8_v_u8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vse8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool32_t op0, uint8_t * op1, vuint8mf4_t op2, size_t op3){
  return vse8_v_u8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse8(uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vse8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded void vse8(vbool64_t op0, uint8_t * op1, vuint8mf8_t op2, size_t op3){
  return vse8_v_u8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(uint8_t * op0, vuint32m4_t op1, vuint8m1_t op2, size_t op3){
  return vsoxei32_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, uint8_t * op1, vuint32m4_t op2, vuint8m1_t op3, size_t op4){
  return vsoxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint8_t * op0, vuint32m8_t op1, vuint8m2_t op2, size_t op3){
  return vsoxei32_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, uint8_t * op1, vuint32m8_t op2, vuint8m2_t op3, size_t op4){
  return vsoxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint8_t * op0, vuint32m2_t op1, vuint8mf2_t op2, size_t op3){
  return vsoxei32_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, uint8_t * op1, vuint32m2_t op2, vuint8mf2_t op3, size_t op4){
  return vsoxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint8_t * op0, vuint32m1_t op1, vuint8mf4_t op2, size_t op3){
  return vsoxei32_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, uint8_t * op1, vuint32m1_t op2, vuint8mf4_t op3, size_t op4){
  return vsoxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint8_t * op0, vuint32mf2_t op1, vuint8mf8_t op2, size_t op3){
  return vsoxei32_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, uint8_t * op1, vuint32mf2_t op2, vuint8mf8_t op3, size_t op4){
  return vsoxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int8_t * op0, vuint64m8_t op1, vint8m1_t op2, size_t op3){
  return vsoxei64_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, int8_t * op1, vuint64m8_t op2, vint8m1_t op3, size_t op4){
  return vsoxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int8_t * op0, vuint64m4_t op1, vint8mf2_t op2, size_t op3){
  return vsoxei64_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, int8_t * op1, vuint64m4_t op2, vint8mf2_t op3, size_t op4){
  return vsoxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int8_t * op0, vuint64m2_t op1, vint8mf4_t op2, size_t op3){
  return vsoxei64_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, int8_t * op1, vuint64m2_t op2, vint8mf4_t op3, size_t op4){
  return vsoxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int8_t * op0, vuint64m1_t op1, vint8mf8_t op2, size_t op3){
  return vsoxei64_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, int8_t * op1, vuint64m1_t op2, vint8mf8_t op3, size_t op4){
  return vsoxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint8_t * op0, vuint64m8_t op1, vuint8m1_t op2, size_t op3){
  return vsoxei64_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, uint8_t * op1, vuint64m8_t op2, vuint8m1_t op3, size_t op4){
  return vsoxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint8_t * op0, vuint64m4_t op1, vuint8mf2_t op2, size_t op3){
  return vsoxei64_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, uint8_t * op1, vuint64m4_t op2, vuint8mf2_t op3, size_t op4){
  return vsoxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint8_t * op0, vuint64m2_t op1, vuint8mf4_t op2, size_t op3){
  return vsoxei64_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, uint8_t * op1, vuint64m2_t op2, vuint8mf4_t op3, size_t op4){
  return vsoxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint8_t * op0, vuint64m1_t op1, vuint8mf8_t op2, size_t op3){
  return vsoxei64_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, uint8_t * op1, vuint64m1_t op2, vuint8mf8_t op3, size_t op4){
  return vsoxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8mf2_t op1, vint16m1_t op2, size_t op3){
  return vsoxei8_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, int16_t * op1, vuint8mf2_t op2, vint16m1_t op3, size_t op4){
  return vsoxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8m1_t op1, vint16m2_t op2, size_t op3){
  return vsoxei8_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, int16_t * op1, vuint8m1_t op2, vint16m2_t op3, size_t op4){
  return vsoxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8m2_t op1, vint16m4_t op2, size_t op3){
  return vsoxei8_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, int16_t * op1, vuint8m2_t op2, vint16m4_t op3, size_t op4){
  return vsoxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8m4_t op1, vint16m8_t op2, size_t op3){
  return vsoxei8_v_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool2_t op0, int16_t * op1, vuint8m4_t op2, vint16m8_t op3, size_t op4){
  return vsoxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8mf4_t op1, vint16mf2_t op2, size_t op3){
  return vsoxei8_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, int16_t * op1, vuint8mf4_t op2, vint16mf2_t op3, size_t op4){
  return vsoxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int16_t * op0, vuint8mf8_t op1, vint16mf4_t op2, size_t op3){
  return vsoxei8_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, int16_t * op1, vuint8mf8_t op2, vint16mf4_t op3, size_t op4){
  return vsoxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3){
  return vsoxei8_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, uint16_t * op1, vuint8mf2_t op2, vuint16m1_t op3, size_t op4){
  return vsoxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3){
  return vsoxei8_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, uint16_t * op1, vuint8m1_t op2, vuint16m2_t op3, size_t op4){
  return vsoxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3){
  return vsoxei8_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, uint16_t * op1, vuint8m2_t op2, vuint16m4_t op3, size_t op4){
  return vsoxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3){
  return vsoxei8_v_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool2_t op0, uint16_t * op1, vuint8m4_t op2, vuint16m8_t op3, size_t op4){
  return vsoxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3){
  return vsoxei8_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, uint16_t * op1, vuint8mf4_t op2, vuint16mf2_t op3, size_t op4){
  return vsoxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint16_t * op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3){
  return vsoxei8_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, uint16_t * op1, vuint8mf8_t op2, vuint16mf4_t op3, size_t op4){
  return vsoxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16m1_t op1, vint16m1_t op2, size_t op3){
  return vsoxei16_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, int16_t * op1, vuint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsoxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16m2_t op1, vint16m2_t op2, size_t op3){
  return vsoxei16_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, int16_t * op1, vuint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsoxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16m4_t op1, vint16m4_t op2, size_t op3){
  return vsoxei16_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, int16_t * op1, vuint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsoxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16m8_t op1, vint16m8_t op2, size_t op3){
  return vsoxei16_v_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool2_t op0, int16_t * op1, vuint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsoxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vsoxei16_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, int16_t * op1, vuint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsoxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int16_t * op0, vuint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vsoxei16_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, int16_t * op1, vuint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsoxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vsoxei16_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, uint16_t * op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsoxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vsoxei16_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, uint16_t * op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsoxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vsoxei16_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, uint16_t * op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsoxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vsoxei16_v_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool2_t op0, uint16_t * op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsoxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vsoxei16_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, uint16_t * op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsoxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint16_t * op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vsoxei16_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, uint16_t * op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsoxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int16_t * op0, vuint32m2_t op1, vint16m1_t op2, size_t op3){
  return vsoxei32_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, int16_t * op1, vuint32m2_t op2, vint16m1_t op3, size_t op4){
  return vsoxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int16_t * op0, vuint32m4_t op1, vint16m2_t op2, size_t op3){
  return vsoxei32_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, int16_t * op1, vuint32m4_t op2, vint16m2_t op3, size_t op4){
  return vsoxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int16_t * op0, vuint32m8_t op1, vint16m4_t op2, size_t op3){
  return vsoxei32_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, int16_t * op1, vuint32m8_t op2, vint16m4_t op3, size_t op4){
  return vsoxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int16_t * op0, vuint32m1_t op1, vint16mf2_t op2, size_t op3){
  return vsoxei32_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, int16_t * op1, vuint32m1_t op2, vint16mf2_t op3, size_t op4){
  return vsoxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int16_t * op0, vuint32mf2_t op1, vint16mf4_t op2, size_t op3){
  return vsoxei32_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, int16_t * op1, vuint32mf2_t op2, vint16mf4_t op3, size_t op4){
  return vsoxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint16_t * op0, vuint32m2_t op1, vuint16m1_t op2, size_t op3){
  return vsoxei32_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, uint16_t * op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vsoxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint16_t * op0, vuint32m4_t op1, vuint16m2_t op2, size_t op3){
  return vsoxei32_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, uint16_t * op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vsoxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint16_t * op0, vuint32m8_t op1, vuint16m4_t op2, size_t op3){
  return vsoxei32_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, uint16_t * op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vsoxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint16_t * op0, vuint32m1_t op1, vuint16mf2_t op2, size_t op3){
  return vsoxei32_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, uint16_t * op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vsoxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint16_t * op0, vuint32mf2_t op1, vuint16mf4_t op2, size_t op3){
  return vsoxei32_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, uint16_t * op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vsoxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int16_t * op0, vuint64m4_t op1, vint16m1_t op2, size_t op3){
  return vsoxei64_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, int16_t * op1, vuint64m4_t op2, vint16m1_t op3, size_t op4){
  return vsoxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int16_t * op0, vuint64m8_t op1, vint16m2_t op2, size_t op3){
  return vsoxei64_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, int16_t * op1, vuint64m8_t op2, vint16m2_t op3, size_t op4){
  return vsoxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int16_t * op0, vuint64m2_t op1, vint16mf2_t op2, size_t op3){
  return vsoxei64_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, int16_t * op1, vuint64m2_t op2, vint16mf2_t op3, size_t op4){
  return vsoxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int16_t * op0, vuint64m1_t op1, vint16mf4_t op2, size_t op3){
  return vsoxei64_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, int16_t * op1, vuint64m1_t op2, vint16mf4_t op3, size_t op4){
  return vsoxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8m1_t op2, size_t op3){
  return vsse8_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool8_t op0, int8_t * op1, ptrdiff_t op2, vint8m1_t op3, size_t op4){
  return vsse8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8m2_t op2, size_t op3){
  return vsse8_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool4_t op0, int8_t * op1, ptrdiff_t op2, vint8m2_t op3, size_t op4){
  return vsse8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8m4_t op2, size_t op3){
  return vsse8_v_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool2_t op0, int8_t * op1, ptrdiff_t op2, vint8m4_t op3, size_t op4){
  return vsse8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8m8_t op2, size_t op3){
  return vsse8_v_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool1_t op0, int8_t * op1, ptrdiff_t op2, vint8m8_t op3, size_t op4){
  return vsse8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8mf2_t op2, size_t op3){
  return vsse8_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool16_t op0, int8_t * op1, ptrdiff_t op2, vint8mf2_t op3, size_t op4){
  return vsse8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8mf4_t op2, size_t op3){
  return vsse8_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool32_t op0, int8_t * op1, ptrdiff_t op2, vint8mf4_t op3, size_t op4){
  return vsse8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(int8_t * op0, ptrdiff_t op1, vint8mf8_t op2, size_t op3){
  return vsse8_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool64_t op0, int8_t * op1, ptrdiff_t op2, vint8mf8_t op3, size_t op4){
  return vsse8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint16_t * op0, vuint64m4_t op1, vuint16m1_t op2, size_t op3){
  return vsoxei64_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, uint16_t * op1, vuint64m4_t op2, vuint16m1_t op3, size_t op4){
  return vsoxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint16_t * op0, vuint64m8_t op1, vuint16m2_t op2, size_t op3){
  return vsoxei64_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, uint16_t * op1, vuint64m8_t op2, vuint16m2_t op3, size_t op4){
  return vsoxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint16_t * op0, vuint64m2_t op1, vuint16mf2_t op2, size_t op3){
  return vsoxei64_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, uint16_t * op1, vuint64m2_t op2, vuint16mf2_t op3, size_t op4){
  return vsoxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint16_t * op0, vuint64m1_t op1, vuint16mf4_t op2, size_t op3){
  return vsoxei64_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, uint16_t * op1, vuint64m1_t op2, vuint16mf4_t op3, size_t op4){
  return vsoxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int32_t * op0, vuint8mf4_t op1, vint32m1_t op2, size_t op3){
  return vsoxei8_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, int32_t * op1, vuint8mf4_t op2, vint32m1_t op3, size_t op4){
  return vsoxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int32_t * op0, vuint8mf2_t op1, vint32m2_t op2, size_t op3){
  return vsoxei8_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, int32_t * op1, vuint8mf2_t op2, vint32m2_t op3, size_t op4){
  return vsoxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int32_t * op0, vuint8m1_t op1, vint32m4_t op2, size_t op3){
  return vsoxei8_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, int32_t * op1, vuint8m1_t op2, vint32m4_t op3, size_t op4){
  return vsoxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int32_t * op0, vuint8m2_t op1, vint32m8_t op2, size_t op3){
  return vsoxei8_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, int32_t * op1, vuint8m2_t op2, vint32m8_t op3, size_t op4){
  return vsoxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int32_t * op0, vuint8mf8_t op1, vint32mf2_t op2, size_t op3){
  return vsoxei8_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, int32_t * op1, vuint8mf8_t op2, vint32mf2_t op3, size_t op4){
  return vsoxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint32_t * op0, vuint8mf4_t op1, vuint32m1_t op2, size_t op3){
  return vsoxei8_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, uint32_t * op1, vuint8mf4_t op2, vuint32m1_t op3, size_t op4){
  return vsoxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint32_t * op0, vuint8mf2_t op1, vuint32m2_t op2, size_t op3){
  return vsoxei8_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, uint32_t * op1, vuint8mf2_t op2, vuint32m2_t op3, size_t op4){
  return vsoxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint32_t * op0, vuint8m1_t op1, vuint32m4_t op2, size_t op3){
  return vsoxei8_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, uint32_t * op1, vuint8m1_t op2, vuint32m4_t op3, size_t op4){
  return vsoxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint32_t * op0, vuint8m2_t op1, vuint32m8_t op2, size_t op3){
  return vsoxei8_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, uint32_t * op1, vuint8m2_t op2, vuint32m8_t op3, size_t op4){
  return vsoxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint32_t * op0, vuint8mf8_t op1, vuint32mf2_t op2, size_t op3){
  return vsoxei8_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, uint32_t * op1, vuint8mf8_t op2, vuint32mf2_t op3, size_t op4){
  return vsoxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int32_t * op0, vuint16mf2_t op1, vint32m1_t op2, size_t op3){
  return vsoxei16_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, int32_t * op1, vuint16mf2_t op2, vint32m1_t op3, size_t op4){
  return vsoxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int32_t * op0, vuint16m1_t op1, vint32m2_t op2, size_t op3){
  return vsoxei16_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, int32_t * op1, vuint16m1_t op2, vint32m2_t op3, size_t op4){
  return vsoxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int32_t * op0, vuint16m2_t op1, vint32m4_t op2, size_t op3){
  return vsoxei16_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, int32_t * op1, vuint16m2_t op2, vint32m4_t op3, size_t op4){
  return vsoxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int32_t * op0, vuint16m4_t op1, vint32m8_t op2, size_t op3){
  return vsoxei16_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, int32_t * op1, vuint16m4_t op2, vint32m8_t op3, size_t op4){
  return vsoxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int32_t * op0, vuint16mf4_t op1, vint32mf2_t op2, size_t op3){
  return vsoxei16_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, int32_t * op1, vuint16mf4_t op2, vint32mf2_t op3, size_t op4){
  return vsoxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint32_t * op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3){
  return vsoxei16_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, uint32_t * op1, vuint16mf2_t op2, vuint32m1_t op3, size_t op4){
  return vsoxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint32_t * op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3){
  return vsoxei16_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, uint32_t * op1, vuint16m1_t op2, vuint32m2_t op3, size_t op4){
  return vsoxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint32_t * op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3){
  return vsoxei16_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, uint32_t * op1, vuint16m2_t op2, vuint32m4_t op3, size_t op4){
  return vsoxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint32_t * op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3){
  return vsoxei16_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, uint32_t * op1, vuint16m4_t op2, vuint32m8_t op3, size_t op4){
  return vsoxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint32_t * op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3){
  return vsoxei16_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, uint32_t * op1, vuint16mf4_t op2, vuint32mf2_t op3, size_t op4){
  return vsoxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int32_t * op0, vuint32m1_t op1, vint32m1_t op2, size_t op3){
  return vsoxei32_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, int32_t * op1, vuint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsoxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int32_t * op0, vuint32m2_t op1, vint32m2_t op2, size_t op3){
  return vsoxei32_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, int32_t * op1, vuint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsoxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int32_t * op0, vuint32m4_t op1, vint32m4_t op2, size_t op3){
  return vsoxei32_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, int32_t * op1, vuint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsoxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int32_t * op0, vuint32m8_t op1, vint32m8_t op2, size_t op3){
  return vsoxei32_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, int32_t * op1, vuint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsoxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int32_t * op0, vuint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vsoxei32_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, int32_t * op1, vuint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsoxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint32_t * op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vsoxei32_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, uint32_t * op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsoxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint32_t * op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vsoxei32_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, uint32_t * op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsoxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint32_t * op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vsoxei32_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, uint32_t * op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsoxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint32_t * op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vsoxei32_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, uint32_t * op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsoxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint32_t * op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vsoxei32_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, uint32_t * op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsoxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int32_t * op0, vuint64m2_t op1, vint32m1_t op2, size_t op3){
  return vsoxei64_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, int32_t * op1, vuint64m2_t op2, vint32m1_t op3, size_t op4){
  return vsoxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int32_t * op0, vuint64m4_t op1, vint32m2_t op2, size_t op3){
  return vsoxei64_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, int32_t * op1, vuint64m4_t op2, vint32m2_t op3, size_t op4){
  return vsoxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int32_t * op0, vuint64m8_t op1, vint32m4_t op2, size_t op3){
  return vsoxei64_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, int32_t * op1, vuint64m8_t op2, vint32m4_t op3, size_t op4){
  return vsoxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int32_t * op0, vuint64m1_t op1, vint32mf2_t op2, size_t op3){
  return vsoxei64_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, int32_t * op1, vuint64m1_t op2, vint32mf2_t op3, size_t op4){
  return vsoxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint32_t * op0, vuint64m2_t op1, vuint32m1_t op2, size_t op3){
  return vsoxei64_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, uint32_t * op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vsoxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint32_t * op0, vuint64m4_t op1, vuint32m2_t op2, size_t op3){
  return vsoxei64_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, uint32_t * op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vsoxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint32_t * op0, vuint64m8_t op1, vuint32m4_t op2, size_t op3){
  return vsoxei64_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, uint32_t * op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vsoxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint32_t * op0, vuint64m1_t op1, vuint32mf2_t op2, size_t op3){
  return vsoxei64_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, uint32_t * op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vsoxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int64_t * op0, vuint8mf8_t op1, vint64m1_t op2, size_t op3){
  return vsoxei8_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, int64_t * op1, vuint8mf8_t op2, vint64m1_t op3, size_t op4){
  return vsoxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int64_t * op0, vuint8mf4_t op1, vint64m2_t op2, size_t op3){
  return vsoxei8_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, int64_t * op1, vuint8mf4_t op2, vint64m2_t op3, size_t op4){
  return vsoxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int64_t * op0, vuint8mf2_t op1, vint64m4_t op2, size_t op3){
  return vsoxei8_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, int64_t * op1, vuint8mf2_t op2, vint64m4_t op3, size_t op4){
  return vsoxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(int64_t * op0, vuint8m1_t op1, vint64m8_t op2, size_t op3){
  return vsoxei8_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, int64_t * op1, vuint8m1_t op2, vint64m8_t op3, size_t op4){
  return vsoxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwaddu_wv(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vwaddu_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwaddu_wv(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vwaddu_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwaddu_wv(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vwaddu_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwaddu_wv(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vwaddu_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwaddu_wv(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vwaddu_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwaddu_wv(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vwaddu_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwaddu_wv(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vwaddu_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwaddu_wv(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vwaddu_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwaddu_wv(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vwaddu_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwaddu_wv(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vwaddu_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwaddu_wv(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vwaddu_wv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwaddu_wv(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vwaddu_wv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwaddu_wv(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vwaddu_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwaddu_wv(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vwaddu_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwaddu_wv(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vwaddu_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwaddu_wv(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vwaddu_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwaddu_wv(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vwaddu_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwaddu_wv(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vwaddu_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwaddu_wv(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vwaddu_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwaddu_wv(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vwaddu_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwaddu_wv(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vwaddu_wv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwaddu_wv(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vwaddu_wv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwaddu_wv(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vwaddu_wv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwaddu_wv(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vwaddu_wv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwaddu_wv(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vwaddu_wv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwaddu_wv(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vwaddu_wv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwaddu_wv(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vwaddu_wv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwaddu_wv(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vwaddu_wv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwaddu_wv(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vwaddu_wv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwaddu_wv(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vwaddu_wv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8m1_t op2, size_t op3){
  return vsse8_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool8_t op0, uint8_t * op1, ptrdiff_t op2, vuint8m1_t op3, size_t op4){
  return vsse8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8m2_t op2, size_t op3){
  return vsse8_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool4_t op0, uint8_t * op1, ptrdiff_t op2, vuint8m2_t op3, size_t op4){
  return vsse8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8m4_t op2, size_t op3){
  return vsse8_v_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool2_t op0, uint8_t * op1, ptrdiff_t op2, vuint8m4_t op3, size_t op4){
  return vsse8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8m8_t op2, size_t op3){
  return vsse8_v_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool1_t op0, uint8_t * op1, ptrdiff_t op2, vuint8m8_t op3, size_t op4){
  return vsse8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8mf2_t op2, size_t op3){
  return vsse8_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool16_t op0, uint8_t * op1, ptrdiff_t op2, vuint8mf2_t op3, size_t op4){
  return vsse8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8mf4_t op2, size_t op3){
  return vsse8_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool32_t op0, uint8_t * op1, ptrdiff_t op2, vuint8mf4_t op3, size_t op4){
  return vsse8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse8(uint8_t * op0, ptrdiff_t op1, vuint8mf8_t op2, size_t op3){
  return vsse8_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse8(vbool64_t op0, uint8_t * op1, ptrdiff_t op2, vuint8mf8_t op3, size_t op4){
  return vsse8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint64_t * op0, vuint8mf8_t op1, vuint64m1_t op2, size_t op3){
  return vsoxei8_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, uint64_t * op1, vuint8mf8_t op2, vuint64m1_t op3, size_t op4){
  return vsoxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint64_t * op0, vuint8mf4_t op1, vuint64m2_t op2, size_t op3){
  return vsoxei8_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, uint64_t * op1, vuint8mf4_t op2, vuint64m2_t op3, size_t op4){
  return vsoxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint64_t * op0, vuint8mf2_t op1, vuint64m4_t op2, size_t op3){
  return vsoxei8_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, uint64_t * op1, vuint8mf2_t op2, vuint64m4_t op3, size_t op4){
  return vsoxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(uint64_t * op0, vuint8m1_t op1, vuint64m8_t op2, size_t op3){
  return vsoxei8_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, uint64_t * op1, vuint8m1_t op2, vuint64m8_t op3, size_t op4){
  return vsoxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int64_t * op0, vuint16mf4_t op1, vint64m1_t op2, size_t op3){
  return vsoxei16_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, int64_t * op1, vuint16mf4_t op2, vint64m1_t op3, size_t op4){
  return vsoxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int64_t * op0, vuint16mf2_t op1, vint64m2_t op2, size_t op3){
  return vsoxei16_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, int64_t * op1, vuint16mf2_t op2, vint64m2_t op3, size_t op4){
  return vsoxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int64_t * op0, vuint16m1_t op1, vint64m4_t op2, size_t op3){
  return vsoxei16_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, int64_t * op1, vuint16m1_t op2, vint64m4_t op3, size_t op4){
  return vsoxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(int64_t * op0, vuint16m2_t op1, vint64m8_t op2, size_t op3){
  return vsoxei16_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, int64_t * op1, vuint16m2_t op2, vint64m8_t op3, size_t op4){
  return vsoxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint64_t * op0, vuint16mf4_t op1, vuint64m1_t op2, size_t op3){
  return vsoxei16_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, uint64_t * op1, vuint16mf4_t op2, vuint64m1_t op3, size_t op4){
  return vsoxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint64_t * op0, vuint16mf2_t op1, vuint64m2_t op2, size_t op3){
  return vsoxei16_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, uint64_t * op1, vuint16mf2_t op2, vuint64m2_t op3, size_t op4){
  return vsoxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint64_t * op0, vuint16m1_t op1, vuint64m4_t op2, size_t op3){
  return vsoxei16_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, uint64_t * op1, vuint16m1_t op2, vuint64m4_t op3, size_t op4){
  return vsoxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(uint64_t * op0, vuint16m2_t op1, vuint64m8_t op2, size_t op3){
  return vsoxei16_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, uint64_t * op1, vuint16m2_t op2, vuint64m8_t op3, size_t op4){
  return vsoxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int64_t * op0, vuint32mf2_t op1, vint64m1_t op2, size_t op3){
  return vsoxei32_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, int64_t * op1, vuint32mf2_t op2, vint64m1_t op3, size_t op4){
  return vsoxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int64_t * op0, vuint32m1_t op1, vint64m2_t op2, size_t op3){
  return vsoxei32_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, int64_t * op1, vuint32m1_t op2, vint64m2_t op3, size_t op4){
  return vsoxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int64_t * op0, vuint32m2_t op1, vint64m4_t op2, size_t op3){
  return vsoxei32_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, int64_t * op1, vuint32m2_t op2, vint64m4_t op3, size_t op4){
  return vsoxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(int64_t * op0, vuint32m4_t op1, vint64m8_t op2, size_t op3){
  return vsoxei32_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, int64_t * op1, vuint32m4_t op2, vint64m8_t op3, size_t op4){
  return vsoxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint64_t * op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3){
  return vsoxei32_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, uint64_t * op1, vuint32mf2_t op2, vuint64m1_t op3, size_t op4){
  return vsoxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint64_t * op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3){
  return vsoxei32_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, uint64_t * op1, vuint32m1_t op2, vuint64m2_t op3, size_t op4){
  return vsoxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint64_t * op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3){
  return vsoxei32_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, uint64_t * op1, vuint32m2_t op2, vuint64m4_t op3, size_t op4){
  return vsoxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(uint64_t * op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3){
  return vsoxei32_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, uint64_t * op1, vuint32m4_t op2, vuint64m8_t op3, size_t op4){
  return vsoxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int64_t * op0, vuint64m1_t op1, vint64m1_t op2, size_t op3){
  return vsoxei64_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, int64_t * op1, vuint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsoxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int64_t * op0, vuint64m2_t op1, vint64m2_t op2, size_t op3){
  return vsoxei64_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, int64_t * op1, vuint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsoxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int64_t * op0, vuint64m4_t op1, vint64m4_t op2, size_t op3){
  return vsoxei64_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, int64_t * op1, vuint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsoxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(int64_t * op0, vuint64m8_t op1, vint64m8_t op2, size_t op3){
  return vsoxei64_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, int64_t * op1, vuint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsoxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint64_t * op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vsoxei64_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, uint64_t * op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsoxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint64_t * op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vsoxei64_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, uint64_t * op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsoxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint64_t * op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vsoxei64_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, uint64_t * op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsoxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(uint64_t * op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vsoxei64_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, uint64_t * op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsoxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8m1_t op1, vint8m1_t op2, size_t op3){
  return vsuxei8_v_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, int8_t * op1, vuint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsuxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8m2_t op1, vint8m2_t op2, size_t op3){
  return vsuxei8_v_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, int8_t * op1, vuint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsuxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8m4_t op1, vint8m4_t op2, size_t op3){
  return vsuxei8_v_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool2_t op0, int8_t * op1, vuint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsuxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8m8_t op1, vint8m8_t op2, size_t op3){
  return vsuxei8_v_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool1_t op0, int8_t * op1, vuint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsuxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vsuxei8_v_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, int8_t * op1, vuint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsuxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vsuxei8_v_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, int8_t * op1, vuint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsuxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(int8_t * op0, vuint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vsuxei8_v_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, int8_t * op1, vuint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsuxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vle16ff(vbool16_t op0, vint16m1_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vle16ff(vbool8_t op0, vint16m2_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vle16ff(vbool4_t op0, vint16m4_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vle16ff(vbool2_t op0, vint16m8_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vle16ff(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vle16ff(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vle16ff(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vle16ff(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vle16ff(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vle16ff(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vle16ff(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vle16ff(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, size_t * op3, size_t op4){
  return vle16ff_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vle32ff(vbool32_t op0, vint32m1_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vle32ff(vbool16_t op0, vint32m2_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vle32ff(vbool8_t op0, vint32m4_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vle32ff(vbool4_t op0, vint32m8_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vle32ff(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vle32ff(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vle32ff(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vle32ff(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vle32ff(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vle32ff(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, size_t * op3, size_t op4){
  return vle32ff_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vsuxei8_v_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, uint8_t * op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsuxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vsuxei8_v_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, uint8_t * op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsuxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vsuxei8_v_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool2_t op0, uint8_t * op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsuxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vsuxei8_v_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool1_t op0, uint8_t * op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsuxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vsuxei8_v_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, uint8_t * op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsuxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vsuxei8_v_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, uint8_t * op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsuxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(uint8_t * op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vsuxei8_v_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, uint8_t * op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsuxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vle64ff(vbool64_t op0, vint64m1_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vle64ff(vbool32_t op0, vint64m2_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vle64ff(vbool16_t op0, vint64m4_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vle64ff(vbool8_t op0, vint64m8_t op1, const int64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vle64ff(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vle64ff(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vle64ff(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vle64ff(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, size_t * op3, size_t op4){
  return vle64ff_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vadd(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vadd_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vadd_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vadd(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vadd_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vadd_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vadd(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vadd_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vadd_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vadd(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vadd_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vadd_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vadd(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vadd_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vadd_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vadd(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vadd_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vadd_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vadd(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vadd_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vadd_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vadd(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vadd_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vadd_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vadd(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vadd_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vadd_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vadd(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vadd_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vadd_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vadd(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vadd_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vadd_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vadd(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vadd_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vadd_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vadd(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vadd_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vadd_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vadd(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vadd_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vadd_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vadd(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vadd_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vadd_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vadd(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vadd_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vadd_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vadd(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vadd_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vadd_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vadd(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vadd_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vadd_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vadd(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vadd_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vadd_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vadd(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vadd_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vadd_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vadd(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vadd_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vadd_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vadd(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vadd_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vadd_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vadd(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vadd(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vadd(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vadd(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vadd(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vadd(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vadd(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vadd_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vadd_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vadd(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vadd(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vadd(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vadd(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vadd(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vadd(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vadd_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vadd_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vadd(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vadd(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vadd(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vadd(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vadd(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vadd_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vadd_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vadd(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vadd(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vadd(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vadd(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vadd_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vadd_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsub(vint8m1_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsub(vint8m2_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsub(vint8m4_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsub(vint8m8_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsub(vint16m1_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsub(vint16m2_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsub(vint16m4_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsub(vint16m8_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsub(vint32m1_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsub(vint32m2_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsub(vint32m4_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsub(vint32m8_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsub(vint64m1_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsub(vint64m2_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsub(vint64m4_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsub(vint64m8_t op0, int64_t op1, size_t op2){
  return vsub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsub(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsub_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsub_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsub(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsub_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsub_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsub(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsub_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsub_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsub(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsub_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsub_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsub(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsub_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsub_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsub(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsub_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsub_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsub(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsub_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsub_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsub(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsub_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsub_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsub(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsub_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsub_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsub(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsub_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsub_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsub(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsub_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsub_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsub(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsub_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsub_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsub(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsub_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsub_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsub(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsub_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsub_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsub(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsub_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsub_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsub(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsub_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsub_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsub(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsub_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsub_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsub(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsub_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsub_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsub(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsub_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsub_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsub(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsub_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsub_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsub(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsub_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsub_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsub(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsub_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsub_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsub(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsub(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsub(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsub(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsub(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsub(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsub(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vsub_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsub(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsub(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsub(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsub(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsub(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsub(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vsub_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsub(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsub(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsub(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsub(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsub(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vsub_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsub(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsub(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsub(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsub(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vsub_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vle16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vle16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vle16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vle16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vle16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vle16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, size_t op3){
  return vle16_v_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vrsub(vint8m1_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrsub(vint8m2_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrsub(vint8m4_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrsub(vint8m8_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrsub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrsub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrsub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vrsub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vrsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrsub(vint16m1_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrsub(vint16m2_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrsub(vint16m4_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrsub(vint16m8_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrsub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrsub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vrsub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vrsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrsub(vint32m1_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrsub(vint32m2_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrsub(vint32m4_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrsub(vint32m8_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrsub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vrsub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vrsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrsub(vint64m1_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrsub(vint64m2_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrsub(vint64m4_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrsub(vint64m8_t op0, int64_t op1, size_t op2){
  return vrsub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vrsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vrsub(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vrsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vrsub(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vrsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vrsub(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vrsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vrsub(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vrsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vrsub(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vrsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vrsub(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vrsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vrsub(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vrsub_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vrsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vrsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vrsub(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vrsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vrsub(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vrsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vrsub(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vrsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vrsub(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vrsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vrsub(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vrsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vrsub(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vrsub_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vrsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vrsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vrsub(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vrsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vrsub(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vrsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vrsub(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vrsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vrsub(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vrsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vrsub(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vrsub_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vrsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vrsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vrsub(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vrsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vrsub(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vrsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vrsub(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vrsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vrsub(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vrsub_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vrsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vrsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwaddu_vx(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwaddu_vx(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwaddu_vx(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwaddu_vx(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwaddu_vx(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwaddu_vx(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwaddu_vx(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwaddu_vx(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwaddu_vx(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwaddu_vx(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwaddu_vx(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vwaddu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwaddu_vx(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vwaddu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwaddu_vx(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vwaddu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwaddu_vx(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vwaddu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwaddu_vx(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vwaddu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwaddu_vx(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vwaddu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwaddu_vx(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vwaddu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwaddu_vx(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vwaddu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwaddu_vx(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vwaddu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwaddu_vx(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vwaddu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwaddu_vx(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vwaddu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwaddu_vx(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vwaddu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwaddu_vx(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vwaddu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwaddu_vx(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vwaddu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwaddu_vx(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vwaddu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwaddu_vx(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vwaddu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwaddu_vx(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vwaddu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwaddu_vx(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vwaddu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwaddu_vx(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vwaddu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwaddu_vx(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vwaddu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwsubu_vv(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwsubu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwsubu_vv(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwsubu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwsubu_vv(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwsubu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwsubu_vv(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwsubu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwsubu_vv(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwsubu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwsubu_vv(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwsubu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwsubu_vv(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwsubu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwsubu_vv(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwsubu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwsubu_vv(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwsubu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwsubu_vv(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwsubu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwsubu_vv(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwsubu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwsubu_vv(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwsubu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwsubu_vv(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwsubu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwsubu_vv(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwsubu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwsubu_vv(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwsubu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwsubu_vv(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwsubu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwsubu_vv(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwsubu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwsubu_vv(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwsubu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwsubu_vv(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwsubu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwsubu_vv(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwsubu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwsubu_vv(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwsubu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwsubu_vv(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwsubu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwsubu_vv(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwsubu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwsubu_vv(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwsubu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwsubu_vv(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwsubu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwsubu_vv(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwsubu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwsubu_vv(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwsubu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwsubu_vv(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwsubu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwsubu_vv(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwsubu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwsubu_vv(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwsubu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwsubu_vx(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwsubu_vx(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwsubu_vx(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwsubu_vx(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwsubu_vx(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwsubu_vx(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwsubu_vx(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwsubu_vx(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwsubu_vx(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwsubu_vx(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwsubu_vx(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vwsubu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwsubu_vx(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vwsubu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwsubu_vx(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vwsubu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwsubu_vx(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vwsubu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwsubu_vx(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vwsubu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwsubu_vx(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vwsubu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwsubu_vx(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vwsubu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwsubu_vx(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vwsubu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwsubu_vx(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vwsubu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwsubu_vx(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vwsubu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwsubu_vx(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vwsubu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwsubu_vx(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vwsubu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwsubu_vx(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vwsubu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwsubu_vx(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vwsubu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwsubu_vx(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vwsubu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwsubu_vx(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vwsubu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwsubu_vx(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vwsubu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwsubu_vx(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vwsubu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwsubu_vx(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vwsubu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwsubu_vx(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vwsubu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwadd_vv(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vwadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwadd_vv(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwadd_vv(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vwadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwadd_vv(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwadd_vv(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vwadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwadd_vv(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwadd_vv(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vwadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwadd_vv(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwadd_vv(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vwadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwadd_vv(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwadd_vv(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vwadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwadd_vv(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwadd_vv(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vwadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwadd_vv(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwadd_vv(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vwadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwadd_vv(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwadd_vv(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vwadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwadd_vv(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwadd_vv(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vwadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwadd_vv(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwadd_vv(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vwadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwadd_vv(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwadd_vv(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vwadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwadd_vv(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwadd_vv(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vwadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwadd_vv(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwadd_vv(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vwadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwadd_vv(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwadd_vv(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vwadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwadd_vv(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwadd_vx(vint8mf8_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwadd_vx(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwadd_vx(vint8mf4_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwadd_vx(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwadd_vx(vint8mf2_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwadd_vx(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwadd_vx(vint8m1_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwadd_vx(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwadd_vx(vint8m2_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwadd_vx(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwadd_vx(vint8m4_t op0, int8_t op1, size_t op2){
  return vwadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwadd_vx(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vwadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwadd_vx(vint16mf4_t op0, int16_t op1, size_t op2){
  return vwadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwadd_vx(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vwadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwadd_vx(vint16mf2_t op0, int16_t op1, size_t op2){
  return vwadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwadd_vx(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vwadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwadd_vx(vint16m1_t op0, int16_t op1, size_t op2){
  return vwadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwadd_vx(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vwadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwadd_vx(vint16m2_t op0, int16_t op1, size_t op2){
  return vwadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwadd_vx(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vwadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwadd_vx(vint16m4_t op0, int16_t op1, size_t op2){
  return vwadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwadd_vx(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vwadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwadd_vx(vint32mf2_t op0, int32_t op1, size_t op2){
  return vwadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwadd_vx(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vwadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwadd_vx(vint32m1_t op0, int32_t op1, size_t op2){
  return vwadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwadd_vx(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vwadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwadd_vx(vint32m2_t op0, int32_t op1, size_t op2){
  return vwadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwadd_vx(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vwadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwadd_vx(vint32m4_t op0, int32_t op1, size_t op2){
  return vwadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwadd_vx(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vwadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwsub_vv(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vwsub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwsub_vv(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwsub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwsub_vv(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vwsub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwsub_vv(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwsub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwsub_vv(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vwsub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwsub_vv(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwsub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwsub_vv(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vwsub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwsub_vv(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwsub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwsub_vv(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vwsub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwsub_vv(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwsub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwsub_vv(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vwsub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwsub_vv(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwsub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwsub_vv(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vwsub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwsub_vv(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwsub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwsub_vv(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vwsub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwsub_vv(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwsub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwsub_vv(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vwsub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwsub_vv(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwsub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwsub_vv(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vwsub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwsub_vv(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwsub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwsub_vv(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vwsub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwsub_vv(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwsub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwsub_vv(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vwsub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwsub_vv(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwsub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwsub_vv(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vwsub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwsub_vv(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwsub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwsub_vv(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vwsub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwsub_vv(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwsub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwsub_vv(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vwsub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwsub_vv(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwsub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwsub_vx(vint8mf8_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwsub_vx(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwsub_vx(vint8mf4_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwsub_vx(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwsub_vx(vint8mf2_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwsub_vx(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwsub_vx(vint8m1_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwsub_vx(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwsub_vx(vint8m2_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwsub_vx(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwsub_vx(vint8m4_t op0, int8_t op1, size_t op2){
  return vwsub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwsub_vx(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vwsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwsub_vx(vint16mf4_t op0, int16_t op1, size_t op2){
  return vwsub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwsub_vx(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vwsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwsub_vx(vint16mf2_t op0, int16_t op1, size_t op2){
  return vwsub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwsub_vx(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vwsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwsub_vx(vint16m1_t op0, int16_t op1, size_t op2){
  return vwsub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwsub_vx(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vwsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwsub_vx(vint16m2_t op0, int16_t op1, size_t op2){
  return vwsub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwsub_vx(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vwsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwsub_vx(vint16m4_t op0, int16_t op1, size_t op2){
  return vwsub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwsub_vx(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vwsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwsub_vx(vint32mf2_t op0, int32_t op1, size_t op2){
  return vwsub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwsub_vx(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vwsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwsub_vx(vint32m1_t op0, int32_t op1, size_t op2){
  return vwsub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwsub_vx(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vwsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwsub_vx(vint32m2_t op0, int32_t op1, size_t op2){
  return vwsub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwsub_vx(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vwsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwsub_vx(vint32m4_t op0, int32_t op1, size_t op2){
  return vwsub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwsub_vx(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vwsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwaddu_wx(vuint16mf4_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwaddu_wx(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwaddu_wx(vuint16mf2_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwaddu_wx(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwaddu_wx(vuint16m1_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwaddu_wx(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwaddu_wx(vuint16m2_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwaddu_wx(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwaddu_wx(vuint16m4_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwaddu_wx(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwaddu_wx(vuint16m8_t op0, uint8_t op1, size_t op2){
  return vwaddu_wx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwaddu_wx(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint8_t op3, size_t op4){
  return vwaddu_wx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwaddu_wx(vuint32mf2_t op0, uint16_t op1, size_t op2){
  return vwaddu_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwaddu_wx(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint16_t op3, size_t op4){
  return vwaddu_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwaddu_wx(vuint32m1_t op0, uint16_t op1, size_t op2){
  return vwaddu_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwaddu_wx(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint16_t op3, size_t op4){
  return vwaddu_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwaddu_wx(vuint32m2_t op0, uint16_t op1, size_t op2){
  return vwaddu_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwaddu_wx(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint16_t op3, size_t op4){
  return vwaddu_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwaddu_wx(vuint32m4_t op0, uint16_t op1, size_t op2){
  return vwaddu_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwaddu_wx(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint16_t op3, size_t op4){
  return vwaddu_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwaddu_wx(vuint32m8_t op0, uint16_t op1, size_t op2){
  return vwaddu_wx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwaddu_wx(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint16_t op3, size_t op4){
  return vwaddu_wx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwaddu_wx(vuint64m1_t op0, uint32_t op1, size_t op2){
  return vwaddu_wx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwaddu_wx(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint32_t op3, size_t op4){
  return vwaddu_wx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwaddu_wx(vuint64m2_t op0, uint32_t op1, size_t op2){
  return vwaddu_wx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwaddu_wx(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint32_t op3, size_t op4){
  return vwaddu_wx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwaddu_wx(vuint64m4_t op0, uint32_t op1, size_t op2){
  return vwaddu_wx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwaddu_wx(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint32_t op3, size_t op4){
  return vwaddu_wx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwaddu_wx(vuint64m8_t op0, uint32_t op1, size_t op2){
  return vwaddu_wx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwaddu_wx(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint32_t op3, size_t op4){
  return vwaddu_wx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vle16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vle16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vle16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vle16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vle16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vle16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, size_t op3){
  return vle16_v_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwsubu_wv(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vwsubu_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwsubu_wv(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vwsubu_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwsubu_wv(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vwsubu_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwsubu_wv(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vwsubu_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwsubu_wv(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vwsubu_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwsubu_wv(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vwsubu_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwsubu_wv(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vwsubu_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwsubu_wv(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vwsubu_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwsubu_wv(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vwsubu_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwsubu_wv(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vwsubu_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwsubu_wv(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vwsubu_wv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwsubu_wv(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vwsubu_wv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwsubu_wv(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vwsubu_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwsubu_wv(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vwsubu_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwsubu_wv(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vwsubu_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwsubu_wv(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vwsubu_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwsubu_wv(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vwsubu_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwsubu_wv(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vwsubu_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwsubu_wv(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vwsubu_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwsubu_wv(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vwsubu_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwsubu_wv(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vwsubu_wv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwsubu_wv(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vwsubu_wv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwsubu_wv(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vwsubu_wv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwsubu_wv(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vwsubu_wv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwsubu_wv(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vwsubu_wv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwsubu_wv(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vwsubu_wv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwsubu_wv(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vwsubu_wv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwsubu_wv(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vwsubu_wv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwsubu_wv(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vwsubu_wv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwsubu_wv(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vwsubu_wv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwsubu_wx(vuint16mf4_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwsubu_wx(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwsubu_wx(vuint16mf2_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwsubu_wx(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwsubu_wx(vuint16m1_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwsubu_wx(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwsubu_wx(vuint16m2_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwsubu_wx(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwsubu_wx(vuint16m4_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwsubu_wx(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwsubu_wx(vuint16m8_t op0, uint8_t op1, size_t op2){
  return vwsubu_wx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwsubu_wx(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint8_t op3, size_t op4){
  return vwsubu_wx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwsubu_wx(vuint32mf2_t op0, uint16_t op1, size_t op2){
  return vwsubu_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwsubu_wx(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint16_t op3, size_t op4){
  return vwsubu_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwsubu_wx(vuint32m1_t op0, uint16_t op1, size_t op2){
  return vwsubu_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwsubu_wx(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint16_t op3, size_t op4){
  return vwsubu_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwsubu_wx(vuint32m2_t op0, uint16_t op1, size_t op2){
  return vwsubu_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwsubu_wx(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint16_t op3, size_t op4){
  return vwsubu_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwsubu_wx(vuint32m4_t op0, uint16_t op1, size_t op2){
  return vwsubu_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwsubu_wx(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint16_t op3, size_t op4){
  return vwsubu_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwsubu_wx(vuint32m8_t op0, uint16_t op1, size_t op2){
  return vwsubu_wx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwsubu_wx(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint16_t op3, size_t op4){
  return vwsubu_wx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwsubu_wx(vuint64m1_t op0, uint32_t op1, size_t op2){
  return vwsubu_wx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwsubu_wx(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint32_t op3, size_t op4){
  return vwsubu_wx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwsubu_wx(vuint64m2_t op0, uint32_t op1, size_t op2){
  return vwsubu_wx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwsubu_wx(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint32_t op3, size_t op4){
  return vwsubu_wx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwsubu_wx(vuint64m4_t op0, uint32_t op1, size_t op2){
  return vwsubu_wx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwsubu_wx(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint32_t op3, size_t op4){
  return vwsubu_wx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwsubu_wx(vuint64m8_t op0, uint32_t op1, size_t op2){
  return vwsubu_wx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwsubu_wx(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint32_t op3, size_t op4){
  return vwsubu_wx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwadd_wv(vint16mf4_t op0, vint8mf8_t op1, size_t op2){
  return vwadd_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwadd_wv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint8mf8_t op3, size_t op4){
  return vwadd_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwadd_wv(vint16mf2_t op0, vint8mf4_t op1, size_t op2){
  return vwadd_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwadd_wv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint8mf4_t op3, size_t op4){
  return vwadd_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwadd_wv(vint16m1_t op0, vint8mf2_t op1, size_t op2){
  return vwadd_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwadd_wv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint8mf2_t op3, size_t op4){
  return vwadd_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwadd_wv(vint16m2_t op0, vint8m1_t op1, size_t op2){
  return vwadd_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwadd_wv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint8m1_t op3, size_t op4){
  return vwadd_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwadd_wv(vint16m4_t op0, vint8m2_t op1, size_t op2){
  return vwadd_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwadd_wv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint8m2_t op3, size_t op4){
  return vwadd_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwadd_wv(vint16m8_t op0, vint8m4_t op1, size_t op2){
  return vwadd_wv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwadd_wv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint8m4_t op3, size_t op4){
  return vwadd_wv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwadd_wv(vint32mf2_t op0, vint16mf4_t op1, size_t op2){
  return vwadd_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwadd_wv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint16mf4_t op3, size_t op4){
  return vwadd_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwadd_wv(vint32m1_t op0, vint16mf2_t op1, size_t op2){
  return vwadd_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwadd_wv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint16mf2_t op3, size_t op4){
  return vwadd_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwadd_wv(vint32m2_t op0, vint16m1_t op1, size_t op2){
  return vwadd_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwadd_wv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint16m1_t op3, size_t op4){
  return vwadd_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwadd_wv(vint32m4_t op0, vint16m2_t op1, size_t op2){
  return vwadd_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwadd_wv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint16m2_t op3, size_t op4){
  return vwadd_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwadd_wv(vint32m8_t op0, vint16m4_t op1, size_t op2){
  return vwadd_wv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwadd_wv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint16m4_t op3, size_t op4){
  return vwadd_wv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwadd_wv(vint64m1_t op0, vint32mf2_t op1, size_t op2){
  return vwadd_wv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwadd_wv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint32mf2_t op3, size_t op4){
  return vwadd_wv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwadd_wv(vint64m2_t op0, vint32m1_t op1, size_t op2){
  return vwadd_wv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwadd_wv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint32m1_t op3, size_t op4){
  return vwadd_wv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwadd_wv(vint64m4_t op0, vint32m2_t op1, size_t op2){
  return vwadd_wv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwadd_wv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint32m2_t op3, size_t op4){
  return vwadd_wv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwadd_wv(vint64m8_t op0, vint32m4_t op1, size_t op2){
  return vwadd_wv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwadd_wv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint32m4_t op3, size_t op4){
  return vwadd_wv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwadd_wx(vint16mf4_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwadd_wx(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwadd_wx(vint16mf2_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwadd_wx(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwadd_wx(vint16m1_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwadd_wx(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwadd_wx(vint16m2_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwadd_wx(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwadd_wx(vint16m4_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwadd_wx(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwadd_wx(vint16m8_t op0, int8_t op1, size_t op2){
  return vwadd_wx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwadd_wx(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int8_t op3, size_t op4){
  return vwadd_wx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwadd_wx(vint32mf2_t op0, int16_t op1, size_t op2){
  return vwadd_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwadd_wx(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int16_t op3, size_t op4){
  return vwadd_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwadd_wx(vint32m1_t op0, int16_t op1, size_t op2){
  return vwadd_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwadd_wx(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int16_t op3, size_t op4){
  return vwadd_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwadd_wx(vint32m2_t op0, int16_t op1, size_t op2){
  return vwadd_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwadd_wx(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int16_t op3, size_t op4){
  return vwadd_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwadd_wx(vint32m4_t op0, int16_t op1, size_t op2){
  return vwadd_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwadd_wx(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int16_t op3, size_t op4){
  return vwadd_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwadd_wx(vint32m8_t op0, int16_t op1, size_t op2){
  return vwadd_wx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwadd_wx(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int16_t op3, size_t op4){
  return vwadd_wx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwadd_wx(vint64m1_t op0, int32_t op1, size_t op2){
  return vwadd_wx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwadd_wx(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int32_t op3, size_t op4){
  return vwadd_wx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwadd_wx(vint64m2_t op0, int32_t op1, size_t op2){
  return vwadd_wx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwadd_wx(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int32_t op3, size_t op4){
  return vwadd_wx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwadd_wx(vint64m4_t op0, int32_t op1, size_t op2){
  return vwadd_wx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwadd_wx(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int32_t op3, size_t op4){
  return vwadd_wx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwadd_wx(vint64m8_t op0, int32_t op1, size_t op2){
  return vwadd_wx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwadd_wx(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int32_t op3, size_t op4){
  return vwadd_wx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwsub_wv(vint16mf4_t op0, vint8mf8_t op1, size_t op2){
  return vwsub_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwsub_wv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint8mf8_t op3, size_t op4){
  return vwsub_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwsub_wv(vint16mf2_t op0, vint8mf4_t op1, size_t op2){
  return vwsub_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwsub_wv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint8mf4_t op3, size_t op4){
  return vwsub_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwsub_wv(vint16m1_t op0, vint8mf2_t op1, size_t op2){
  return vwsub_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwsub_wv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint8mf2_t op3, size_t op4){
  return vwsub_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwsub_wv(vint16m2_t op0, vint8m1_t op1, size_t op2){
  return vwsub_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwsub_wv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint8m1_t op3, size_t op4){
  return vwsub_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwsub_wv(vint16m4_t op0, vint8m2_t op1, size_t op2){
  return vwsub_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwsub_wv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint8m2_t op3, size_t op4){
  return vwsub_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwsub_wv(vint16m8_t op0, vint8m4_t op1, size_t op2){
  return vwsub_wv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwsub_wv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint8m4_t op3, size_t op4){
  return vwsub_wv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwsub_wv(vint32mf2_t op0, vint16mf4_t op1, size_t op2){
  return vwsub_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwsub_wv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint16mf4_t op3, size_t op4){
  return vwsub_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwsub_wv(vint32m1_t op0, vint16mf2_t op1, size_t op2){
  return vwsub_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwsub_wv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint16mf2_t op3, size_t op4){
  return vwsub_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwsub_wv(vint32m2_t op0, vint16m1_t op1, size_t op2){
  return vwsub_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwsub_wv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint16m1_t op3, size_t op4){
  return vwsub_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwsub_wv(vint32m4_t op0, vint16m2_t op1, size_t op2){
  return vwsub_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwsub_wv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint16m2_t op3, size_t op4){
  return vwsub_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwsub_wv(vint32m8_t op0, vint16m4_t op1, size_t op2){
  return vwsub_wv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwsub_wv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint16m4_t op3, size_t op4){
  return vwsub_wv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwsub_wv(vint64m1_t op0, vint32mf2_t op1, size_t op2){
  return vwsub_wv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwsub_wv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint32mf2_t op3, size_t op4){
  return vwsub_wv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwsub_wv(vint64m2_t op0, vint32m1_t op1, size_t op2){
  return vwsub_wv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwsub_wv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint32m1_t op3, size_t op4){
  return vwsub_wv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwsub_wv(vint64m4_t op0, vint32m2_t op1, size_t op2){
  return vwsub_wv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwsub_wv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint32m2_t op3, size_t op4){
  return vwsub_wv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwsub_wv(vint64m8_t op0, vint32m4_t op1, size_t op2){
  return vwsub_wv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwsub_wv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint32m4_t op3, size_t op4){
  return vwsub_wv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwsub_wx(vint16mf4_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwsub_wx(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwsub_wx(vint16mf2_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwsub_wx(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwsub_wx(vint16m1_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwsub_wx(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwsub_wx(vint16m2_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwsub_wx(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwsub_wx(vint16m4_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwsub_wx(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwsub_wx(vint16m8_t op0, int8_t op1, size_t op2){
  return vwsub_wx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwsub_wx(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int8_t op3, size_t op4){
  return vwsub_wx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwsub_wx(vint32mf2_t op0, int16_t op1, size_t op2){
  return vwsub_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwsub_wx(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int16_t op3, size_t op4){
  return vwsub_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwsub_wx(vint32m1_t op0, int16_t op1, size_t op2){
  return vwsub_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwsub_wx(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int16_t op3, size_t op4){
  return vwsub_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwsub_wx(vint32m2_t op0, int16_t op1, size_t op2){
  return vwsub_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwsub_wx(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int16_t op3, size_t op4){
  return vwsub_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwsub_wx(vint32m4_t op0, int16_t op1, size_t op2){
  return vwsub_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwsub_wx(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int16_t op3, size_t op4){
  return vwsub_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwsub_wx(vint32m8_t op0, int16_t op1, size_t op2){
  return vwsub_wx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwsub_wx(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int16_t op3, size_t op4){
  return vwsub_wx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwsub_wx(vint64m1_t op0, int32_t op1, size_t op2){
  return vwsub_wx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwsub_wx(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int32_t op3, size_t op4){
  return vwsub_wx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwsub_wx(vint64m2_t op0, int32_t op1, size_t op2){
  return vwsub_wx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwsub_wx(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int32_t op3, size_t op4){
  return vwsub_wx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwsub_wx(vint64m4_t op0, int32_t op1, size_t op2){
  return vwsub_wx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwsub_wx(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int32_t op3, size_t op4){
  return vwsub_wx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwsub_wx(vint64m8_t op0, int32_t op1, size_t op2){
  return vwsub_wx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwsub_wx(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int32_t op3, size_t op4){
  return vwsub_wx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vadc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vadc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vadc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vadc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vadc_vvm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vadc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vadc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vadc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vadc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vadc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vadc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vadc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vadc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vadc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vadc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vadc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vadc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vadc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vadc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vadc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vadc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vadc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vadc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vadc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vadc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vadc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vadc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vadc_vxm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vadc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vadc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vadc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vadc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vadc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vadc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vadc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vadc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vadc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vadc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vadc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vadc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vadc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vadc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vadc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vadc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vadc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vadc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vadc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vadc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vadc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vadc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vadc_vvm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vadc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vadc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vadc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vadc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vadc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vadc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vadc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vadc_vvm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vadc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vadc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vadc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vadc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vadc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vadc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vadc_vvm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vadc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vadc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vadc_vvm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vadc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vadc_vvm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vadc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vadc_vvm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vadc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vadc_vvm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vadc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vadc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vadc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vadc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vadc_vxm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vadc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vadc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vadc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vadc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vadc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vadc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vadc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vadc_vxm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vadc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vadc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vadc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vadc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vadc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vadc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vadc_vxm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vadc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vadc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vadc_vxm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vadc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vadc_vxm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vadc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vadc_vxm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vadc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vadc_vxm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vle32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vle32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vle32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vle32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vle32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, size_t op3){
  return vle32_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vvm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vxm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vvm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vvm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vvm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vmadc_vvm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vmadc_vvm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vmadc_vvm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vvm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vmadc_vxm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vmadc_vxm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vmadc_vxm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vmadc_vxm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vmadc_vxm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vmadc_vxm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vmadc_vxm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmadc_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmadc_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmadc_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmadc_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmadc_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmadc_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmadc_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmadc_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmadc_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmadc_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmadc_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmadc_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmadc_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmadc_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmadc_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmadc_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmadc_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmadc_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmadc_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmadc_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmadc_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmadc_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint8m1_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint8m2_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint8m4_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vint8m8_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmadc_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint16m1_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint16m2_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint16m4_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vint16m8_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmadc_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint32m1_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint32m2_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint32m4_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vint32m8_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmadc_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vint64m1_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vint64m2_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vint64m4_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vint64m8_t op0, int64_t op1, size_t op2){
  return vmadc_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmadc_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmadc_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmadc_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmadc_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmadc_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmadc_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmadc_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmadc_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmadc_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmadc_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmadc_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmadc_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmadc_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmadc_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmadc_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmadc_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmadc_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmadc_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmadc_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmadc_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmadc_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmadc_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmadc(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmadc_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmadc(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmadc_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmadc(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmadc_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmadc(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmadc(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmadc(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmadc(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmadc_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsbc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vsbc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vsbc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vsbc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vvm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vsbc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vsbc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vsbc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsbc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsbc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsbc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsbc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsbc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vsbc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsbc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsbc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsbc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsbc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsbc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsbc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsbc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsbc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsbc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vsbc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vsbc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vsbc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vsbc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vxm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vsbc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vsbc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vsbc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsbc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsbc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsbc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsbc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsbc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vsbc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsbc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsbc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsbc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsbc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsbc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsbc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsbc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsbc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsbc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vle32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vle32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vle32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vle32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vle32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, size_t op3){
  return vle32_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vsbc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vsbc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vsbc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vsbc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vvm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vsbc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vsbc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vsbc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vsbc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vsbc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vsbc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vsbc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vvm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vsbc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vsbc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vsbc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vsbc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vsbc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vsbc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vvm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vsbc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vsbc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vsbc_vvm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vsbc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vsbc_vvm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vsbc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vsbc_vvm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vsbc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vvm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vsbc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vsbc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vsbc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vsbc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vsbc_vxm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vsbc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vsbc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vsbc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vsbc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vsbc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vsbc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vsbc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vsbc_vxm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vsbc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vsbc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vsbc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vsbc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vsbc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vsbc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vsbc_vxm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vsbc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vsbc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vsbc_vxm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vsbc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vsbc_vxm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vsbc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vsbc_vxm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vsbc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vsbc_vxm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, vint8m1_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, vint8m2_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, vint8m4_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, vint8m8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vvm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, vint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, vint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, vint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, vint16m1_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, vint16m2_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, vint16m4_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, vint16m8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, vint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, vint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, vint32m1_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, vint32m2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, vint32m4_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, vint32m8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, vint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, vint64m1_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, vint64m2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, vint64m4_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, vint64m8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, int8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, int8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, int8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_i8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, int8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vxm_i8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, int8_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, int8_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, int8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, int16_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, int16_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, int16_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, int16_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_i16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, int16_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, int16_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, int32_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, int32_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, int32_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, int32_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_i32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, int32_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, int64_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_i64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, int64_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_i64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, int64_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_i64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, int64_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_i64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vvm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vvm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vvm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vvm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vvm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vvm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vvm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, uint8_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u8m1_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, uint8_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u8m2_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, uint8_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_u8m4_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, uint8_t op1, vbool1_t op2, size_t op3){
  return vmsbc_vxm_u8m8_b1(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, uint8_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u8mf2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, uint8_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u8mf4_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, uint8_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u8mf8_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, uint16_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u16m1_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, uint16_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u16m2_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, uint16_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u16m4_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, uint16_t op1, vbool2_t op2, size_t op3){
  return vmsbc_vxm_u16m8_b2(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, uint16_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u16mf2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, uint16_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u16mf4_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, uint32_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u32m1_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, uint32_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u32m2_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, uint32_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u32m4_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, uint32_t op1, vbool4_t op2, size_t op3){
  return vmsbc_vxm_u32m8_b4(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, uint32_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u32mf2_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, uint64_t op1, vbool64_t op2, size_t op3){
  return vmsbc_vxm_u64m1_b64(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, uint64_t op1, vbool32_t op2, size_t op3){
  return vmsbc_vxm_u64m2_b32(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, uint64_t op1, vbool16_t op2, size_t op3){
  return vmsbc_vxm_u64m4_b16(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, uint64_t op1, vbool8_t op2, size_t op3){
  return vmsbc_vxm_u64m8_b8(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsbc_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsbc_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsbc_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsbc_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsbc_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsbc_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsbc_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsbc_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsbc_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsbc_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsbc_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsbc_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsbc_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsbc_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsbc_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsbc_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsbc_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsbc_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsbc_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsbc_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsbc_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsbc_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsbc_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsbc_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsbc_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsbc_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsbc_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsbc_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsbc_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsbc_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsbc_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsbc_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsbc_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsbc_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsbc_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsbc_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsbc_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsbc_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsbc_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsbc_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsbc_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsbc_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsbc_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsbc_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsbc_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsbc_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsbc_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsbc_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsbc(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsbc_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsbc(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsbc_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsbc(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsbc_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsbc(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsbc(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsbc(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbc(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsbc_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vand_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vand_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vand(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vand_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vand(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vand_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vand(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vand_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vand(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vand_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vand(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vand_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vand(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vand_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vand(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vand_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vand(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vand_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vand(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vand_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vand(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vand_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vand(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vand_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vand(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vand_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vand(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vand_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vand(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vand_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vand(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vand_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vand(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vand_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vand(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vand_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vand(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vand_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vand(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vand_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vand(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vand_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vand(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vand_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vand(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vand_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vand(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vand_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vand(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vand_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vand(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vand_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vand(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vand_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vand(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vand_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vand(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vand_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vand(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vand_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vand(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vand_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vand(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vand_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vand(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vand_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vand(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vand_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vand(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vand_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vand(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vand_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vand(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vand_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vand(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vand_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vand(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vand_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vand(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vand_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vand(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vand_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vand(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vand_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vand(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vand_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vand(vint8m1_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vand(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vand(vint8m2_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vand(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vand(vint8m4_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vand(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vand(vint8m8_t op0, int8_t op1, size_t op2){
  return vand_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vand(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vand_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vand(vint8mf2_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vand(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vand(vint8mf4_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vand(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vand(vint8mf8_t op0, int8_t op1, size_t op2){
  return vand_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vand(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vand_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vand(vint16m1_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vand(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vand(vint16m2_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vand(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vand(vint16m4_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vand(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vand(vint16m8_t op0, int16_t op1, size_t op2){
  return vand_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vand(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vand_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vand(vint16mf2_t op0, int16_t op1, size_t op2){
  return vand_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vand(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vand_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vand(vint16mf4_t op0, int16_t op1, size_t op2){
  return vand_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vand(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vand_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vand(vint32m1_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vand(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vand(vint32m2_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vand(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vand(vint32m4_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vand(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vand(vint32m8_t op0, int32_t op1, size_t op2){
  return vand_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vand(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vand_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vand(vint32mf2_t op0, int32_t op1, size_t op2){
  return vand_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vand(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vand_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vand(vint64m1_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vand(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vand(vint64m2_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vand(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vand(vint64m4_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vand(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vand(vint64m8_t op0, int64_t op1, size_t op2){
  return vand_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vand(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vand_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vand(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vand_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vand(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vand_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vand(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vand_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vand(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vand_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vand(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vand_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vand(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vand_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vand(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vand_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vand(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vand_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vand(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vand_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vand(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vand_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vand(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vand_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vand(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vand_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vand(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vand_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vand(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vand_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vand(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vand_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vand(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vand_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vand(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vand_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vand(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vand_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vand(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vand_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vand(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vand_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vand(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vand_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vand(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vand_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vand(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vand_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vand(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vand_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vand(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vand_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vand(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vand_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vand(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vand_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vand(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vand_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vand(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vand_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vand(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vand_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vand(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vand_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vand(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vand_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vand(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vand_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vand(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vand_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vand(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vand_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vand(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vand_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vand(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vand_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vand(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vand_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vand(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vand_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vand(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vand_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vand(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vand_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vand(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vand_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vand(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vand_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vand(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vand_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vand(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vand(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vand(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vand(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vand(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vand(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vand(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vand(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vand(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vand(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vand(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vand(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vand(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vand_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vand(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vand_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vand(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vand(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vand(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vand(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vand(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vand(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vand(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vand(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vand(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vand(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vand(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vand_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vand(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vand_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vand(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vand(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vand(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vand(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vand(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vand(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vand(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vand(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vand(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vand_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vand(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vand_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vand(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vand(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vand(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vand(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vand(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vand(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vand(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vand_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vand(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vand_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vxor(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vxor_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vxor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vxor_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vxor(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vxor_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vxor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vxor_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vxor(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vxor_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vxor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vxor_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vxor(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vxor_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vxor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vxor_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vxor(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vxor_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vxor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vxor_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vxor(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vxor_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vxor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vxor_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vxor(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vxor_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vxor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vxor_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vxor(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vxor_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vxor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vxor_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vxor(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vxor_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vxor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vxor_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vxor(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vxor_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vxor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vxor_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vxor(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vxor_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vxor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vxor_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vxor(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vxor_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vxor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vxor_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vxor(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vxor_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vxor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vxor_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vxor(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vxor_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vxor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vxor_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vxor(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vxor_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vxor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vxor_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vxor(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vxor_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vxor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vxor_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vxor(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vxor_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vxor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vxor_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vxor(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vxor_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vxor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vxor_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vxor(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vxor_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vxor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vxor_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vxor(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vxor_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vxor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vxor_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vxor(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vxor_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vxor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vxor_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vxor(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vxor_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vxor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vxor_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vxor(vint8m1_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vxor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vxor(vint8m2_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vxor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vxor(vint8m4_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vxor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vxor(vint8m8_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vxor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vxor(vint8mf2_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vxor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vxor(vint8mf4_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vxor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vxor(vint8mf8_t op0, int8_t op1, size_t op2){
  return vxor_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vxor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vxor_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vxor(vint16m1_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vxor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vxor(vint16m2_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vxor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vxor(vint16m4_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vxor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vxor(vint16m8_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vxor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vxor(vint16mf2_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vxor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vxor(vint16mf4_t op0, int16_t op1, size_t op2){
  return vxor_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vxor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vxor_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vxor(vint32m1_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vxor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vxor(vint32m2_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vxor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vxor(vint32m4_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vxor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vxor(vint32m8_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vxor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vxor(vint32mf2_t op0, int32_t op1, size_t op2){
  return vxor_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vxor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vxor_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vxor(vint64m1_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vxor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vxor(vint64m2_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vxor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vxor(vint64m4_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vxor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vxor(vint64m8_t op0, int64_t op1, size_t op2){
  return vxor_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vxor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vxor_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vxor(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vxor_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vxor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vxor_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vxor(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vxor_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vxor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vxor_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vxor(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vxor_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vxor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vxor_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vxor(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vxor_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vxor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vxor_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vxor(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vxor_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vxor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vxor_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vxor(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vxor_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vxor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vxor_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vxor(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vxor_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vxor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vxor_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vxor(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vxor_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vxor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vxor_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vxor(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vxor_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vxor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vxor_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vxor(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vxor_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vxor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vxor_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vxor(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vxor_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vxor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vxor_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vxor(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vxor_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vxor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vxor_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vxor(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vxor_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vxor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vxor_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vxor(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vxor_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vxor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vxor_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vxor(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vxor_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vxor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vxor_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vxor(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vxor_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vxor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vxor_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vxor(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vxor_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vxor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vxor_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vxor(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vxor_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vxor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vxor_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vxor(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vxor_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vxor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vxor_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vxor(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vxor_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vxor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vxor_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vxor(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vxor_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vxor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vxor_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vxor(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vxor_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vxor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vxor_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vxor(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vxor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vxor(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vxor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vxor(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vxor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vxor(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vxor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vxor(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vxor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vxor(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vxor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vxor(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vxor_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vxor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vxor_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vxor(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vxor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vxor(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vxor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vxor(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vxor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vxor(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vxor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vxor(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vxor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vxor(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vxor_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vxor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vxor_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vxor(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vxor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vxor(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vxor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vxor(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vxor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vxor(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vxor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vxor(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vxor_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vxor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vxor_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vxor(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vxor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vxor(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vxor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vxor(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vxor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vxor(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vxor_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vxor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vxor_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vor(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vor_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vor_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vor(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vor_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vor_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vor(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vor_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vor_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vor(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vor_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vor_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vor(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vor_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vor_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vor(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vor_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vor_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vor(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vor_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vor_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vor(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vor_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vor_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vor(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vor_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vor_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vor(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vor_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vor_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vor(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vor_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vor_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vor(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vor_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vor_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vor(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vor_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vor_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vor(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vor_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vor_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vor(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vor_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vor_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vor(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vor_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vor_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vor(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vor_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vor_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vor(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vor_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vor_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vor(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vor_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vor_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vor(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vor_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vor_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vor(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vor_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vor_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vor(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vor_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vor_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vor(vint8m1_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vor(vint8m2_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vor(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vor(vint8m4_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vor(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vor(vint8m8_t op0, int8_t op1, size_t op2){
  return vor_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vor(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vor_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vor(vint8mf2_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vor(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vor(vint8mf4_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vor(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vor(vint8mf8_t op0, int8_t op1, size_t op2){
  return vor_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vor(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vor_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vor(vint16m1_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vor(vint16m2_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vor(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vor(vint16m4_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vor(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vor(vint16m8_t op0, int16_t op1, size_t op2){
  return vor_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vor(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vor_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vor(vint16mf2_t op0, int16_t op1, size_t op2){
  return vor_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vor(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vor_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vor(vint16mf4_t op0, int16_t op1, size_t op2){
  return vor_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vor(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vor_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vor(vint32m1_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vor(vint32m2_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vor(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vor(vint32m4_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vor(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vor(vint32m8_t op0, int32_t op1, size_t op2){
  return vor_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vor(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vor_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vor(vint32mf2_t op0, int32_t op1, size_t op2){
  return vor_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vor(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vor_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vor(vint64m1_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vor(vint64m2_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vor(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vor(vint64m4_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vor(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vor(vint64m8_t op0, int64_t op1, size_t op2){
  return vor_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vor(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vor_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vle64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vle64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vle64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vle64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, size_t op3){
  return vle64_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vor(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vor_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vor_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vor(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vor_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vor_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vor(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vor_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vor_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vor(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vor_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vor_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vor(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vor_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vor_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vor(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vor_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vor_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vor(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vor_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vor_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vor(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vor_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vor_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vor(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vor_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vor_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vor(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vor_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vor_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vor(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vor_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vor_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vor(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vor_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vor_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vor(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vor_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vor_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vor(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vor_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vor_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vor(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vor_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vor_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vor(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vor_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vor_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vor(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vor_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vor_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vor(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vor_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vor_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vor(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vor_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vor_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vor(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vor_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vor_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vor(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vor_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vor_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vor(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vor_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vor_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vor(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vor(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vor(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vor(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vor(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vor(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vor(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vor(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vor(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vor(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vor(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vor(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vor_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vor(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vor_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vor(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vor(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vor(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vor(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vor(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vor(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vor(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vor(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vor(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vor(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vor_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vor(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vor_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vor(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vor(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vor(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vor(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vor(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vor(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vor(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vor(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vor_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vor(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vor_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vor(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vor(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vor(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vor(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vor(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vor(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vor_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vor(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vor_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsll(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsll_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsll(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsll_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsll(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsll_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsll(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsll_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsll(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsll_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsll(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsll_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsll(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsll_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsll(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsll_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsll(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsll_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsll(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsll_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsll(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsll_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsll(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsll_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsll(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsll_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsll(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsll_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsll(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsll_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsll(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsll_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsll(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsll_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsll(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsll_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsll(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsll_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsll(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsll_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsll(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsll_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsll(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsll_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsll(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsll_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsll(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsll_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsll(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsll_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsll(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsll_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsll(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsll_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsll(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsll_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsll(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsll_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsll(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsll_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsll(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsll_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsll(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsll_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsll(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsll_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsll(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsll_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsll(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsll_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsll(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsll_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsll(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsll_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsll(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsll_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsll(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsll_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsll(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsll_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsll(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsll_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsll(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsll_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsll(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsll_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsll(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsll_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsll(vint8m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsll(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsll(vint8m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsll(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsll(vint8m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsll(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsll(vint8m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsll(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsll(vint8mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsll(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsll(vint8mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsll(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsll(vint8mf8_t op0, size_t op1, size_t op2){
  return vsll_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsll(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vsll_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsll(vint16m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsll(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsll(vint16m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsll(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsll(vint16m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsll(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsll(vint16m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsll(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsll(vint16mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsll(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsll(vint16mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsll(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsll(vint32m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsll(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsll(vint32m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsll(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsll(vint32m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsll(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsll(vint32m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsll(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsll(vint32mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsll(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsll(vint64m1_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsll(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsll(vint64m2_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsll(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsll(vint64m4_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsll(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsll(vint64m8_t op0, size_t op1, size_t op2){
  return vsll_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsll(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vsll_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsll(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsll_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsll(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsll_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsll(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsll_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsll(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsll_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsll(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsll_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsll(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsll_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsll(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsll_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsll(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsll_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsll(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsll_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsll(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsll_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsll(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsll_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsll(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsll_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsll(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsll_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsll(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsll_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsll(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsll_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsll(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsll_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsll(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsll_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsll(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsll_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsll(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsll_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsll(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsll_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsll(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsll_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsll(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsll_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsll(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsll_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsll(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsll_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsll(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsll_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsll(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsll_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsll(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsll_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsll(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsll_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsll(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsll_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsll(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsll_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsll(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsll_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsll(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsll_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsll(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsll_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsll(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsll_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsll(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsll_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsll(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsll_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsll(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsll_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsll(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsll_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsll(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsll_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsll(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsll_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsll(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsll_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsll(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsll_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsll(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsll_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsll(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsll_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsll(vuint8m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsll(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsll(vuint8m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsll(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsll(vuint8m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsll(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsll(vuint8m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsll(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsll(vuint8mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsll(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsll(vuint8mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsll(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsll(vuint8mf8_t op0, size_t op1, size_t op2){
  return vsll_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsll(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vsll_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsll(vuint16m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsll(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsll(vuint16m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsll(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsll(vuint16m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsll(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsll(vuint16m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsll(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsll(vuint16mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsll(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsll(vuint16mf4_t op0, size_t op1, size_t op2){
  return vsll_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsll(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vsll_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsll(vuint32m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsll(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsll(vuint32m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsll(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsll(vuint32m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsll(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsll(vuint32m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsll(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsll(vuint32mf2_t op0, size_t op1, size_t op2){
  return vsll_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsll(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vsll_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsll(vuint64m1_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsll(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsll(vuint64m2_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsll(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsll(vuint64m4_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsll(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsll(vuint64m8_t op0, size_t op1, size_t op2){
  return vsll_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsll(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vsll_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsrl(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsrl_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsrl_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsrl(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsrl_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsrl_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsrl(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsrl_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsrl_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsrl(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsrl_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsrl_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsrl(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsrl_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsrl_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsrl(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsrl_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsrl_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsrl(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsrl_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsrl_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsrl(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsrl_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsrl_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsrl(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsrl_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsrl_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsrl(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsrl_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsrl_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsrl(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsrl_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsrl_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsrl(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsrl_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsrl_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsrl(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsrl_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsrl_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsrl(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsrl_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsrl_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsrl(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsrl_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsrl_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsrl(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsrl_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsrl_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsrl(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsrl_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsrl_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsrl(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsrl_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsrl_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsrl(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsrl_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsrl_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsrl(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsrl_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsrl_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsrl(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsrl_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsrl_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsrl(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsrl_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsrl_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsrl(vuint8m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsrl(vuint8m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsrl(vuint8m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsrl(vuint8m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsrl(vuint8mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsrl(vuint8mf4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsrl(vuint8mf8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vsrl_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vsrl_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsra(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsra_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsra_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsra(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsra_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsra_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsra(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsra_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsra_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsra(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsra_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsra_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsra(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsra_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsra_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsra(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsra_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsra_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsra(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsra_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsra_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsra(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsra_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsra_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsra(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsra_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsra_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsra(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsra_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsra_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsra(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsra_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsra_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsra(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsra_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsra_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsra(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsra_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsra_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsra(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsra_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsra_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsra(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsra_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsra_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsra(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsra_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsra_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsra(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsra_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsra_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsra(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsra_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsra_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsra(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsra_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsra_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsra(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsra_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsra_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsra(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsra_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsra_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsra(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsra_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsra_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsra(vint8m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsra(vint8m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsra(vint8m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsra(vint8m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsra(vint8mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsra(vint8mf4_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsra(vint8mf8_t op0, size_t op1, size_t op2){
  return vsra_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vsra_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsra(vint16m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsra(vint16m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsra(vint16m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsra(vint16m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsra(vint16mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsra(vint16mf4_t op0, size_t op1, size_t op2){
  return vsra_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vsra_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsra(vint32m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsra(vint32m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsra(vint32m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsra(vint32m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsra(vint32mf2_t op0, size_t op1, size_t op2){
  return vsra_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vsra_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsra(vint64m1_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsra(vint64m2_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsra(vint64m4_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsra(vint64m8_t op0, size_t op1, size_t op2){
  return vsra_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vsra_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vle64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vle64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vle64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vle64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, size_t op3){
  return vle64_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnsrl(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnsrl_wv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnsrl(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnsrl_wv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnsrl(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnsrl_wv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnsrl(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnsrl_wv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnsrl(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnsrl_wv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnsrl(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnsrl_wv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnsrl(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnsrl_wv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnsrl(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnsrl_wv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnsrl(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnsrl_wv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnsrl(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnsrl_wv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnsrl(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnsrl_wv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnsrl(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnsrl_wv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnsrl(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnsrl_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnsrl(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnsrl_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnsrl(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnsrl_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnsrl(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnsrl_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnsrl(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnsrl_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnsrl(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnsrl_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnsrl(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnsrl_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnsrl(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnsrl_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnsrl(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnsrl_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnsrl(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnsrl_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnsrl(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnsrl_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnsrl(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnsrl_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnsrl(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnsrl_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnsrl(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnsrl_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnsrl(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnsrl_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnsrl(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnsrl_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnsrl(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnsrl_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnsrl(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnsrl_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnsrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnsrl(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnsrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnsrl(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnsrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnsrl(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnsrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnsrl(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnsrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnsrl(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnsrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnsrl(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnsrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnsrl(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnsrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnsrl(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnsrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnsrl(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnsrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnsrl(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnsrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnsrl(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnsrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnsrl(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnsrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnsrl(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnsrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnsrl(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnsrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vnsrl_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnsrl(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vnsrl_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnsra(vint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnsra_wv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnsra(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnsra_wv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnsra(vint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnsra_wv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnsra(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnsra_wv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnsra(vint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnsra_wv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnsra(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnsra_wv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnsra(vint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnsra_wv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnsra(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnsra_wv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnsra(vint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnsra_wv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnsra(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnsra_wv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnsra(vint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnsra_wv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnsra(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnsra_wv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnsra(vint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnsra_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnsra(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnsra_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnsra(vint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnsra_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnsra(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnsra_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnsra(vint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnsra_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnsra(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnsra_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnsra(vint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnsra_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnsra(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnsra_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnsra(vint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnsra_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnsra(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnsra_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnsra(vint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnsra_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnsra(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnsra_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnsra(vint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnsra_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnsra(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnsra_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnsra(vint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnsra_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnsra(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnsra_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnsra(vint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnsra_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnsra(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnsra_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnsra(vint16m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnsra(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnsra(vint16m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnsra(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnsra(vint16m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnsra(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnsra(vint16m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnsra(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnsra(vint16mf2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnsra(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnsra(vint16mf4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnsra(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnsra(vint32m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnsra(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnsra(vint32m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnsra(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnsra(vint32m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnsra(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnsra(vint32m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnsra(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnsra(vint32mf2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnsra(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnsra(vint64m2_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnsra(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnsra(vint64m4_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnsra(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnsra(vint64m8_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnsra(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnsra(vint64m1_t op0, size_t op1, size_t op2){
  return vnsra_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnsra(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vnsra_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmseq_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmseq_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmseq_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmseq_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmseq_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmseq_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmseq_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmseq_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmseq_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmseq_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmseq_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmseq_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmseq_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmseq_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmseq_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmseq_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmseq_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmseq_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmseq_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmseq_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmseq_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmseq_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmseq_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmseq_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmseq_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmseq_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmseq_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmseq_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmseq_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmseq_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmseq_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmseq_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmseq_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmseq_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmseq_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmseq_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmseq_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmseq_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmseq_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmseq_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmseq_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmseq_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmseq_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmseq_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint8m1_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint8m2_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint8m4_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vint8m8_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmseq_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmseq_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint16m1_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint16m2_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint16m4_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vint16m8_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmseq_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmseq_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint32m1_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint32m2_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint32m4_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vint32m8_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmseq_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmseq_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vint64m1_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vint64m2_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vint64m4_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vint64m8_t op0, int64_t op1, size_t op2){
  return vmseq_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmseq_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmseq_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmseq_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmseq_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmseq_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmseq_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmseq_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmseq_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmseq_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmseq_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmseq_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmseq_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmseq_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmseq_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmseq_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmseq_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmseq_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmseq_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmseq_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmseq_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmseq_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmseq_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmseq_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmseq_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmseq_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmseq_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmseq_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmseq_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmseq_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmseq_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmseq_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmseq_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmseq_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmseq_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmseq_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmseq_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmseq_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmseq_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmseq_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmseq_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmseq_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmseq_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmseq_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmseq_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmseq_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmseq(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmseq(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmseq_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmseq_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmseq(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmseq(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmseq_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmseq_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmseq(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmseq(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmseq_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmseq_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmseq(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmseq(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmseq(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmseq(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmseq(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmseq(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmseq(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmseq_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmseq(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmseq_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsne_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmsne_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsne_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmsne_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsne_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmsne_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsne_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmsne_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsne_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmsne_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsne_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmsne_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsne_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmsne_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsne_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmsne_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsne_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmsne_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsne_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmsne_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsne_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmsne_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsne_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmsne_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsne_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmsne_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsne_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmsne_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsne_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmsne_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsne_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmsne_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsne_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmsne_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsne_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmsne_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsne_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmsne_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsne_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmsne_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsne_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmsne_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsne_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmsne_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsne_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsne_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsne_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsne_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsne_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsne_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsne_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsne_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vle8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vle8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vle8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vle8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vle8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vle8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vle8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, size_t op3){
  return vle8_v_i8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsne(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsne_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsne_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsne_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsne_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsne_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsne_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsne_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsne_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsne_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsne_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsne_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsne_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsne_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsne_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsne_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsne_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsne_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsne_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsne_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsne_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsne_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsne_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsne_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsne_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsne_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsne_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsne_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsne_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsne_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsne_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsne_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsne_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsne_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsne_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsne_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsne_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsne_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsne_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsne_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsne_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsne_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsne_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsne_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsne_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsne(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsne(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsne_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsne_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsne(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsne(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsne_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsne_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsne(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsne(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsne_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsne_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsne(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsne(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsne(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsne(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsne(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsne(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsne(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsne_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsne(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsne_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsltu_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsltu_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsltu_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsltu_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsltu_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsltu_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsltu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsltu_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsltu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsltu_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsltu_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsltu_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsltu_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsltu_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsltu_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsltu_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsltu_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsltu_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsltu_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsltu_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsltu_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsltu_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsltu_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsltu_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsltu_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsltu_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsltu_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsltu_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsltu_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsltu_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsltu_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsltu_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsltu_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsltu_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsltu_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsltu_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsltu_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsltu_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsltu_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsltu_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsltu_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsltu_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsltu_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsltu_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsltu_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsltu_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsltu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsltu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsltu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsltu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsltu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsltu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsltu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsltu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsltu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsltu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsltu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsltu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsltu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsltu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsltu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsltu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsltu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsltu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsltu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsltu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsltu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsltu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmslt_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmslt_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmslt_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmslt_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmslt_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmslt_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmslt(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmslt_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmslt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmslt_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmslt_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmslt_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmslt_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmslt_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmslt_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmslt_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmslt_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmslt_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmslt_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmslt_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmslt_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmslt_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmslt_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmslt_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmslt_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmslt_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmslt_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmslt_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmslt_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmslt_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmslt_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmslt_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmslt_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmslt_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmslt_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmslt_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmslt_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmslt_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmslt_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmslt_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmslt_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmslt_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmslt_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmslt_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmslt_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmslt_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint8m1_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint8m2_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint8m4_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmslt(vint8m8_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmslt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmslt_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmslt_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint16m1_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint16m2_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint16m4_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmslt(vint16m8_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmslt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmslt_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmslt_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint32m1_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint32m2_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint32m4_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmslt(vint32m8_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmslt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmslt_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmslt_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmslt(vint64m1_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmslt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmslt(vint64m2_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmslt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmslt(vint64m4_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmslt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmslt(vint64m8_t op0, int64_t op1, size_t op2){
  return vmslt_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmslt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmslt_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmsleu_vv_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmsleu_vv_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmsleu_vv_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmsleu_vv_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmsleu_vv_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmsleu_vv_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsleu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmsleu_vv_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsleu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmsleu_vv_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmsleu_vv_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmsleu_vv_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmsleu_vv_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmsleu_vv_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmsleu_vv_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmsleu_vv_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmsleu_vv_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmsleu_vv_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmsleu_vv_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmsleu_vv_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmsleu_vv_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmsleu_vv_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmsleu_vv_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmsleu_vv_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmsleu_vv_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmsleu_vv_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmsleu_vv_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmsleu_vv_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmsleu_vv_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmsleu_vv_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmsleu_vv_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmsleu_vv_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmsleu_vv_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmsleu_vv_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmsleu_vv_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmsleu_vv_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmsleu_vv_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmsleu_vv_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmsleu_vv_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmsleu_vv_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmsleu_vv_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmsleu_vv_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmsleu_vv_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmsleu_vv_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmsleu_vv_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmsleu_vv_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsleu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsleu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsleu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsleu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsleu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsleu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsleu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsleu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsleu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsleu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsleu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsleu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsleu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsleu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsleu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsleu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsleu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsleu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsleu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsleu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsleu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsleu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmsle_vv_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmsle_vv_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmsle_vv_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmsle_vv_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmsle_vv_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmsle_vv_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsle(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmsle_vv_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsle(vbool1_t op0, vbool1_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmsle_vv_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmsle_vv_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmsle_vv_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmsle_vv_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmsle_vv_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmsle_vv_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmsle_vv_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmsle_vv_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmsle_vv_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmsle_vv_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmsle_vv_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmsle_vv_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmsle_vv_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmsle_vv_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmsle_vv_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmsle_vv_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmsle_vv_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmsle_vv_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmsle_vv_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmsle_vv_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmsle_vv_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmsle_vv_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmsle_vv_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmsle_vv_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmsle_vv_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmsle_vv_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmsle_vv_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmsle_vv_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmsle_vv_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmsle_vv_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmsle_vv_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmsle_vv_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmsle_vv_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmsle_vv_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmsle_vv_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmsle_vv_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmsle_vv_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsle(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsle(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsle_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsle_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsle(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsle(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsle_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsle_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsle(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsle(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsle_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsle_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsle(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsle(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsle(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsle(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsle(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsle(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsle(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsle_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsle(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsle_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m1_t op1, size_t op2){
  return vse16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool16_t op0, int16_t * op1, vint16m1_t op2, size_t op3){
  return vse16_v_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m2_t op1, size_t op2){
  return vse16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool8_t op0, int16_t * op1, vint16m2_t op2, size_t op3){
  return vse16_v_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m4_t op1, size_t op2){
  return vse16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool4_t op0, int16_t * op1, vint16m4_t op2, size_t op3){
  return vse16_v_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16m8_t op1, size_t op2){
  return vse16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool2_t op0, int16_t * op1, vint16m8_t op2, size_t op3){
  return vse16_v_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16mf2_t op1, size_t op2){
  return vse16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool32_t op0, int16_t * op1, vint16mf2_t op2, size_t op3){
  return vse16_v_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(int16_t * op0, vint16mf4_t op1, size_t op2){
  return vse16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool64_t op0, int16_t * op1, vint16mf4_t op2, size_t op3){
  return vse16_v_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsgtu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgtu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgtu(vbool2_t op0, vbool2_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsgtu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsgtu(vbool1_t op0, vbool1_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmsgtu_vx_u8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmsgtu_vx_u8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgtu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgtu(vbool2_t op0, vbool2_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmsgtu_vx_u16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmsgtu_vx_u16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgtu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgtu(vbool4_t op0, vbool4_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmsgtu_vx_u32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmsgtu_vx_u32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgtu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgtu(vbool64_t op0, vbool64_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgtu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgtu(vbool32_t op0, vbool32_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgtu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgtu(vbool16_t op0, vbool16_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgtu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmsgtu_vx_u64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgtu(vbool8_t op0, vbool8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmsgtu_vx_u64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint8m1_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m1_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m1_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint8m2_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m2_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m2_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgt(vint8m4_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m4_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgt(vbool2_t op0, vbool2_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m4_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool1_t vmsgt(vint8m8_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8m8_b1(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmsgt(vbool1_t op0, vbool1_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8m8_b1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf4_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf4_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmsgt_vx_i8mf8_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmsgt_vx_i8mf8_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint16m1_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m1_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m1_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint16m2_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m2_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m2_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint16m4_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m4_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m4_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool2_t vmsgt(vint16m8_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16m8_b2(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmsgt(vbool2_t op0, vbool2_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16m8_b2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16mf2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16mf2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmsgt_vx_i16mf4_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmsgt_vx_i16mf4_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint32m1_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint32m2_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint32m4_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmsgt(vint32m8_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmsgt(vbool4_t op0, vbool4_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmsgt_vx_i32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmsgt_vx_i32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmsgt(vint64m1_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmsgt(vbool64_t op0, vbool64_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmsgt(vint64m2_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmsgt(vbool32_t op0, vbool32_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmsgt(vint64m4_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmsgt(vbool16_t op0, vbool16_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmsgt(vint64m8_t op0, int64_t op1, size_t op2){
  return vmsgt_vx_i64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsgt(vbool8_t op0, vbool8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmsgt_vx_i64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vminu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vminu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vminu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vminu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vminu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vminu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vminu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vminu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vminu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vminu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vminu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vminu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vminu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vminu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vminu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vminu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vminu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vminu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vminu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vminu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vminu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vminu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vminu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vminu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vminu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vminu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vminu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vminu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vminu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vminu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vminu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vminu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vminu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vminu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vminu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vminu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vminu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vminu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vminu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vminu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vminu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vminu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vminu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vminu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vminu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vminu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vminu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vminu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vminu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vminu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vminu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vminu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vminu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vminu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vminu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vminu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vminu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vminu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vminu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vminu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vminu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vminu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vminu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vminu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vminu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vminu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vminu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vminu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vminu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vminu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vminu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vminu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vminu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vminu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vminu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vminu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vminu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vminu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vminu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vminu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vminu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vminu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vminu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vminu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vminu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vminu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vminu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vminu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vminu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vminu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vminu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vminu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vminu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vminu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vminu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vminu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vminu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vminu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vminu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vminu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vminu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vminu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vminu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vminu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vminu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vminu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vminu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vminu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vminu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vminu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vminu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vminu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vminu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vminu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vminu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vminu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vminu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vminu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vminu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vminu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vminu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vminu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vminu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vminu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vminu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vminu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vminu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vminu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vminu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vminu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vminu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vminu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vminu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vminu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vminu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vminu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vminu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vminu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vminu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vminu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmin(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmin_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmin(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmin_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmin(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmin_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmin(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmin_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmin(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmin_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmin(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmin_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmin(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmin_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmin(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmin_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmin(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmin_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmin(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmin_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmin(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmin_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmin(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmin_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmin(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmin_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmin(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmin_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmin(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmin_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmin(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmin_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmin(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmin_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmin(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmin_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmin(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmin_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmin(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmin_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmin(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmin_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmin(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmin_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmin(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmin_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmin(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmin_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmin(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmin_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmin(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmin_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmin(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmin_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmin(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmin_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmin(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmin_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmin(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmin_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmin(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmin_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmin(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmin_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmin(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmin_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmin(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmin_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmin(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmin_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmin(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmin_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmin(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmin_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmin(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmin_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmin(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmin_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmin(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmin_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmin(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmin_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmin(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmin_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmin(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmin_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmin(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmin_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmin(vint8m1_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmin(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmin(vint8m2_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmin(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmin(vint8m4_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmin(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmin(vint8m8_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmin(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmin(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmin(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmin(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmin(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmin(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmin_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmin(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmin_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmin(vint16m1_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmin(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmin(vint16m2_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmin(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmin(vint16m4_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmin(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmin(vint16m8_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmin(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmin(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmin(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmin(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmin_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmin(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmin_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmin(vint32m1_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmin(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmin(vint32m2_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmin(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmin(vint32m4_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmin(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmin(vint32m8_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmin(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmin(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmin_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmin(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmin_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmin(vint64m1_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmin(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmin(vint64m2_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmin(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmin(vint64m4_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmin(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmin(vint64m8_t op0, int64_t op1, size_t op2){
  return vmin_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmin(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmin_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmaxu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmaxu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmaxu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmaxu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmaxu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmaxu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmaxu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmaxu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmaxu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmaxu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmaxu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmaxu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmaxu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmaxu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmaxu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmaxu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmaxu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmaxu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmaxu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmaxu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmaxu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmaxu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmaxu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmaxu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmaxu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmaxu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmaxu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmaxu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmaxu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmaxu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmaxu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmaxu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmaxu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmaxu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmaxu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmaxu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmaxu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmaxu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmaxu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmaxu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmaxu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmaxu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmaxu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmaxu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmaxu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmaxu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmaxu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmaxu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmaxu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmaxu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmaxu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmaxu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmaxu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmaxu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmaxu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmaxu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmaxu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmaxu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmaxu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmaxu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmaxu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmaxu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmaxu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmaxu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmaxu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmaxu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmaxu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmaxu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmaxu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmaxu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmaxu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmaxu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmaxu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmaxu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmaxu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmaxu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmaxu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmaxu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmaxu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmaxu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmaxu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmaxu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmaxu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmaxu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmaxu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmaxu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmaxu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmaxu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmaxu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmaxu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmaxu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmaxu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmaxu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmaxu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmaxu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmaxu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmaxu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmaxu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmaxu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmaxu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmaxu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmaxu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmaxu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmaxu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmaxu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmaxu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmaxu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmaxu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmaxu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmaxu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmaxu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmaxu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmaxu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmaxu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmaxu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmaxu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmaxu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmaxu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmaxu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmaxu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmaxu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmaxu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmaxu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmaxu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmaxu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmaxu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmaxu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmaxu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmaxu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmaxu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmaxu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmaxu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmaxu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmaxu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmaxu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmaxu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmaxu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmaxu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmaxu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmaxu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmax(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmax_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmax(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmax_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmax(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmax_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmax(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmax_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmax(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmax_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmax(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmax_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmax(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmax_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmax(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmax_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmax(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmax_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmax(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmax_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmax(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmax_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmax(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmax_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmax(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmax_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmax(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmax_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmax(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmax_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmax(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmax_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmax(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmax_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmax(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmax_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmax(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmax_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmax(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmax_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmax(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmax_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmax(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmax_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmax(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmax_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmax(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmax_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmax(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmax_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmax(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmax_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmax(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmax_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmax(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmax_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmax(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmax_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmax(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmax_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmax(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmax_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmax(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmax_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmax(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmax_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmax(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmax_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmax(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmax_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmax(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmax_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmax(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmax_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmax(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmax_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmax(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmax_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmax(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmax_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmax(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmax_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmax(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmax_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmax(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmax_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmax(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmax_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmax(vint8m1_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmax(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmax(vint8m2_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmax(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmax(vint8m4_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmax(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmax(vint8m8_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmax(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmax(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmax(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmax(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmax(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmax(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmax_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmax(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmax_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmax(vint16m1_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmax(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmax(vint16m2_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmax(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmax(vint16m4_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmax(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmax(vint16m8_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmax(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmax(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmax(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmax(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmax_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmax(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmax_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmax(vint32m1_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmax(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmax(vint32m2_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmax(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmax(vint32m4_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmax(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmax(vint32m8_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmax(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmax(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmax_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmax(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmax_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmax(vint64m1_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmax(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmax(vint64m2_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmax(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmax(vint64m4_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmax(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmax(vint64m8_t op0, int64_t op1, size_t op2){
  return vmax_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmax(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmax_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vse16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool16_t op0, uint16_t * op1, vuint16m1_t op2, size_t op3){
  return vse16_v_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vse16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool8_t op0, uint16_t * op1, vuint16m2_t op2, size_t op3){
  return vse16_v_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vse16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool4_t op0, uint16_t * op1, vuint16m4_t op2, size_t op3){
  return vse16_v_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vse16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool2_t op0, uint16_t * op1, vuint16m8_t op2, size_t op3){
  return vse16_v_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vse16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool32_t op0, uint16_t * op1, vuint16mf2_t op2, size_t op3){
  return vse16_v_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse16(uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vse16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded void vse16(vbool64_t op0, uint16_t * op1, vuint16mf4_t op2, size_t op3){
  return vse16_v_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmul_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmul_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmul_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmul_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmul_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmul_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmul(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmul_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmul_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmul_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmul_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmul_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmul_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmul_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmul_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmul(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmul(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmul(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmul(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmul(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmul(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmul(vint8m8_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmul_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmul_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmul(vint16m8_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmul(vint32m8_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmul(vint64m1_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmul(vint64m2_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmul(vint64m4_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmul(vint64m8_t op0, int64_t op1, size_t op2){
  return vmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmul(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmul_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmul(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmul_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmul(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmul_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmul(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmul_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmul(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmul_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmul(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmul_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmul(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmul_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmul(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmul_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmul(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmul_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmul(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmul_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmul(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmul_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmul(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmul_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmul(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmul_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmul(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmul_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmul(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmul_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmul(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmul_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmul(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmul_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmul(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmul_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmul(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmul_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmul(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmul_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmul(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmul_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmul(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmul_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmul(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmul_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmul(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmul_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmul(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmul_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmul(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmul_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmul(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmul_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmul(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmul_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmul(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmul_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmul(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmul_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmul(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmul_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmul(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmul_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmul(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmul_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmul(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmul_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmul(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmul_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmul(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmul_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmul(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmul_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmul(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmul_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmul(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmul_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmul(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmul_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmul(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmul_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmul(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmul_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmul(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmul_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmul(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmul_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmul(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmul(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmul(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmul(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmul(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmul(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmul(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmul(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmul(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmul(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmul(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmul(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmul(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmul_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmul(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmul_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmul(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmul(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmul(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmul(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmul(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmul(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmul(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmul(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmul(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmul(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmul(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmul_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmul(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmul_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmul(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmul(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmul(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmul(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmul(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmul(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmul(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmul(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmul(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmul_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmul(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmul_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmul(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmul(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmul(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmul(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmul(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmul(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmul(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmul_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmul(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmul_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulh(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vmulh_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulh(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmulh_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulh(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vmulh_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulh(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmulh_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulh(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vmulh_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulh(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmulh_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulh(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vmulh_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulh(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmulh_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulh(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vmulh_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulh(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmulh_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulh(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vmulh_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulh(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmulh_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulh(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vmulh_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulh(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmulh_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulh(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vmulh_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulh(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmulh_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulh(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vmulh_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulh(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmulh_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulh(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vmulh_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulh(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmulh_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulh(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vmulh_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulh(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmulh_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulh(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vmulh_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulh(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmulh_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulh(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vmulh_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulh(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmulh_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulh(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vmulh_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulh(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmulh_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulh(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vmulh_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulh(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmulh_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulh(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vmulh_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulh(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmulh_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulh(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vmulh_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulh(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmulh_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulh(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vmulh_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulh(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmulh_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulh(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vmulh_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulh(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmulh_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulh(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vmulh_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulh(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmulh_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulh(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vmulh_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulh(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmulh_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulh(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vmulh_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulh(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmulh_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulh(vint8m1_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulh(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulh(vint8m2_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulh(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulh(vint8m4_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulh(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulh(vint8m8_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulh(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulh(vint8mf2_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulh(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulh(vint8mf4_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulh(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulh(vint8mf8_t op0, int8_t op1, size_t op2){
  return vmulh_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulh(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vmulh_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulh(vint16m1_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulh(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulh(vint16m2_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulh(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulh(vint16m4_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulh(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulh(vint16m8_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulh(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulh(vint16mf2_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulh(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulh(vint16mf4_t op0, int16_t op1, size_t op2){
  return vmulh_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulh(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vmulh_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulh(vint32m1_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulh(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulh(vint32m2_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulh(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulh(vint32m4_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulh(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulh(vint32m8_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulh(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulh(vint32mf2_t op0, int32_t op1, size_t op2){
  return vmulh_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulh(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vmulh_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulh(vint64m1_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulh(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulh(vint64m2_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulh(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulh(vint64m4_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulh(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulh(vint64m8_t op0, int64_t op1, size_t op2){
  return vmulh_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulh(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vmulh_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmulhu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmulhu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmulhu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmulhu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmulhu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmulhu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmulhu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmulhu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmulhu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmulhu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmulhu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmulhu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmulhu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmulhu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmulhu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmulhu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmulhu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmulhu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmulhu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmulhu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmulhu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmulhu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmulhu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmulhu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmulhu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmulhu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmulhu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmulhu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmulhu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmulhu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmulhu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmulhu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmulhu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmulhu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmulhu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmulhu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmulhu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmulhu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmulhu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmulhu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmulhu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmulhu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmulhu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmulhu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmulhu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmulhu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmulhu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmulhu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmulhu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmulhu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmulhu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmulhu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmulhu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmulhu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmulhu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmulhu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmulhu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmulhu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmulhu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmulhu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmulhu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmulhu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmulhu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmulhu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmulhu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmulhu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmulhu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmulhu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmulhu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmulhu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmulhu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmulhu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmulhu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmulhu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmulhu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmulhu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmulhu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmulhu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmulhu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmulhu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmulhu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmulhu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmulhu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmulhu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmulhu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmulhu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmulhu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmulhu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmulhu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vmulhu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmulhu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vmulhu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmulhu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vmulhu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmulhu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vmulhu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmulhu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vmulhu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmulhu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vmulhu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmulhu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vmulhu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vmulhu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vmulhu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmulhu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vmulhu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmulhu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vmulhu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmulhu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vmulhu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmulhu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vmulhu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmulhu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vmulhu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmulhu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vmulhu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vmulhu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vmulhu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmulhu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vmulhu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmulhu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vmulhu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmulhu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vmulhu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmulhu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vmulhu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmulhu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vmulhu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vmulhu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vmulhu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmulhu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vmulhu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmulhu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vmulhu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmulhu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vmulhu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmulhu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vmulhu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vmulhu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vmulhu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulhsu(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vmulhsu_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulhsu(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmulhsu_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulhsu(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vmulhsu_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulhsu(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmulhsu_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulhsu(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vmulhsu_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulhsu(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmulhsu_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulhsu(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vmulhsu_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulhsu(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmulhsu_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulhsu(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vmulhsu_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulhsu(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmulhsu_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulhsu(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vmulhsu_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulhsu(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmulhsu_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulhsu(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vmulhsu_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulhsu(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmulhsu_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulhsu(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vmulhsu_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulhsu(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmulhsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulhsu(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vmulhsu_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulhsu(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmulhsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulhsu(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vmulhsu_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulhsu(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmulhsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulhsu(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vmulhsu_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulhsu(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmulhsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulhsu(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vmulhsu_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulhsu(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmulhsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulhsu(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vmulhsu_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulhsu(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmulhsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulhsu(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vmulhsu_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulhsu(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmulhsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulhsu(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vmulhsu_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulhsu(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmulhsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulhsu(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vmulhsu_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulhsu(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmulhsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulhsu(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vmulhsu_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulhsu(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmulhsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulhsu(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vmulhsu_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulhsu(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmulhsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulhsu(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vmulhsu_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulhsu(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmulhsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulhsu(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vmulhsu_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulhsu(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmulhsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulhsu(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vmulhsu_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulhsu(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmulhsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulhsu(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vmulhsu_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulhsu(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmulhsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmulhsu(vint8m1_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vmulhsu(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmulhsu(vint8m2_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vmulhsu(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmulhsu(vint8m4_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vmulhsu(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmulhsu(vint8m8_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vmulhsu(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmulhsu(vint8mf2_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vmulhsu(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmulhsu(vint8mf4_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vmulhsu(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmulhsu(vint8mf8_t op0, uint8_t op1, size_t op2){
  return vmulhsu_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vmulhsu(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, uint8_t op3, size_t op4){
  return vmulhsu_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmulhsu(vint16m1_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vmulhsu(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmulhsu(vint16m2_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vmulhsu(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmulhsu(vint16m4_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vmulhsu(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmulhsu(vint16m8_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vmulhsu(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmulhsu(vint16mf2_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vmulhsu(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmulhsu(vint16mf4_t op0, uint16_t op1, size_t op2){
  return vmulhsu_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vmulhsu(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, uint16_t op3, size_t op4){
  return vmulhsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmulhsu(vint32m1_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vmulhsu(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmulhsu(vint32m2_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vmulhsu(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmulhsu(vint32m4_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vmulhsu(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmulhsu(vint32m8_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vmulhsu(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmulhsu(vint32mf2_t op0, uint32_t op1, size_t op2){
  return vmulhsu_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vmulhsu(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, uint32_t op3, size_t op4){
  return vmulhsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmulhsu(vint64m1_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vmulhsu(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmulhsu(vint64m2_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vmulhsu(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmulhsu(vint64m4_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vmulhsu(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmulhsu(vint64m8_t op0, uint64_t op1, size_t op2){
  return vmulhsu_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vmulhsu(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, uint64_t op3, size_t op4){
  return vmulhsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m1_t op1, size_t op2){
  return vse32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, int32_t * op1, vint32m1_t op2, size_t op3){
  return vse32_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m2_t op1, size_t op2){
  return vse32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, int32_t * op1, vint32m2_t op2, size_t op3){
  return vse32_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m4_t op1, size_t op2){
  return vse32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, int32_t * op1, vint32m4_t op2, size_t op3){
  return vse32_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32m8_t op1, size_t op2){
  return vse32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, int32_t * op1, vint32m8_t op2, size_t op3){
  return vse32_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(int32_t * op0, vint32mf2_t op1, size_t op2){
  return vse32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, int32_t * op1, vint32mf2_t op2, size_t op3){
  return vse32_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vdivu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vdivu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vdivu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vdivu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vdivu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vdivu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vdivu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vdivu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vdivu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vdivu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vdivu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vdivu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vdivu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vdivu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vdivu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vdivu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vdivu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vdivu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vdivu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vdivu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vdivu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vdivu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vdivu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vdivu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vdivu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vdivu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vdivu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vdivu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vdivu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vdivu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vdivu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vdivu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vdivu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vdivu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vdivu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vdivu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vdivu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vdivu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vdivu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vdivu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vdivu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vdivu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vdivu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vdivu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vdivu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vdivu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vdivu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vdivu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vdivu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vdivu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vdivu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vdivu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vdivu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vdivu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vdivu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vdivu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vdivu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vdivu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vdivu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vdivu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vdivu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vdivu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vdivu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vdivu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vdivu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vdivu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vdivu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vdivu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vdivu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vdivu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vdivu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vdivu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vdivu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vdivu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vdivu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vdivu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vdivu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vdivu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vdivu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vdivu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vdivu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vdivu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vdivu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vdivu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vdivu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vdivu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vdivu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vdivu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vdivu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vdivu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vdivu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vdivu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vdivu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vdivu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vdivu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vdivu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vdivu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vdivu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vdivu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vdivu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vdivu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vdivu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vdivu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vdivu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vdivu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vdivu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vdivu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vdivu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vdivu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vdivu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vdivu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vdivu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vdivu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vdivu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vdivu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vdivu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vdivu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vdivu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vdivu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vdivu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vdivu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vdivu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vdivu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vdivu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vdivu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vdivu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vdivu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vdivu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vdivu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vdivu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vdivu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vdivu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vdivu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vdivu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vdivu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vdivu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vdivu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vdivu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vdivu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vdivu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vdiv(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vdiv_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vdiv(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vdiv_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vdiv(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vdiv_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vdiv(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vdiv_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vdiv(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vdiv_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vdiv(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vdiv_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vdiv(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vdiv_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vdiv(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vdiv_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vdiv(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vdiv_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vdiv(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vdiv_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vdiv(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vdiv_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vdiv(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vdiv_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vdiv(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vdiv_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vdiv(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vdiv_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vdiv(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vdiv_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vdiv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vdiv_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vdiv(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vdiv_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vdiv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vdiv_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vdiv(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vdiv_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vdiv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vdiv_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vdiv(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vdiv_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vdiv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vdiv_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vdiv(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vdiv_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vdiv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vdiv_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vdiv(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vdiv_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vdiv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vdiv_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vdiv(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vdiv_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vdiv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vdiv_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vdiv(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vdiv_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vdiv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vdiv_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vdiv(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vdiv_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vdiv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vdiv_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vdiv(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vdiv_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vdiv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vdiv_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vdiv(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vdiv_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vdiv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vdiv_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vdiv(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vdiv_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vdiv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vdiv_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vdiv(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vdiv_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vdiv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vdiv_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vdiv(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vdiv_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vdiv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vdiv_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vdiv(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vdiv_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vdiv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vdiv_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vdiv(vint8m1_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vdiv(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vdiv(vint8m2_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vdiv(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vdiv(vint8m4_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vdiv(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vdiv(vint8m8_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vdiv(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vdiv(vint8mf2_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vdiv(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vdiv(vint8mf4_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vdiv(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vdiv(vint8mf8_t op0, int8_t op1, size_t op2){
  return vdiv_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vdiv(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vdiv_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vdiv(vint16m1_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vdiv(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vdiv(vint16m2_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vdiv(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vdiv(vint16m4_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vdiv(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vdiv(vint16m8_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vdiv(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vdiv(vint16mf2_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vdiv(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vdiv(vint16mf4_t op0, int16_t op1, size_t op2){
  return vdiv_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vdiv(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vdiv_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vdiv(vint32m1_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vdiv(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vdiv(vint32m2_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vdiv(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vdiv(vint32m4_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vdiv(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vdiv(vint32m8_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vdiv(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vdiv(vint32mf2_t op0, int32_t op1, size_t op2){
  return vdiv_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vdiv(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vdiv_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vdiv(vint64m1_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vdiv(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vdiv(vint64m2_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vdiv(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vdiv(vint64m4_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vdiv(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vdiv(vint64m8_t op0, int64_t op1, size_t op2){
  return vdiv_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vdiv(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vdiv_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vremu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vremu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vremu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vremu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vremu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vremu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vremu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vremu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vremu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vremu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vremu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vremu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vremu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vremu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vremu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vremu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vremu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vremu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vremu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vremu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vremu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vremu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vremu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vremu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vremu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vremu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vremu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vremu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vremu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vremu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vremu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vremu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vremu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vremu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vremu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vremu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vremu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vremu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vremu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vremu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vremu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vremu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vremu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vremu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vremu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vremu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vremu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vremu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vremu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vremu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vremu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vremu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vremu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vremu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vremu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vremu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vremu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vremu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vremu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vremu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vremu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vremu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vremu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vremu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vremu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vremu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vremu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vremu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vremu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vremu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vremu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vremu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vremu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vremu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vremu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vremu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vremu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vremu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vremu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vremu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vremu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vremu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vremu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vremu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vremu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vremu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vremu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vremu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vremu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vremu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vremu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vremu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vremu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vremu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vremu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vremu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vremu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vremu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vremu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vremu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vremu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vremu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vremu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vremu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vremu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vremu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vremu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vremu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vremu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vremu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vremu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vremu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vremu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vremu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vremu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vremu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vremu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vremu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vremu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vremu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vremu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vremu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vremu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vremu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vremu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vremu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vremu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vremu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vremu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vremu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vremu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vremu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vremu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vremu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vremu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vremu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vremu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vremu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vremu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vremu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrem(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vrem_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrem(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vrem_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrem(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vrem_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrem(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vrem_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrem(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vrem_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrem(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vrem_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrem(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vrem_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrem(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vrem_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrem(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vrem_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrem(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vrem_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrem(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vrem_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrem(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vrem_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrem(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vrem_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrem(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vrem_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrem(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vrem_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrem(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vrem_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrem(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vrem_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrem(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vrem_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrem(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vrem_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrem(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vrem_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrem(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vrem_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrem(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vrem_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrem(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vrem_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrem(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vrem_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrem(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vrem_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrem(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vrem_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrem(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vrem_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrem(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vrem_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrem(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vrem_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrem(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vrem_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrem(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vrem_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrem(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vrem_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrem(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vrem_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrem(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vrem_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrem(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vrem_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrem(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vrem_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrem(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vrem_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrem(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vrem_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrem(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vrem_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrem(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vrem_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrem(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vrem_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrem(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vrem_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrem(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vrem_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrem(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vrem_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrem(vint8m1_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrem(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrem(vint8m2_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrem(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrem(vint8m4_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrem(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrem(vint8m8_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrem(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrem(vint8mf2_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrem(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrem(vint8mf4_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrem(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrem(vint8mf8_t op0, int8_t op1, size_t op2){
  return vrem_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrem(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vrem_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrem(vint16m1_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrem(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrem(vint16m2_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrem(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrem(vint16m4_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrem(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrem(vint16m8_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrem(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrem(vint16mf2_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrem(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrem(vint16mf4_t op0, int16_t op1, size_t op2){
  return vrem_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrem(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vrem_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrem(vint32m1_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrem(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrem(vint32m2_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrem(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrem(vint32m4_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrem(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrem(vint32m8_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrem(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrem(vint32mf2_t op0, int32_t op1, size_t op2){
  return vrem_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrem(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vrem_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrem(vint64m1_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrem(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrem(vint64m2_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrem(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrem(vint64m4_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrem(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrem(vint64m8_t op0, int64_t op1, size_t op2){
  return vrem_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrem(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vrem_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vwmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmul(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vwmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmul(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vwmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmul(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vwmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmul(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vwmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmul(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vwmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmul(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vwmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmul(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vwmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmul(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vwmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmul(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vwmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmul(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vwmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmul(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vwmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmul(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vwmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmul(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vwmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmul(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vwmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmul(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmul(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmul(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmul(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmul(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmul(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vwmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmul(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vwmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmul(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmul(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmul(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmul(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vwmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmul(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vwmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmul(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmul(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmul(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vwmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmul(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vwmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vse32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, uint32_t * op1, vuint32m1_t op2, size_t op3){
  return vse32_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vse32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, uint32_t * op1, vuint32m2_t op2, size_t op3){
  return vse32_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vse32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, uint32_t * op1, vuint32m4_t op2, size_t op3){
  return vse32_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vse32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, uint32_t * op1, vuint32m8_t op2, size_t op3){
  return vse32_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vse32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, uint32_t * op1, vuint32mf2_t op2, size_t op3){
  return vse32_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmulu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwmulu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwmulu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmulu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmulu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwmulu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwmulu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmulu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmulu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwmulu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwmulu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmulu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmulu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwmulu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwmulu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmulu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmulu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwmulu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwmulu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmulu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmulu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwmulu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwmulu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmulu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmulu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwmulu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwmulu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmulu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmulu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwmulu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwmulu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmulu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmulu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwmulu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwmulu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmulu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmulu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwmulu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwmulu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmulu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmulu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwmulu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwmulu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmulu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmulu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwmulu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwmulu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmulu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmulu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwmulu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwmulu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmulu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmulu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwmulu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwmulu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmulu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmulu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwmulu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwmulu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmulu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmulu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vwmulu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmulu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vwmulu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmulu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vwmulu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmulu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vwmulu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmulu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vwmulu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmulu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vwmulu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vwmulu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vwmulu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmulu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vwmulu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmulu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vwmulu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmulu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vwmulu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmulu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vwmulu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmulu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vwmulu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vwmulu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vwmulu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmulu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vwmulu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmulu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vwmulu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmulu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vwmulu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmulu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vwmulu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vwmulu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vwmulu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmulsu(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vwmulsu_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmulsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmulsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmulsu(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vwmulsu_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmulsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmulsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmulsu(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vwmulsu_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmulsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmulsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmulsu(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vwmulsu_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmulsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmulsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmulsu(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vwmulsu_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmulsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmulsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmulsu(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vwmulsu_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmulsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmulsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmulsu(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vwmulsu_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmulsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmulsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmulsu(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vwmulsu_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmulsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmulsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmulsu(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vwmulsu_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmulsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmulsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmulsu(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vwmulsu_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmulsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmulsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmulsu(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vwmulsu_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmulsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmulsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmulsu(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vwmulsu_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmulsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmulsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmulsu(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vwmulsu_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmulsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmulsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmulsu(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vwmulsu_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmulsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmulsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmulsu(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vwmulsu_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmulsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmulsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmulsu(vint8mf8_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vwmulsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmulsu(vint8mf4_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vwmulsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmulsu(vint8mf2_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vwmulsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmulsu(vint8m1_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vwmulsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmulsu(vint8m2_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vwmulsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmulsu(vint8m4_t op0, uint8_t op1, size_t op2){
  return vwmulsu_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vwmulsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, uint8_t op3, size_t op4){
  return vwmulsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmulsu(vint16mf4_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vwmulsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmulsu(vint16mf2_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vwmulsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmulsu(vint16m1_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vwmulsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmulsu(vint16m2_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vwmulsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmulsu(vint16m4_t op0, uint16_t op1, size_t op2){
  return vwmulsu_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vwmulsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, uint16_t op3, size_t op4){
  return vwmulsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmulsu(vint32mf2_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vwmulsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmulsu(vint32m1_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vwmulsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmulsu(vint32m2_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vwmulsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmulsu(vint32m4_t op0, uint32_t op1, size_t op2){
  return vwmulsu_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vwmulsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, uint32_t op3, size_t op4){
  return vwmulsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmacc(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vmacc_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmacc(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmacc_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmacc(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vmacc_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmacc(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmacc_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmacc(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vmacc_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmacc(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmacc_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmacc(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vmacc_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmacc(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmacc_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmacc(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vmacc_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmacc(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmacc_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmacc(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vmacc_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmacc(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmacc_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmacc(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vmacc_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmacc(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmacc_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmacc(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vmacc_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmacc(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmacc_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmacc(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vmacc_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmacc(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmacc_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmacc(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vmacc_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmacc(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmacc_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmacc(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vmacc_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmacc(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmacc_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmacc(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vmacc_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmacc(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmacc_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmacc(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vmacc_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmacc(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmacc_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmacc(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vmacc_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmacc(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmacc_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmacc(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vmacc_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmacc(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmacc_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmacc(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vmacc_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmacc(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmacc_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmacc(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vmacc_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmacc(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmacc_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmacc(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vmacc_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmacc(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmacc_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmacc(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vmacc_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmacc(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmacc_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmacc(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vmacc_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmacc(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmacc_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmacc(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vmacc_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmacc(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmacc_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmacc(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vmacc_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmacc(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmacc_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmacc(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vmacc_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmacc(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vmacc_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmacc(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vmacc_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmacc(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vmacc_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmacc(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vmacc_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmacc(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vmacc_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmacc(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vmacc_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmacc(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vmacc_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmacc(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vmacc_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmacc(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vmacc_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmacc(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vmacc_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmacc(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vmacc_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmacc(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vmacc_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmacc(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vmacc_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmacc(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vmacc_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmacc(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vmacc_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmacc(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vmacc_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmacc(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vmacc_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmacc(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vmacc_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmacc(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vmacc_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmacc(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vmacc_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmacc(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vmacc_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmacc(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vmacc_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmacc(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vmacc_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmacc(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vmacc_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmacc(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vmacc_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmacc(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vmacc_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmacc(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vmacc_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmacc(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vmacc_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmacc(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vmacc_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmacc(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vmacc_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmacc(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vmacc_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmacc(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vmacc_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmacc(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vmacc_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmacc(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vmacc_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmacc(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vmacc_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmacc(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vmacc_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmacc(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vmacc_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmacc(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vmacc_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmacc(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vmacc_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmacc(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vmacc_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmacc(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vmacc_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmacc(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vmacc_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmacc(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vmacc_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmacc(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vmacc_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmacc(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmacc_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmacc(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vmacc_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmacc(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmacc_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmacc(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vmacc_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmacc(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmacc_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmacc(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vmacc_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmacc(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmacc_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmacc(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vmacc_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmacc(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmacc_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmacc(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vmacc_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmacc(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmacc_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmacc(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vmacc_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmacc(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmacc_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmacc(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vmacc_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmacc(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmacc_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmacc(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vmacc_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmacc(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmacc_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmacc(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vmacc_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmacc(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmacc_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmacc(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vmacc_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmacc(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmacc_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmacc(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vmacc_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmacc(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmacc_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmacc(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vmacc_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmacc(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmacc_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmacc(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vmacc_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmacc(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmacc_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmacc(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vmacc_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmacc(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmacc_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmacc(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vmacc_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmacc(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmacc_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmacc(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vmacc_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmacc(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmacc_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmacc(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vmacc_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmacc(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmacc_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmacc(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vmacc_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmacc(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmacc_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmacc(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vmacc_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmacc(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmacc_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmacc(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vmacc_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmacc(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmacc_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmacc(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vmacc_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmacc(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmacc_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmacc(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vmacc_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmacc(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vmacc_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmacc(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vmacc_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmacc(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vmacc_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmacc(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vmacc_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmacc(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vmacc_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmacc(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vmacc_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmacc(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vmacc_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmacc(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vmacc_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmacc(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vmacc_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmacc(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vmacc_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmacc(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vmacc_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmacc(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vmacc_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmacc(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vmacc_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmacc(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vmacc_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmacc(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vmacc_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmacc(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vmacc_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmacc(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vmacc_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmacc(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vmacc_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmacc(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vmacc_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmacc(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vmacc_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmacc(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vmacc_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmacc(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vmacc_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmacc(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vmacc_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmacc(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vmacc_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmacc(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vmacc_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmacc(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vmacc_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmacc(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vmacc_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmacc(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vmacc_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmacc(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vmacc_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmacc(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vmacc_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmacc(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vmacc_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmacc(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vmacc_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmacc(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vmacc_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmacc(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vmacc_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmacc(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vmacc_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmacc(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vmacc_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmacc(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vmacc_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmacc(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vmacc_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmacc(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vmacc_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmacc(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vmacc_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmacc(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vmacc_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmacc(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vmacc_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmacc(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vmacc_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsac(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vnmsac_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsac(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vnmsac_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsac(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vnmsac_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsac(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vnmsac_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsac(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vnmsac_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsac(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vnmsac_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsac(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vnmsac_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsac(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vnmsac_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsac(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vnmsac_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsac(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vnmsac_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsac(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vnmsac_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsac(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vnmsac_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsac(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsac_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsac(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsac_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsac(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vnmsac_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsac(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vnmsac_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsac(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vnmsac_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsac(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vnmsac_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsac(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vnmsac_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsac(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vnmsac_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsac(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vnmsac_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsac(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vnmsac_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsac(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vnmsac_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsac(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vnmsac_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsac(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vnmsac_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsac(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vnmsac_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsac(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vnmsac_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsac(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vnmsac_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsac(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vnmsac_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsac(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vnmsac_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsac(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vnmsac_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsac(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vnmsac_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsac(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vnmsac_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsac(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vnmsac_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsac(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vnmsac_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsac(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vnmsac_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsac(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vnmsac_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsac(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vnmsac_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsac(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vnmsac_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsac(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vnmsac_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsac(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vnmsac_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsac(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vnmsac_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsac(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vnmsac_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsac(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vnmsac_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsac(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vnmsac_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsac(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vnmsac_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsac(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vnmsac_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsac(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vnmsac_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsac(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vnmsac_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsac(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vnmsac_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsac(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vnmsac_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsac(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vnmsac_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsac(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vnmsac_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsac(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vnmsac_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsac(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vnmsac_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsac(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vnmsac_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsac(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsac_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsac(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsac_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsac(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vnmsac_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsac(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vnmsac_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsac(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vnmsac_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsac(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vnmsac_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsac(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vnmsac_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsac(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vnmsac_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsac(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vnmsac_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsac(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vnmsac_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsac(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vnmsac_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsac(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vnmsac_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsac(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vnmsac_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsac(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vnmsac_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsac(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vnmsac_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsac(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vnmsac_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsac(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vnmsac_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsac(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vnmsac_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsac(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vnmsac_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsac(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vnmsac_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsac(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vnmsac_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsac(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vnmsac_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsac(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vnmsac_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsac(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vnmsac_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsac(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vnmsac_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsac(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vnmsac_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsac(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vnmsac_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsac(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vnmsac_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsac(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vnmsac_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsac(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vnmsac_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsac(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vnmsac_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsac(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vnmsac_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsac(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vnmsac_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsac(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vnmsac_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsac(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vnmsac_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsac(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vnmsac_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsac(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vnmsac_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsac(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vnmsac_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsac(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsac_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsac(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsac_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsac(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsac_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsac(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsac_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsac(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsac_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsac(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsac_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsac(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsac_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsac(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsac_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsac(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vnmsac_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsac(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vnmsac_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsac(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vnmsac_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsac(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vnmsac_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsac(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vnmsac_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsac(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vnmsac_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsac(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vnmsac_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsac(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vnmsac_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsac(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsac_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsac(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsac_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsac(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsac_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsac(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsac_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsac(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vnmsac_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsac(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vnmsac_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsac(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vnmsac_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsac(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vnmsac_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsac(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vnmsac_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsac(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vnmsac_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsac(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vnmsac_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsac(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vnmsac_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsac(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsac_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsac(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsac_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsac(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vnmsac_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsac(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vnmsac_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsac(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vnmsac_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsac(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vnmsac_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsac(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vnmsac_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsac(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vnmsac_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsac(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vnmsac_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsac(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vnmsac_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsac(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vnmsac_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsac(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vnmsac_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsac(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vnmsac_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsac(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vnmsac_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsac(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vnmsac_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsac(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vnmsac_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsac(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsac_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsac(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsac_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsac(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsac_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsac(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsac_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsac(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsac_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsac(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsac_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsac(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsac_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsac(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsac_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsac(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vnmsac_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsac(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vnmsac_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsac(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vnmsac_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsac(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vnmsac_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsac(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vnmsac_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsac(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vnmsac_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsac(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vnmsac_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsac(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vnmsac_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsac(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsac_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsac(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsac_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsac(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsac_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsac(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsac_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsac(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vnmsac_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsac(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vnmsac_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsac(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vnmsac_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsac(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vnmsac_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsac(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vnmsac_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsac(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vnmsac_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsac(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vnmsac_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsac(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vnmsac_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsac(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsac_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsac(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsac_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsac(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vnmsac_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsac(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vnmsac_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsac(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vnmsac_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsac(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vnmsac_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsac(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vnmsac_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsac(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vnmsac_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsac(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vnmsac_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsac(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vnmsac_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmadd(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vmadd_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vmadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmadd(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vmadd_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vmadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmadd(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vmadd_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vmadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmadd(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vmadd_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vmadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmadd(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vmadd_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vmadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmadd(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vmadd_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vmadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmadd(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vmadd_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vmadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmadd(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vmadd_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vmadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmadd(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vmadd_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vmadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmadd(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vmadd_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vmadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmadd(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vmadd_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vmadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmadd(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vmadd_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vmadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmadd(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vmadd_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vmadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmadd(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vmadd_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vmadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmadd(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vmadd_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vmadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmadd(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vmadd_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vmadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmadd(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vmadd_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vmadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmadd(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vmadd_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vmadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmadd(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vmadd_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vmadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmadd(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vmadd_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vmadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmadd(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vmadd_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vmadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmadd(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vmadd_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vmadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmadd(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vmadd_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmadd(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vmadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vmadd(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vmadd_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmadd(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vmadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vmadd(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vmadd_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmadd(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vmadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vmadd(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vmadd_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmadd(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vmadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vmadd(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vmadd_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmadd(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vmadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vmadd(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vmadd_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmadd(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vmadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vmadd(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vmadd_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmadd(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vmadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vmadd(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vmadd_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmadd(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vmadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vmadd(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vmadd_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmadd(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vmadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vmadd(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vmadd_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmadd(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vmadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vmadd(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vmadd_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmadd(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vmadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vmadd(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vmadd_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmadd(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vmadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vmadd(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vmadd_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmadd(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vmadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vmadd(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vmadd_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmadd(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vmadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vmadd(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vmadd_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmadd(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vmadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vmadd(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vmadd_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmadd(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vmadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vmadd(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vmadd_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmadd(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vmadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vmadd(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vmadd_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmadd(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vmadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vmadd(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vmadd_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmadd(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vmadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vmadd(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vmadd_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmadd(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vmadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vmadd(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vmadd_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmadd(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vmadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vmadd(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vmadd_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmadd(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vmadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmadd(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vmadd_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmadd(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vmadd_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmadd(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vmadd_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmadd(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vmadd_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmadd(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vmadd_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmadd(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vmadd_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmadd(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vmadd_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmadd(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vmadd_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmadd(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vmadd_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmadd(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vmadd_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmadd(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vmadd_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmadd(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vmadd_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmadd(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vmadd_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmadd(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vmadd_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmadd(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vmadd_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmadd(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vmadd_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmadd(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vmadd_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmadd(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vmadd_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmadd(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vmadd_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmadd(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vmadd_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmadd(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vmadd_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmadd(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vmadd_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmadd(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vmadd_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmadd(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vmadd_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmadd(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vmadd_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmadd(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vmadd_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmadd(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vmadd_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmadd(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vmadd_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmadd(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vmadd_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmadd(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vmadd_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmadd(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vmadd_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmadd(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vmadd_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmadd(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vmadd_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmadd(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vmadd_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmadd(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vmadd_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmadd(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vmadd_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmadd(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vmadd_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmadd(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vmadd_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmadd(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vmadd_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmadd(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vmadd_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmadd(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vmadd_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmadd(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vmadd_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmadd(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vmadd_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmadd(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vmadd_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vmadd(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vmadd_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmadd(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vmadd_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vmadd(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vmadd_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmadd(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vmadd_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vmadd(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vmadd_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmadd(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vmadd_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vmadd(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vmadd_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmadd(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vmadd_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vmadd(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vmadd_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmadd(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vmadd_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vmadd(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vmadd_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmadd(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vmadd_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vmadd(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vmadd_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmadd(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vmadd_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vmadd(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vmadd_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmadd(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vmadd_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vmadd(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vmadd_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmadd(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vmadd_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vmadd(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vmadd_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmadd(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vmadd_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vmadd(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vmadd_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmadd(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vmadd_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vmadd(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vmadd_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmadd(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vmadd_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vmadd(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vmadd_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmadd(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vmadd_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vmadd(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vmadd_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmadd(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vmadd_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vmadd(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vmadd_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmadd(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vmadd_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vmadd(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vmadd_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmadd(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vmadd_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vmadd(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vmadd_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmadd(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vmadd_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vmadd(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vmadd_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmadd(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vmadd_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vmadd(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vmadd_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmadd(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vmadd_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vmadd(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vmadd_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmadd(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vmadd_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vmadd(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vmadd_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmadd(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vmadd_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vmadd(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vmadd_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmadd(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vmadd_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsub(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vnmsub_vv_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vnmsub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsub(vint8m2_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vnmsub_vv_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vnmsub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsub(vint8m4_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vnmsub_vv_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vnmsub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsub(vint8m8_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vnmsub_vv_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vnmsub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsub(vint8mf2_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vnmsub_vv_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vnmsub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsub(vint8mf4_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vnmsub_vv_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vnmsub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsub(vint8mf8_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsub_vv_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsub(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vnmsub_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vnmsub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsub(vint16m2_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vnmsub_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vnmsub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsub(vint16m4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vnmsub_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vnmsub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsub(vint16m8_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vnmsub_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vnmsub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsub(vint16mf2_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vnmsub_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vnmsub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsub(vint16mf4_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vnmsub_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vnmsub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsub(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vnmsub_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vnmsub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsub(vint32m2_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vnmsub_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vnmsub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsub(vint32m4_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vnmsub_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vnmsub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsub(vint32m8_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vnmsub_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vnmsub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsub(vint32mf2_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vnmsub_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vnmsub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsub(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vnmsub_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vnmsub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsub(vint64m2_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vnmsub_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vnmsub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsub(vint64m4_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vnmsub_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vnmsub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsub(vint64m8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vnmsub_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vnmsub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnmsub(vint8m1_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vnmsub_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vnmsub(vbool8_t op0, vint8m1_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vnmsub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnmsub(vint8m2_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vnmsub_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vnmsub(vbool4_t op0, vint8m2_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vnmsub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnmsub(vint8m4_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vnmsub_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vnmsub(vbool2_t op0, vint8m4_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vnmsub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vnmsub(vint8m8_t op0, int8_t op1, vint8m8_t op2, size_t op3){
  return vnmsub_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vnmsub(vbool1_t op0, vint8m8_t op1, int8_t op2, vint8m8_t op3, size_t op4){
  return vnmsub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnmsub(vint8mf2_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vnmsub_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vnmsub(vbool16_t op0, vint8mf2_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vnmsub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnmsub(vint8mf4_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vnmsub_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vnmsub(vbool32_t op0, vint8mf4_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vnmsub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnmsub(vint8mf8_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vnmsub_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vnmsub(vbool64_t op0, vint8mf8_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vnmsub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnmsub(vint16m1_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vnmsub_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vnmsub(vbool16_t op0, vint16m1_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vnmsub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnmsub(vint16m2_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vnmsub_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vnmsub(vbool8_t op0, vint16m2_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vnmsub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnmsub(vint16m4_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vnmsub_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vnmsub(vbool4_t op0, vint16m4_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vnmsub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vnmsub(vint16m8_t op0, int16_t op1, vint16m8_t op2, size_t op3){
  return vnmsub_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vnmsub(vbool2_t op0, vint16m8_t op1, int16_t op2, vint16m8_t op3, size_t op4){
  return vnmsub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnmsub(vint16mf2_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vnmsub_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vnmsub(vbool32_t op0, vint16mf2_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vnmsub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnmsub(vint16mf4_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vnmsub_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vnmsub(vbool64_t op0, vint16mf4_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vnmsub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnmsub(vint32m1_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vnmsub_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vnmsub(vbool32_t op0, vint32m1_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vnmsub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnmsub(vint32m2_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vnmsub_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vnmsub(vbool16_t op0, vint32m2_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vnmsub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnmsub(vint32m4_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vnmsub_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vnmsub(vbool8_t op0, vint32m4_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vnmsub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vnmsub(vint32m8_t op0, int32_t op1, vint32m8_t op2, size_t op3){
  return vnmsub_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vnmsub(vbool4_t op0, vint32m8_t op1, int32_t op2, vint32m8_t op3, size_t op4){
  return vnmsub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnmsub(vint32mf2_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vnmsub_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vnmsub(vbool64_t op0, vint32mf2_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vnmsub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vnmsub(vint64m1_t op0, int64_t op1, vint64m1_t op2, size_t op3){
  return vnmsub_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vnmsub(vbool64_t op0, vint64m1_t op1, int64_t op2, vint64m1_t op3, size_t op4){
  return vnmsub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vnmsub(vint64m2_t op0, int64_t op1, vint64m2_t op2, size_t op3){
  return vnmsub_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vnmsub(vbool32_t op0, vint64m2_t op1, int64_t op2, vint64m2_t op3, size_t op4){
  return vnmsub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vnmsub(vint64m4_t op0, int64_t op1, vint64m4_t op2, size_t op3){
  return vnmsub_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vnmsub(vbool16_t op0, vint64m4_t op1, int64_t op2, vint64m4_t op3, size_t op4){
  return vnmsub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vnmsub(vint64m8_t op0, int64_t op1, vint64m8_t op2, size_t op3){
  return vnmsub_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vnmsub(vbool8_t op0, vint64m8_t op1, int64_t op2, vint64m8_t op3, size_t op4){
  return vnmsub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsub(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vnmsub_vv_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsub(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vnmsub_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsub(vuint8m2_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vnmsub_vv_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsub(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vnmsub_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsub(vuint8m4_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vnmsub_vv_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsub(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vnmsub_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsub(vuint8m8_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsub_vv_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsub(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsub_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsub(vuint8mf2_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsub_vv_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsub(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsub_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsub(vuint8mf4_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsub_vv_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsub(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsub_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsub(vuint8mf8_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsub_vv_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsub(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsub_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsub(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vnmsub_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsub(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vnmsub_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsub(vuint16m2_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vnmsub_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsub(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vnmsub_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsub(vuint16m4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vnmsub_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsub(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vnmsub_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsub(vuint16m8_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vnmsub_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsub(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vnmsub_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsub(vuint16mf2_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsub_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsub(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsub_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsub(vuint16mf4_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsub_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsub(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsub_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsub(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vnmsub_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsub(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vnmsub_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsub(vuint32m2_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vnmsub_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsub(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vnmsub_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsub(vuint32m4_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vnmsub_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsub(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vnmsub_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsub(vuint32m8_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vnmsub_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsub(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vnmsub_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsub(vuint32mf2_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsub_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsub(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsub_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsub(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vnmsub_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsub(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vnmsub_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsub(vuint64m2_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vnmsub_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsub(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vnmsub_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsub(vuint64m4_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vnmsub_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsub(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vnmsub_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsub(vuint64m8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vnmsub_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsub(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vnmsub_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnmsub(vuint8m1_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vnmsub_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vnmsub(vbool8_t op0, vuint8m1_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vnmsub_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnmsub(vuint8m2_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vnmsub_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vnmsub(vbool4_t op0, vuint8m2_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vnmsub_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnmsub(vuint8m4_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vnmsub_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vnmsub(vbool2_t op0, vuint8m4_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vnmsub_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vnmsub(vuint8m8_t op0, uint8_t op1, vuint8m8_t op2, size_t op3){
  return vnmsub_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vnmsub(vbool1_t op0, vuint8m8_t op1, uint8_t op2, vuint8m8_t op3, size_t op4){
  return vnmsub_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnmsub(vuint8mf2_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vnmsub_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vnmsub(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vnmsub_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnmsub(vuint8mf4_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vnmsub_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vnmsub(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vnmsub_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnmsub(vuint8mf8_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vnmsub_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vnmsub(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vnmsub_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnmsub(vuint16m1_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vnmsub_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vnmsub(vbool16_t op0, vuint16m1_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vnmsub_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnmsub(vuint16m2_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vnmsub_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vnmsub(vbool8_t op0, vuint16m2_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vnmsub_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnmsub(vuint16m4_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vnmsub_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vnmsub(vbool4_t op0, vuint16m4_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vnmsub_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vnmsub(vuint16m8_t op0, uint16_t op1, vuint16m8_t op2, size_t op3){
  return vnmsub_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vnmsub(vbool2_t op0, vuint16m8_t op1, uint16_t op2, vuint16m8_t op3, size_t op4){
  return vnmsub_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnmsub(vuint16mf2_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vnmsub_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vnmsub(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vnmsub_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnmsub(vuint16mf4_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vnmsub_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vnmsub(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vnmsub_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnmsub(vuint32m1_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vnmsub_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vnmsub(vbool32_t op0, vuint32m1_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vnmsub_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnmsub(vuint32m2_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vnmsub_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vnmsub(vbool16_t op0, vuint32m2_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vnmsub_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnmsub(vuint32m4_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vnmsub_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vnmsub(vbool8_t op0, vuint32m4_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vnmsub_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vnmsub(vuint32m8_t op0, uint32_t op1, vuint32m8_t op2, size_t op3){
  return vnmsub_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vnmsub(vbool4_t op0, vuint32m8_t op1, uint32_t op2, vuint32m8_t op3, size_t op4){
  return vnmsub_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnmsub(vuint32mf2_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vnmsub_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vnmsub(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vnmsub_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vnmsub(vuint64m1_t op0, uint64_t op1, vuint64m1_t op2, size_t op3){
  return vnmsub_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vnmsub(vbool64_t op0, vuint64m1_t op1, uint64_t op2, vuint64m1_t op3, size_t op4){
  return vnmsub_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vnmsub(vuint64m2_t op0, uint64_t op1, vuint64m2_t op2, size_t op3){
  return vnmsub_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vnmsub(vbool32_t op0, vuint64m2_t op1, uint64_t op2, vuint64m2_t op3, size_t op4){
  return vnmsub_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vnmsub(vuint64m4_t op0, uint64_t op1, vuint64m4_t op2, size_t op3){
  return vnmsub_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vnmsub(vbool16_t op0, vuint64m4_t op1, uint64_t op2, vuint64m4_t op3, size_t op4){
  return vnmsub_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vnmsub(vuint64m8_t op0, uint64_t op1, vuint64m8_t op2, size_t op3){
  return vnmsub_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vnmsub(vbool8_t op0, vuint64m8_t op1, uint64_t op2, vuint64m8_t op3, size_t op4){
  return vnmsub_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m1_t op1, size_t op2){
  return vse64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, int64_t * op1, vint64m1_t op2, size_t op3){
  return vse64_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m2_t op1, size_t op2){
  return vse64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, int64_t * op1, vint64m2_t op2, size_t op3){
  return vse64_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m4_t op1, size_t op2){
  return vse64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, int64_t * op1, vint64m4_t op2, size_t op3){
  return vse64_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(int64_t * op0, vint64m8_t op1, size_t op2){
  return vse64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, int64_t * op1, vint64m8_t op2, size_t op3){
  return vse64_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vuint16mf4_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccu_vv_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vuint16mf2_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccu_vv_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmaccu(vuint16m1_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccu_vv_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwmaccu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmaccu(vuint16m2_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccu_vv_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vwmaccu(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmaccu(vuint16m4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccu_vv_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vwmaccu(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmaccu(vuint16m8_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccu_vv_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vwmaccu(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vuint32mf2_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccu_vv_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmaccu(vuint32m1_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccu_vv_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwmaccu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmaccu(vuint32m2_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccu_vv_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vwmaccu(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmaccu(vuint32m4_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccu_vv_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vwmaccu(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmaccu(vuint32m8_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccu_vv_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vwmaccu(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmaccu(vuint64m1_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccu_vv_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwmaccu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmaccu(vuint64m2_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccu_vv_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vwmaccu(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmaccu(vuint64m4_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccu_vv_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vwmaccu(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmaccu(vuint64m8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccu_vv_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vwmaccu(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vuint16mf4_t op0, uint8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccu_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vwmaccu(vbool64_t op0, vuint16mf4_t op1, uint8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vuint16mf2_t op0, uint8_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccu_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vwmaccu(vbool32_t op0, vuint16mf2_t op1, uint8_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwmaccu(vuint16m1_t op0, uint8_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccu_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwmaccu(vbool16_t op0, vuint16m1_t op1, uint8_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vwmaccu(vuint16m2_t op0, uint8_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccu_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vwmaccu(vbool8_t op0, vuint16m2_t op1, uint8_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vwmaccu(vuint16m4_t op0, uint8_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccu_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vwmaccu(vbool4_t op0, vuint16m4_t op1, uint8_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vwmaccu(vuint16m8_t op0, uint8_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccu_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vwmaccu(vbool2_t op0, vuint16m8_t op1, uint8_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vuint32mf2_t op0, uint16_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccu_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vwmaccu(vbool64_t op0, vuint32mf2_t op1, uint16_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwmaccu(vuint32m1_t op0, uint16_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccu_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwmaccu(vbool32_t op0, vuint32m1_t op1, uint16_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vwmaccu(vuint32m2_t op0, uint16_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccu_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vwmaccu(vbool16_t op0, vuint32m2_t op1, uint16_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vwmaccu(vuint32m4_t op0, uint16_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccu_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vwmaccu(vbool8_t op0, vuint32m4_t op1, uint16_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vwmaccu(vuint32m8_t op0, uint16_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccu_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vwmaccu(vbool4_t op0, vuint32m8_t op1, uint16_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwmaccu(vuint64m1_t op0, uint32_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccu_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwmaccu(vbool64_t op0, vuint64m1_t op1, uint32_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vwmaccu(vuint64m2_t op0, uint32_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccu_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vwmaccu(vbool32_t op0, vuint64m2_t op1, uint32_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vwmaccu(vuint64m4_t op0, uint32_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccu_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vwmaccu(vbool16_t op0, vuint64m4_t op1, uint32_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vwmaccu(vuint64m8_t op0, uint32_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccu_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vwmaccu(vbool8_t op0, vuint64m8_t op1, uint32_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmacc(vint16mf4_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vwmacc_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmacc(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vwmacc_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmacc(vint16mf2_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vwmacc_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmacc(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vwmacc_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmacc(vint16m1_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vwmacc_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmacc(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vwmacc_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmacc(vint16m2_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vwmacc_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmacc(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vwmacc_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmacc(vint16m4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vwmacc_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmacc(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vwmacc_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmacc(vint16m8_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vwmacc_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmacc(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vwmacc_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmacc(vint32mf2_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vwmacc_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmacc(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vwmacc_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmacc(vint32m1_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vwmacc_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmacc(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vwmacc_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmacc(vint32m2_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vwmacc_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmacc(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vwmacc_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmacc(vint32m4_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vwmacc_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmacc(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vwmacc_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmacc(vint32m8_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vwmacc_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmacc(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vwmacc_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmacc(vint64m1_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vwmacc_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmacc(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vwmacc_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmacc(vint64m2_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vwmacc_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmacc(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vwmacc_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmacc(vint64m4_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vwmacc_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmacc(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vwmacc_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmacc(vint64m8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vwmacc_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmacc(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vwmacc_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmacc(vint16mf4_t op0, int8_t op1, vint8mf8_t op2, size_t op3){
  return vwmacc_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmacc(vbool64_t op0, vint16mf4_t op1, int8_t op2, vint8mf8_t op3, size_t op4){
  return vwmacc_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmacc(vint16mf2_t op0, int8_t op1, vint8mf4_t op2, size_t op3){
  return vwmacc_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmacc(vbool32_t op0, vint16mf2_t op1, int8_t op2, vint8mf4_t op3, size_t op4){
  return vwmacc_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmacc(vint16m1_t op0, int8_t op1, vint8mf2_t op2, size_t op3){
  return vwmacc_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmacc(vbool16_t op0, vint16m1_t op1, int8_t op2, vint8mf2_t op3, size_t op4){
  return vwmacc_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmacc(vint16m2_t op0, int8_t op1, vint8m1_t op2, size_t op3){
  return vwmacc_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmacc(vbool8_t op0, vint16m2_t op1, int8_t op2, vint8m1_t op3, size_t op4){
  return vwmacc_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmacc(vint16m4_t op0, int8_t op1, vint8m2_t op2, size_t op3){
  return vwmacc_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmacc(vbool4_t op0, vint16m4_t op1, int8_t op2, vint8m2_t op3, size_t op4){
  return vwmacc_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmacc(vint16m8_t op0, int8_t op1, vint8m4_t op2, size_t op3){
  return vwmacc_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmacc(vbool2_t op0, vint16m8_t op1, int8_t op2, vint8m4_t op3, size_t op4){
  return vwmacc_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmacc(vint32mf2_t op0, int16_t op1, vint16mf4_t op2, size_t op3){
  return vwmacc_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmacc(vbool64_t op0, vint32mf2_t op1, int16_t op2, vint16mf4_t op3, size_t op4){
  return vwmacc_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmacc(vint32m1_t op0, int16_t op1, vint16mf2_t op2, size_t op3){
  return vwmacc_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmacc(vbool32_t op0, vint32m1_t op1, int16_t op2, vint16mf2_t op3, size_t op4){
  return vwmacc_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmacc(vint32m2_t op0, int16_t op1, vint16m1_t op2, size_t op3){
  return vwmacc_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmacc(vbool16_t op0, vint32m2_t op1, int16_t op2, vint16m1_t op3, size_t op4){
  return vwmacc_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmacc(vint32m4_t op0, int16_t op1, vint16m2_t op2, size_t op3){
  return vwmacc_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmacc(vbool8_t op0, vint32m4_t op1, int16_t op2, vint16m2_t op3, size_t op4){
  return vwmacc_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmacc(vint32m8_t op0, int16_t op1, vint16m4_t op2, size_t op3){
  return vwmacc_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmacc(vbool4_t op0, vint32m8_t op1, int16_t op2, vint16m4_t op3, size_t op4){
  return vwmacc_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmacc(vint64m1_t op0, int32_t op1, vint32mf2_t op2, size_t op3){
  return vwmacc_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmacc(vbool64_t op0, vint64m1_t op1, int32_t op2, vint32mf2_t op3, size_t op4){
  return vwmacc_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmacc(vint64m2_t op0, int32_t op1, vint32m1_t op2, size_t op3){
  return vwmacc_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmacc(vbool32_t op0, vint64m2_t op1, int32_t op2, vint32m1_t op3, size_t op4){
  return vwmacc_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmacc(vint64m4_t op0, int32_t op1, vint32m2_t op2, size_t op3){
  return vwmacc_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmacc(vbool16_t op0, vint64m4_t op1, int32_t op2, vint32m2_t op3, size_t op4){
  return vwmacc_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmacc(vint64m8_t op0, int32_t op1, vint32m4_t op2, size_t op3){
  return vwmacc_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmacc(vbool8_t op0, vint64m8_t op1, int32_t op2, vint32m4_t op3, size_t op4){
  return vwmacc_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vint16mf4_t op0, vint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccsu_vv_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccsu_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vint16mf2_t op0, vint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccsu_vv_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccsu_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccsu(vint16m1_t op0, vint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccsu_vv_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccsu(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccsu_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccsu(vint16m2_t op0, vint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccsu_vv_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccsu(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccsu_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccsu(vint16m4_t op0, vint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccsu_vv_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccsu(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccsu_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccsu(vint16m8_t op0, vint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccsu_vv_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccsu(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccsu_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vint32mf2_t op0, vint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccsu_vv_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccsu_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccsu(vint32m1_t op0, vint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccsu_vv_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccsu(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccsu_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccsu(vint32m2_t op0, vint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccsu_vv_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccsu(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccsu_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccsu(vint32m4_t op0, vint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccsu_vv_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccsu(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccsu_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccsu(vint32m8_t op0, vint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccsu_vv_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccsu(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccsu_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccsu(vint64m1_t op0, vint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccsu_vv_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccsu(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccsu_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccsu(vint64m2_t op0, vint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccsu_vv_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccsu(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccsu_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccsu(vint64m4_t op0, vint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccsu_vv_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccsu(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccsu_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccsu(vint64m8_t op0, vint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccsu_vv_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccsu(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccsu_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vint16mf4_t op0, int8_t op1, vuint8mf8_t op2, size_t op3){
  return vwmaccsu_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccsu(vbool64_t op0, vint16mf4_t op1, int8_t op2, vuint8mf8_t op3, size_t op4){
  return vwmaccsu_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vint16mf2_t op0, int8_t op1, vuint8mf4_t op2, size_t op3){
  return vwmaccsu_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccsu(vbool32_t op0, vint16mf2_t op1, int8_t op2, vuint8mf4_t op3, size_t op4){
  return vwmaccsu_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccsu(vint16m1_t op0, int8_t op1, vuint8mf2_t op2, size_t op3){
  return vwmaccsu_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccsu(vbool16_t op0, vint16m1_t op1, int8_t op2, vuint8mf2_t op3, size_t op4){
  return vwmaccsu_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccsu(vint16m2_t op0, int8_t op1, vuint8m1_t op2, size_t op3){
  return vwmaccsu_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccsu(vbool8_t op0, vint16m2_t op1, int8_t op2, vuint8m1_t op3, size_t op4){
  return vwmaccsu_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccsu(vint16m4_t op0, int8_t op1, vuint8m2_t op2, size_t op3){
  return vwmaccsu_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccsu(vbool4_t op0, vint16m4_t op1, int8_t op2, vuint8m2_t op3, size_t op4){
  return vwmaccsu_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccsu(vint16m8_t op0, int8_t op1, vuint8m4_t op2, size_t op3){
  return vwmaccsu_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccsu(vbool2_t op0, vint16m8_t op1, int8_t op2, vuint8m4_t op3, size_t op4){
  return vwmaccsu_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vint32mf2_t op0, int16_t op1, vuint16mf4_t op2, size_t op3){
  return vwmaccsu_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccsu(vbool64_t op0, vint32mf2_t op1, int16_t op2, vuint16mf4_t op3, size_t op4){
  return vwmaccsu_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccsu(vint32m1_t op0, int16_t op1, vuint16mf2_t op2, size_t op3){
  return vwmaccsu_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccsu(vbool32_t op0, vint32m1_t op1, int16_t op2, vuint16mf2_t op3, size_t op4){
  return vwmaccsu_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccsu(vint32m2_t op0, int16_t op1, vuint16m1_t op2, size_t op3){
  return vwmaccsu_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccsu(vbool16_t op0, vint32m2_t op1, int16_t op2, vuint16m1_t op3, size_t op4){
  return vwmaccsu_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccsu(vint32m4_t op0, int16_t op1, vuint16m2_t op2, size_t op3){
  return vwmaccsu_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccsu(vbool8_t op0, vint32m4_t op1, int16_t op2, vuint16m2_t op3, size_t op4){
  return vwmaccsu_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccsu(vint32m8_t op0, int16_t op1, vuint16m4_t op2, size_t op3){
  return vwmaccsu_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccsu(vbool4_t op0, vint32m8_t op1, int16_t op2, vuint16m4_t op3, size_t op4){
  return vwmaccsu_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccsu(vint64m1_t op0, int32_t op1, vuint32mf2_t op2, size_t op3){
  return vwmaccsu_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccsu(vbool64_t op0, vint64m1_t op1, int32_t op2, vuint32mf2_t op3, size_t op4){
  return vwmaccsu_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccsu(vint64m2_t op0, int32_t op1, vuint32m1_t op2, size_t op3){
  return vwmaccsu_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccsu(vbool32_t op0, vint64m2_t op1, int32_t op2, vuint32m1_t op3, size_t op4){
  return vwmaccsu_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccsu(vint64m4_t op0, int32_t op1, vuint32m2_t op2, size_t op3){
  return vwmaccsu_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccsu(vbool16_t op0, vint64m4_t op1, int32_t op2, vuint32m2_t op3, size_t op4){
  return vwmaccsu_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccsu(vint64m8_t op0, int32_t op1, vuint32m4_t op2, size_t op3){
  return vwmaccsu_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccsu(vbool8_t op0, vint64m8_t op1, int32_t op2, vuint32m4_t op3, size_t op4){
  return vwmaccsu_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vwmaccus(vint16mf4_t op0, uint8_t op1, vint8mf8_t op2, size_t op3){
  return vwmaccus_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vwmaccus(vbool64_t op0, vint16mf4_t op1, uint8_t op2, vint8mf8_t op3, size_t op4){
  return vwmaccus_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vwmaccus(vint16mf2_t op0, uint8_t op1, vint8mf4_t op2, size_t op3){
  return vwmaccus_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vwmaccus(vbool32_t op0, vint16mf2_t op1, uint8_t op2, vint8mf4_t op3, size_t op4){
  return vwmaccus_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwmaccus(vint16m1_t op0, uint8_t op1, vint8mf2_t op2, size_t op3){
  return vwmaccus_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwmaccus(vbool16_t op0, vint16m1_t op1, uint8_t op2, vint8mf2_t op3, size_t op4){
  return vwmaccus_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vwmaccus(vint16m2_t op0, uint8_t op1, vint8m1_t op2, size_t op3){
  return vwmaccus_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vwmaccus(vbool8_t op0, vint16m2_t op1, uint8_t op2, vint8m1_t op3, size_t op4){
  return vwmaccus_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vwmaccus(vint16m4_t op0, uint8_t op1, vint8m2_t op2, size_t op3){
  return vwmaccus_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vwmaccus(vbool4_t op0, vint16m4_t op1, uint8_t op2, vint8m2_t op3, size_t op4){
  return vwmaccus_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vwmaccus(vint16m8_t op0, uint8_t op1, vint8m4_t op2, size_t op3){
  return vwmaccus_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vwmaccus(vbool2_t op0, vint16m8_t op1, uint8_t op2, vint8m4_t op3, size_t op4){
  return vwmaccus_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vwmaccus(vint32mf2_t op0, uint16_t op1, vint16mf4_t op2, size_t op3){
  return vwmaccus_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vwmaccus(vbool64_t op0, vint32mf2_t op1, uint16_t op2, vint16mf4_t op3, size_t op4){
  return vwmaccus_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwmaccus(vint32m1_t op0, uint16_t op1, vint16mf2_t op2, size_t op3){
  return vwmaccus_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwmaccus(vbool32_t op0, vint32m1_t op1, uint16_t op2, vint16mf2_t op3, size_t op4){
  return vwmaccus_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vwmaccus(vint32m2_t op0, uint16_t op1, vint16m1_t op2, size_t op3){
  return vwmaccus_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vwmaccus(vbool16_t op0, vint32m2_t op1, uint16_t op2, vint16m1_t op3, size_t op4){
  return vwmaccus_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vwmaccus(vint32m4_t op0, uint16_t op1, vint16m2_t op2, size_t op3){
  return vwmaccus_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vwmaccus(vbool8_t op0, vint32m4_t op1, uint16_t op2, vint16m2_t op3, size_t op4){
  return vwmaccus_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vwmaccus(vint32m8_t op0, uint16_t op1, vint16m4_t op2, size_t op3){
  return vwmaccus_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vwmaccus(vbool4_t op0, vint32m8_t op1, uint16_t op2, vint16m4_t op3, size_t op4){
  return vwmaccus_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwmaccus(vint64m1_t op0, uint32_t op1, vint32mf2_t op2, size_t op3){
  return vwmaccus_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwmaccus(vbool64_t op0, vint64m1_t op1, uint32_t op2, vint32mf2_t op3, size_t op4){
  return vwmaccus_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vwmaccus(vint64m2_t op0, uint32_t op1, vint32m1_t op2, size_t op3){
  return vwmaccus_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vwmaccus(vbool32_t op0, vint64m2_t op1, uint32_t op2, vint32m1_t op3, size_t op4){
  return vwmaccus_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vwmaccus(vint64m4_t op0, uint32_t op1, vint32m2_t op2, size_t op3){
  return vwmaccus_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vwmaccus(vbool16_t op0, vint64m4_t op1, uint32_t op2, vint32m2_t op3, size_t op4){
  return vwmaccus_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vwmaccus(vint64m8_t op0, uint32_t op1, vint32m4_t op2, size_t op3){
  return vwmaccus_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vwmaccus(vbool8_t op0, vint64m8_t op1, uint32_t op2, vint32m4_t op3, size_t op4){
  return vwmaccus_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vmerge(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vmerge_vvm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmerge(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vmerge_vvm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmerge(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vmerge_vvm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmerge(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vmerge_vvm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmerge(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vmerge_vvm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmerge(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vmerge_vvm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmerge(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vmerge_vvm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmerge(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vmerge_vvm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmerge(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vmerge_vvm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmerge(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vmerge_vvm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmerge(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vmerge_vvm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmerge(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vmerge_vvm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmerge(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vmerge_vvm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmerge(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vmerge_vvm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmerge(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vmerge_vvm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmerge(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vmerge_vvm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmerge(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vmerge_vvm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmerge(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vmerge_vvm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmerge(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vmerge_vvm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmerge(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vmerge_vvm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmerge(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vmerge_vvm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmerge(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vmerge_vvm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vmerge(vbool8_t op0, vint8m1_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vmerge(vbool4_t op0, vint8m2_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vmerge(vbool2_t op0, vint8m4_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vmerge(vbool1_t op0, vint8m8_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vmerge(vbool16_t op0, vint8mf2_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vmerge(vbool32_t op0, vint8mf4_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vmerge(vbool64_t op0, vint8mf8_t op1, int8_t op2, size_t op3){
  return vmerge_vxm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vmerge(vbool16_t op0, vint16m1_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vmerge(vbool8_t op0, vint16m2_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vmerge(vbool4_t op0, vint16m4_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vmerge(vbool2_t op0, vint16m8_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vmerge(vbool32_t op0, vint16mf2_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vmerge(vbool64_t op0, vint16mf4_t op1, int16_t op2, size_t op3){
  return vmerge_vxm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vmerge(vbool32_t op0, vint32m1_t op1, int32_t op2, size_t op3){
  return vmerge_vxm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vmerge(vbool16_t op0, vint32m2_t op1, int32_t op2, size_t op3){
  return vmerge_vxm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vmerge(vbool8_t op0, vint32m4_t op1, int32_t op2, size_t op3){
  return vmerge_vxm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vmerge(vbool4_t op0, vint32m8_t op1, int32_t op2, size_t op3){
  return vmerge_vxm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vmerge(vbool64_t op0, vint32mf2_t op1, int32_t op2, size_t op3){
  return vmerge_vxm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vmerge(vbool64_t op0, vint64m1_t op1, int64_t op2, size_t op3){
  return vmerge_vxm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vmerge(vbool32_t op0, vint64m2_t op1, int64_t op2, size_t op3){
  return vmerge_vxm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vmerge(vbool16_t op0, vint64m4_t op1, int64_t op2, size_t op3){
  return vmerge_vxm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vmerge(vbool8_t op0, vint64m8_t op1, int64_t op2, size_t op3){
  return vmerge_vxm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmerge(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vmerge_vvm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmerge(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vmerge_vvm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmerge(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vmerge_vvm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmerge(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vmerge_vvm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmerge(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vmerge_vvm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmerge(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vmerge_vvm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmerge(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vmerge_vvm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmerge(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vmerge_vvm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmerge(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vmerge_vvm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmerge(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vmerge_vvm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmerge(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vmerge_vvm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmerge(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vmerge_vvm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmerge(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vmerge_vvm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmerge(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vmerge_vvm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmerge(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vmerge_vvm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmerge(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vmerge_vvm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmerge(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vmerge_vvm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmerge(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vmerge_vvm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmerge(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vmerge_vvm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmerge(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vmerge_vvm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmerge(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vmerge_vvm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmerge(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vmerge_vvm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vse64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, uint64_t * op1, vuint64m1_t op2, size_t op3){
  return vse64_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vse64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, uint64_t * op1, vuint64m2_t op2, size_t op3){
  return vse64_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vse64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, uint64_t * op1, vuint64m4_t op2, size_t op3){
  return vse64_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vse64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, uint64_t * op1, vuint64m8_t op2, size_t op3){
  return vse64_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vmerge(vbool8_t op0, vuint8m1_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vmerge(vbool4_t op0, vuint8m2_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vmerge(vbool2_t op0, vuint8m4_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vmerge(vbool1_t op0, vuint8m8_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vmerge(vbool16_t op0, vuint8mf2_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vmerge(vbool32_t op0, vuint8mf4_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vmerge(vbool64_t op0, vuint8mf8_t op1, uint8_t op2, size_t op3){
  return vmerge_vxm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vmerge(vbool16_t op0, vuint16m1_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vmerge(vbool8_t op0, vuint16m2_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vmerge(vbool4_t op0, vuint16m4_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vmerge(vbool2_t op0, vuint16m8_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vmerge(vbool32_t op0, vuint16mf2_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vmerge(vbool64_t op0, vuint16mf4_t op1, uint16_t op2, size_t op3){
  return vmerge_vxm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vmerge(vbool32_t op0, vuint32m1_t op1, uint32_t op2, size_t op3){
  return vmerge_vxm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vmerge(vbool16_t op0, vuint32m2_t op1, uint32_t op2, size_t op3){
  return vmerge_vxm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vmerge(vbool8_t op0, vuint32m4_t op1, uint32_t op2, size_t op3){
  return vmerge_vxm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vmerge(vbool4_t op0, vuint32m8_t op1, uint32_t op2, size_t op3){
  return vmerge_vxm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vmerge(vbool64_t op0, vuint32mf2_t op1, uint32_t op2, size_t op3){
  return vmerge_vxm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vmerge(vbool64_t op0, vuint64m1_t op1, uint64_t op2, size_t op3){
  return vmerge_vxm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vmerge(vbool32_t op0, vuint64m2_t op1, uint64_t op2, size_t op3){
  return vmerge_vxm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vmerge(vbool16_t op0, vuint64m4_t op1, uint64_t op2, size_t op3){
  return vmerge_vxm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vmerge(vbool8_t op0, vuint64m8_t op1, uint64_t op2, size_t op3){
  return vmerge_vxm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vsaddu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vsaddu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vsaddu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsaddu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vsaddu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vsaddu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsaddu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vsaddu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vsaddu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsaddu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vsaddu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vsaddu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsaddu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vsaddu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vsaddu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsaddu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vsaddu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vsaddu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsaddu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vsaddu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vsaddu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsaddu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vsaddu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vsaddu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsaddu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vsaddu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vsaddu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsaddu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vsaddu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vsaddu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsaddu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vsaddu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vsaddu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsaddu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vsaddu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vsaddu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsaddu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vsaddu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vsaddu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsaddu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vsaddu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vsaddu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsaddu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vsaddu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vsaddu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsaddu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vsaddu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vsaddu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsaddu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vsaddu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vsaddu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsaddu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vsaddu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vsaddu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsaddu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vsaddu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vsaddu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsaddu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vsaddu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vsaddu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsaddu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vsaddu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vsaddu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsaddu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vsaddu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vsaddu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vsaddu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vsaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vsaddu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vsaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vsaddu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vsaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vsaddu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vsaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vsaddu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vsaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vsaddu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vsaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vsaddu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vsaddu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vsaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vsaddu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vsaddu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vsaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vsaddu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vsaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vsaddu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vsaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vsaddu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vsaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vsaddu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vsaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vsaddu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vsaddu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vsaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vsaddu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vsaddu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vsaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vsaddu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vsaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vsaddu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vsaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vsaddu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vsaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vsaddu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vsaddu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vsaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vsaddu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vsaddu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vsaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vsaddu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vsaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vsaddu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vsaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vsaddu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vsaddu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vsaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vsaddu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vsadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssubu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssubu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssubu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssubu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssubu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssubu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssubu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssubu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssubu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssubu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssubu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssubu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssubu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssubu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssubu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssubu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssubu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssubu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssubu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssubu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssubu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssubu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssubu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssubu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssubu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssubu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssubu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssubu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssubu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssubu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssubu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssubu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssubu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssubu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssubu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssubu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssubu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssubu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssubu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssubu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssubu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssubu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssubu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssubu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssubu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssubu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssubu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssubu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssubu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssubu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssubu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssubu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssubu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssubu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssubu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssubu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssubu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssubu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssubu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssubu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssubu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssubu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssubu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssubu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssubu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssubu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssubu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssubu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssubu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssubu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssubu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssubu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssubu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vssubu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vssubu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssubu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssubu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssubu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssubu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssubu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssubu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vssubu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vssubu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssubu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssubu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssubu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssubu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssubu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vssubu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vssubu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssubu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssubu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssubu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssubu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vssubu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vssubu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vssub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vssub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vssub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vssub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vssub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vssub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vssub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vssub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vssub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vssub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vssub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vssub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vssub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vssub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vssub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vssub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vssub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vssub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vssub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vssub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vssub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vssub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vssub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vssub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vssub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vssub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vssub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vssub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vssub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vssub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vssub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vssub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vssub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vssub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vssub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vssub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vssub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vssub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vssub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vssub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vssub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vssub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vssub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vssub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssub(vint8m1_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssub(vint8m2_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssub(vint8m4_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssub(vint8m8_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vssub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vssub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssub(vint16m1_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssub(vint16m2_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssub(vint16m4_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssub(vint16m8_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vssub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vssub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssub(vint32m1_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssub(vint32m2_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssub(vint32m4_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssub(vint32m8_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vssub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vssub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssub(vint64m1_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssub(vint64m2_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssub(vint64m4_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssub(vint64m8_t op0, int64_t op1, size_t op2){
  return vssub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vssub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vaaddu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vaaddu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vaaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vaaddu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vaaddu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vaaddu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vaaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vaaddu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vaaddu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vaaddu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vaaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vaaddu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vaaddu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vaaddu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vaaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vaaddu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vaaddu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vaaddu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vaaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vaaddu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vaaddu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vaaddu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vaaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vaaddu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vaaddu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vaaddu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vaaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vaaddu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vaaddu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vaaddu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vaaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vaaddu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vaaddu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vaaddu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vaaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vaaddu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vaaddu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vaaddu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vaaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vaaddu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vaaddu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vaaddu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vaaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vaaddu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vaaddu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vaaddu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vaaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vaaddu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vaaddu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vaaddu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vaaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vaaddu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vaaddu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vaaddu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vaaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vaaddu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vaaddu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vaaddu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vaaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vaaddu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vaaddu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vaaddu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vaaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vaaddu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vaaddu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vaaddu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vaaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vaaddu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vaaddu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vaaddu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vaaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vaaddu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vaaddu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vaaddu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vaaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vaaddu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vaaddu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vaaddu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vaaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vaaddu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vaaddu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vaaddu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vaaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vaaddu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vaaddu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vaaddu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vaaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vaaddu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vaaddu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vaaddu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vaaddu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vaaddu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vaaddu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vaaddu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vaaddu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vaaddu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vaaddu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vaaddu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vaaddu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vaaddu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vaaddu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vaaddu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vaaddu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vaaddu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vaaddu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vaaddu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vaaddu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vaaddu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vaaddu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vaaddu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vaaddu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vaaddu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vaaddu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vaaddu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vaaddu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vaaddu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vaaddu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vaaddu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vaaddu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vaaddu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vaaddu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vaaddu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vaaddu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vaaddu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vaaddu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vaaddu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vaaddu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vaaddu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vaaddu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vaaddu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vaaddu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vaaddu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vaaddu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vaaddu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vaaddu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vaaddu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vaaddu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vaaddu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vaaddu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vaaddu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vaadd(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vaadd_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vaadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vaadd_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vaadd(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vaadd_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vaadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vaadd_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vaadd(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vaadd_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vaadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vaadd_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vaadd(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vaadd_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vaadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vaadd_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vaadd(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vaadd_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vaadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vaadd_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vaadd(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vaadd_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vaadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vaadd_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vaadd(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vaadd_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vaadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vaadd_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vaadd(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vaadd_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vaadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vaadd_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vaadd(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vaadd_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vaadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vaadd_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vaadd(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vaadd_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vaadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vaadd_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vaadd(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vaadd_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vaadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vaadd_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vaadd(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vaadd_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vaadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vaadd_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vaadd(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vaadd_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vaadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vaadd_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vaadd(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vaadd_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vaadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vaadd_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vaadd(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vaadd_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vaadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vaadd_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vaadd(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vaadd_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vaadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vaadd_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vaadd(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vaadd_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vaadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vaadd_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vaadd(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vaadd_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vaadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vaadd_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vaadd(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vaadd_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vaadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vaadd_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vaadd(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vaadd_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vaadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vaadd_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vaadd(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vaadd_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vaadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vaadd_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vaadd(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vaadd_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vaadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vaadd_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vaadd(vint8m1_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vaadd(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vaadd(vint8m2_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vaadd(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vaadd(vint8m4_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vaadd(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vaadd(vint8m8_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vaadd(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vaadd(vint8mf2_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vaadd(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vaadd(vint8mf4_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vaadd(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vaadd(vint8mf8_t op0, int8_t op1, size_t op2){
  return vaadd_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vaadd(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vaadd_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vaadd(vint16m1_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vaadd(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vaadd(vint16m2_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vaadd(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vaadd(vint16m4_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vaadd(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vaadd(vint16m8_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vaadd(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vaadd(vint16mf2_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vaadd(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vaadd(vint16mf4_t op0, int16_t op1, size_t op2){
  return vaadd_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vaadd(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vaadd_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vaadd(vint32m1_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vaadd(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vaadd(vint32m2_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vaadd(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vaadd(vint32m4_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vaadd(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vaadd(vint32m8_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vaadd(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vaadd(vint32mf2_t op0, int32_t op1, size_t op2){
  return vaadd_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vaadd(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vaadd_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vaadd(vint64m1_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vaadd(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vaadd(vint64m2_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vaadd(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vaadd(vint64m4_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vaadd(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vaadd(vint64m8_t op0, int64_t op1, size_t op2){
  return vaadd_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vaadd(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vaadd_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vasubu(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vasubu_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vasubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vasubu_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vasubu(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vasubu_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vasubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vasubu_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vasubu(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vasubu_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vasubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vasubu_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vasubu(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vasubu_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vasubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vasubu_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vasubu(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vasubu_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vasubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vasubu_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vasubu(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vasubu_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vasubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vasubu_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vasubu(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vasubu_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vasubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vasubu_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vasubu(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vasubu_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vasubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vasubu_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vasubu(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vasubu_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vasubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vasubu_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vasubu(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vasubu_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vasubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vasubu_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vasubu(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vasubu_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vasubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vasubu_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vasubu(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vasubu_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vasubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vasubu_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vasubu(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vasubu_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vasubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vasubu_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vasubu(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vasubu_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vasubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vasubu_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vasubu(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vasubu_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vasubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vasubu_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vasubu(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vasubu_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vasubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vasubu_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vasubu(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vasubu_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vasubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vasubu_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vasubu(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vasubu_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vasubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vasubu_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vasubu(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vasubu_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vasubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vasubu_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vasubu(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vasubu_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vasubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vasubu_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vasubu(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vasubu_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vasubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vasubu_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vasubu(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vasubu_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vasubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vasubu_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vasubu(vuint8m1_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vasubu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vasubu(vuint8m2_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vasubu(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vasubu(vuint8m4_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vasubu(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vasubu(vuint8m8_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vasubu(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vasubu(vuint8mf2_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vasubu(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vasubu(vuint8mf4_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vasubu(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vasubu(vuint8mf8_t op0, uint8_t op1, size_t op2){
  return vasubu_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vasubu(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, uint8_t op3, size_t op4){
  return vasubu_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vasubu(vuint16m1_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vasubu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vasubu(vuint16m2_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vasubu(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vasubu(vuint16m4_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vasubu(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vasubu(vuint16m8_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vasubu(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vasubu(vuint16mf2_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vasubu(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vasubu(vuint16mf4_t op0, uint16_t op1, size_t op2){
  return vasubu_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vasubu(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, uint16_t op3, size_t op4){
  return vasubu_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vasubu(vuint32m1_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vasubu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vasubu(vuint32m2_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vasubu(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vasubu(vuint32m4_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vasubu(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vasubu(vuint32m8_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vasubu(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vasubu(vuint32mf2_t op0, uint32_t op1, size_t op2){
  return vasubu_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vasubu(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, uint32_t op3, size_t op4){
  return vasubu_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vasubu(vuint64m1_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vasubu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vasubu(vuint64m2_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vasubu(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vasubu(vuint64m4_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vasubu(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vasubu(vuint64m8_t op0, uint64_t op1, size_t op2){
  return vasubu_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vasubu(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, uint64_t op3, size_t op4){
  return vasubu_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vasub(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vasub_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vasub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vasub_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vasub(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vasub_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vasub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vasub_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vasub(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vasub_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vasub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vasub_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vasub(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vasub_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vasub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vasub_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vasub(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vasub_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vasub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vasub_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vasub(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vasub_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vasub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vasub_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vasub(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vasub_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vasub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vasub_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vasub(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vasub_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vasub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vasub_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vasub(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vasub_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vasub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vasub_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vasub(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vasub_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vasub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vasub_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vasub(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vasub_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vasub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vasub_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vasub(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vasub_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vasub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vasub_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vasub(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vasub_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vasub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vasub_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vasub(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vasub_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vasub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vasub_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vasub(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vasub_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vasub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vasub_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vasub(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vasub_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vasub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vasub_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vasub(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vasub_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vasub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vasub_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vasub(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vasub_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vasub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vasub_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vasub(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vasub_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vasub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vasub_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vasub(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vasub_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vasub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vasub_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vasub(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vasub_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vasub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vasub_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vasub(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vasub_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vasub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vasub_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vasub(vint8m1_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vasub(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vasub(vint8m2_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vasub(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vasub(vint8m4_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vasub(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vasub(vint8m8_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vasub(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vasub(vint8mf2_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vasub(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vasub(vint8mf4_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vasub(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vasub(vint8mf8_t op0, int8_t op1, size_t op2){
  return vasub_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vasub(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vasub_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vasub(vint16m1_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vasub(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vasub(vint16m2_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vasub(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vasub(vint16m4_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vasub(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vasub(vint16m8_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vasub(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vasub(vint16mf2_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vasub(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vasub(vint16mf4_t op0, int16_t op1, size_t op2){
  return vasub_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vasub(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vasub_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vasub(vint32m1_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vasub(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vasub(vint32m2_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vasub(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vasub(vint32m4_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vasub(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vasub(vint32m8_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vasub(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vasub(vint32mf2_t op0, int32_t op1, size_t op2){
  return vasub_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vasub(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vasub_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vasub(vint64m1_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vasub(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vasub(vint64m2_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vasub(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vasub(vint64m4_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vasub(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vasub(vint64m8_t op0, int64_t op1, size_t op2){
  return vasub_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vasub(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vasub_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsmul(vint8m1_t op0, vint8m1_t op1, size_t op2){
  return vsmul_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vsmul_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsmul(vint8m2_t op0, vint8m2_t op1, size_t op2){
  return vsmul_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vint8m2_t op3, size_t op4){
  return vsmul_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsmul(vint8m4_t op0, vint8m4_t op1, size_t op2){
  return vsmul_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vint8m4_t op3, size_t op4){
  return vsmul_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsmul(vint8m8_t op0, vint8m8_t op1, size_t op2){
  return vsmul_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vint8m8_t op3, size_t op4){
  return vsmul_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsmul(vint8mf2_t op0, vint8mf2_t op1, size_t op2){
  return vsmul_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vint8mf2_t op3, size_t op4){
  return vsmul_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsmul(vint8mf4_t op0, vint8mf4_t op1, size_t op2){
  return vsmul_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vint8mf4_t op3, size_t op4){
  return vsmul_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsmul(vint8mf8_t op0, vint8mf8_t op1, size_t op2){
  return vsmul_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vint8mf8_t op3, size_t op4){
  return vsmul_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsmul(vint16m1_t op0, vint16m1_t op1, size_t op2){
  return vsmul_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vsmul_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsmul(vint16m2_t op0, vint16m2_t op1, size_t op2){
  return vsmul_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vint16m2_t op3, size_t op4){
  return vsmul_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsmul(vint16m4_t op0, vint16m4_t op1, size_t op2){
  return vsmul_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vint16m4_t op3, size_t op4){
  return vsmul_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsmul(vint16m8_t op0, vint16m8_t op1, size_t op2){
  return vsmul_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vint16m8_t op3, size_t op4){
  return vsmul_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsmul(vint16mf2_t op0, vint16mf2_t op1, size_t op2){
  return vsmul_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vint16mf2_t op3, size_t op4){
  return vsmul_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsmul(vint16mf4_t op0, vint16mf4_t op1, size_t op2){
  return vsmul_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vint16mf4_t op3, size_t op4){
  return vsmul_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsmul(vint32m1_t op0, vint32m1_t op1, size_t op2){
  return vsmul_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vsmul_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsmul(vint32m2_t op0, vint32m2_t op1, size_t op2){
  return vsmul_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vint32m2_t op3, size_t op4){
  return vsmul_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsmul(vint32m4_t op0, vint32m4_t op1, size_t op2){
  return vsmul_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vint32m4_t op3, size_t op4){
  return vsmul_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsmul(vint32m8_t op0, vint32m8_t op1, size_t op2){
  return vsmul_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vint32m8_t op3, size_t op4){
  return vsmul_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsmul(vint32mf2_t op0, vint32mf2_t op1, size_t op2){
  return vsmul_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vint32mf2_t op3, size_t op4){
  return vsmul_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsmul(vint64m1_t op0, vint64m1_t op1, size_t op2){
  return vsmul_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vsmul_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsmul(vint64m2_t op0, vint64m2_t op1, size_t op2){
  return vsmul_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vint64m2_t op3, size_t op4){
  return vsmul_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsmul(vint64m4_t op0, vint64m4_t op1, size_t op2){
  return vsmul_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vint64m4_t op3, size_t op4){
  return vsmul_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsmul(vint64m8_t op0, vint64m8_t op1, size_t op2){
  return vsmul_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vint64m8_t op3, size_t op4){
  return vsmul_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vsmul(vint8m1_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vsmul(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vsmul(vint8m2_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vsmul(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vsmul(vint8m4_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vsmul(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vsmul(vint8m8_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vsmul(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vsmul(vint8mf2_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vsmul(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vsmul(vint8mf4_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vsmul(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vsmul(vint8mf8_t op0, int8_t op1, size_t op2){
  return vsmul_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vsmul(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vsmul_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vsmul(vint16m1_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vsmul(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vsmul(vint16m2_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vsmul(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vsmul(vint16m4_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vsmul(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vsmul(vint16m8_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vsmul(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vsmul(vint16mf2_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vsmul(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vsmul(vint16mf4_t op0, int16_t op1, size_t op2){
  return vsmul_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsmul(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vsmul_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vsmul(vint32m1_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vsmul(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vsmul(vint32m2_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vsmul(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vsmul(vint32m4_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vsmul(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vsmul(vint32m8_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vsmul(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vsmul(vint32mf2_t op0, int32_t op1, size_t op2){
  return vsmul_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vsmul(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vsmul_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vsmul(vint64m1_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vsmul(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vsmul(vint64m2_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vsmul(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vsmul(vint64m4_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vsmul(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vsmul(vint64m8_t op0, int64_t op1, size_t op2){
  return vsmul_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vsmul(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vsmul_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssrl(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssrl_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssrl_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssrl(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssrl_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssrl_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssrl(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssrl_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssrl_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssrl(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssrl_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssrl_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssrl(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssrl_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssrl_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssrl(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssrl_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssrl_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssrl(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssrl_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssrl_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssrl(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssrl_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssrl_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssrl(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssrl_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssrl_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssrl(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssrl_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssrl_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssrl(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssrl_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssrl_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssrl(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssrl_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssrl_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssrl(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssrl_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssrl_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssrl(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssrl_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssrl_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssrl(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssrl_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssrl_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssrl(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssrl_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssrl_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssrl(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssrl_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssrl_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssrl(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssrl_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssrl_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssrl(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssrl_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssrl_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssrl(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssrl_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssrl_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssrl(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssrl_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssrl_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssrl(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssrl_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssrl_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vlse16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vlse16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vlse16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vlse16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vlse16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vlse16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vssrl(vuint8m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vssrl(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vssrl(vuint8m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vssrl(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vssrl(vuint8m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vssrl(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vssrl(vuint8m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vssrl(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vssrl(vuint8mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vssrl(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vssrl(vuint8mf4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vssrl(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vssrl(vuint8mf8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vssrl(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vssrl(vuint16m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vssrl(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vssrl(vuint16m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vssrl(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vssrl(vuint16m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vssrl(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vssrl(vuint16m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vssrl(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vssrl(vuint16mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vssrl(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vssrl(vuint16mf4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vssrl(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vssrl(vuint32m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vssrl(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vssrl(vuint32m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vssrl(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vssrl(vuint32m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vssrl(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vssrl(vuint32m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vssrl(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vssrl(vuint32mf2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vssrl(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vssrl(vuint64m1_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vssrl(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vssrl(vuint64m2_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vssrl(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vssrl(vuint64m4_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vssrl(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vssrl(vuint64m8_t op0, size_t op1, size_t op2){
  return vssrl_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vssrl(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vssrl_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssra(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vssra_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vssra_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssra(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vssra_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vssra_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssra(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vssra_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vssra_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssra(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vssra_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vssra_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssra(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vssra_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vssra_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssra(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vssra_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vssra_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssra(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vssra_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vssra_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssra(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vssra_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vssra_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssra(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vssra_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vssra_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssra(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vssra_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vssra_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssra(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vssra_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vssra_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssra(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vssra_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vssra_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssra(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vssra_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vssra_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssra(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vssra_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vssra_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssra(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vssra_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vssra_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssra(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vssra_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vssra_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssra(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vssra_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vssra_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssra(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vssra_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vssra_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssra(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vssra_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vssra_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssra(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vssra_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vssra_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssra(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vssra_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vssra_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssra(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vssra_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vssra_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vssra(vint8m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vssra(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vssra(vint8m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vssra(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vssra(vint8m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vssra(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vssra(vint8m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vssra(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vssra(vint8mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vssra(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vssra(vint8mf4_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vssra(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vssra(vint8mf8_t op0, size_t op1, size_t op2){
  return vssra_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vssra(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vssra_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vssra(vint16m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vssra(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vssra(vint16m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vssra(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vssra(vint16m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vssra(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vssra(vint16m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vssra(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vssra(vint16mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vssra(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vssra(vint16mf4_t op0, size_t op1, size_t op2){
  return vssra_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vssra(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vssra_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vssra(vint32m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vssra(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vssra(vint32m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vssra(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vssra(vint32m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vssra(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vssra(vint32m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vssra(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vssra(vint32mf2_t op0, size_t op1, size_t op2){
  return vssra_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vssra(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vssra_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vssra(vint64m1_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vssra(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vssra(vint64m2_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vssra(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vssra(vint64m4_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vssra(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vssra(vint64m8_t op0, size_t op1, size_t op2){
  return vssra_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vssra(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vssra_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnclipu(vuint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnclipu_wv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnclipu(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnclipu_wv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnclipu(vuint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnclipu_wv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnclipu(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnclipu_wv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnclipu(vuint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnclipu_wv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnclipu(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnclipu_wv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnclipu(vuint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnclipu_wv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnclipu(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnclipu_wv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnclipu(vuint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnclipu_wv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnclipu(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnclipu_wv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnclipu(vuint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnclipu_wv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnclipu(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnclipu_wv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnclipu(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnclipu_wv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnclipu(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnclipu_wv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnclipu(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnclipu_wv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnclipu(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnclipu_wv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnclipu(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnclipu_wv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnclipu(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnclipu_wv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnclipu(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnclipu_wv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnclipu(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnclipu_wv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnclipu(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnclipu_wv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnclipu(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnclipu_wv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnclipu(vuint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnclipu_wv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnclipu(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnclipu_wv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnclipu(vuint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnclipu_wv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnclipu(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnclipu_wv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnclipu(vuint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnclipu_wv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnclipu(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnclipu_wv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnclipu(vuint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnclipu_wv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnclipu(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnclipu_wv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vnclipu(vuint16m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vnclipu(vbool8_t op0, vuint8m1_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vnclipu(vuint16m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vnclipu(vbool4_t op0, vuint8m2_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vnclipu(vuint16m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vnclipu(vbool2_t op0, vuint8m4_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vnclipu(vuint16m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vnclipu(vbool16_t op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vnclipu(vuint16mf2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vnclipu(vbool32_t op0, vuint8mf4_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vnclipu(vuint16mf4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vnclipu(vbool64_t op0, vuint8mf8_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vnclipu(vuint32m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vnclipu(vbool16_t op0, vuint16m1_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vnclipu(vuint32m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vnclipu(vbool8_t op0, vuint16m2_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vnclipu(vuint32m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vnclipu(vbool4_t op0, vuint16m4_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vnclipu(vuint32m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vnclipu(vbool32_t op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vnclipu(vuint32mf2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vnclipu(vbool64_t op0, vuint16mf4_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vnclipu(vuint64m2_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vnclipu(vbool32_t op0, vuint32m1_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vnclipu(vuint64m4_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vnclipu(vbool16_t op0, vuint32m2_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vnclipu(vuint64m8_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vnclipu(vbool8_t op0, vuint32m4_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vnclipu(vuint64m1_t op0, size_t op1, size_t op2){
  return vnclipu_wx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vnclipu(vbool64_t op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vnclipu_wx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnclip(vint16m2_t op0, vuint8m1_t op1, size_t op2){
  return vnclip_wv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnclip(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, vuint8m1_t op3, size_t op4){
  return vnclip_wv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnclip(vint16m4_t op0, vuint8m2_t op1, size_t op2){
  return vnclip_wv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnclip(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, vuint8m2_t op3, size_t op4){
  return vnclip_wv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnclip(vint16m8_t op0, vuint8m4_t op1, size_t op2){
  return vnclip_wv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnclip(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, vuint8m4_t op3, size_t op4){
  return vnclip_wv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnclip(vint16m1_t op0, vuint8mf2_t op1, size_t op2){
  return vnclip_wv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnclip(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, vuint8mf2_t op3, size_t op4){
  return vnclip_wv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnclip(vint16mf2_t op0, vuint8mf4_t op1, size_t op2){
  return vnclip_wv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnclip(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, vuint8mf4_t op3, size_t op4){
  return vnclip_wv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnclip(vint16mf4_t op0, vuint8mf8_t op1, size_t op2){
  return vnclip_wv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnclip(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, vuint8mf8_t op3, size_t op4){
  return vnclip_wv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnclip(vint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vnclip_wv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnclip(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vnclip_wv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnclip(vint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vnclip_wv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnclip(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vnclip_wv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnclip(vint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vnclip_wv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnclip(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vnclip_wv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnclip(vint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vnclip_wv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnclip(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vnclip_wv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnclip(vint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vnclip_wv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnclip(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vnclip_wv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnclip(vint64m2_t op0, vuint32m1_t op1, size_t op2){
  return vnclip_wv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnclip(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, vuint32m1_t op3, size_t op4){
  return vnclip_wv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnclip(vint64m4_t op0, vuint32m2_t op1, size_t op2){
  return vnclip_wv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnclip(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, vuint32m2_t op3, size_t op4){
  return vnclip_wv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnclip(vint64m8_t op0, vuint32m4_t op1, size_t op2){
  return vnclip_wv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnclip(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, vuint32m4_t op3, size_t op4){
  return vnclip_wv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnclip(vint64m1_t op0, vuint32mf2_t op1, size_t op2){
  return vnclip_wv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnclip(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, vuint32mf2_t op3, size_t op4){
  return vnclip_wv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vnclip(vint16m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vnclip(vbool8_t op0, vint8m1_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vnclip(vint16m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vnclip(vbool4_t op0, vint8m2_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vnclip(vint16m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vnclip(vbool2_t op0, vint8m4_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vnclip(vint16m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vnclip(vbool16_t op0, vint8mf2_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vnclip(vint16mf2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vnclip(vbool32_t op0, vint8mf4_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vnclip(vint16mf4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vnclip(vbool64_t op0, vint8mf8_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vnclip(vint32m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vnclip(vbool16_t op0, vint16m1_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vnclip(vint32m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vnclip(vbool8_t op0, vint16m2_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vnclip(vint32m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vnclip(vbool4_t op0, vint16m4_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vnclip(vint32m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vnclip(vbool32_t op0, vint16mf2_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vnclip(vint32mf2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vnclip(vbool64_t op0, vint16mf4_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vnclip(vint64m2_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vnclip(vbool32_t op0, vint32m1_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vnclip(vint64m4_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vnclip(vbool16_t op0, vint32m2_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vnclip(vint64m8_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vnclip(vbool8_t op0, vint32m4_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vnclip(vint64m1_t op0, size_t op1, size_t op2){
  return vnclip_wx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vnclip(vbool64_t op0, vint32mf2_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vnclip_wx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vle8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vle8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vle8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vle8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vle8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vle8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vle8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, size_t op3){
  return vle8_v_u8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vlse16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vlse16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vlse16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vlse16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vlse16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vlse16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, ptrdiff_t op3, size_t op4){
  return vlse16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vlse32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vlse32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vlse32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vlse32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vlse32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vlse32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vlse32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vlse32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vlse32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vlse32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vlse64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vlse64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vlse64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vlse64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vlse64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vlse64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vlse64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vlse64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredsum(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredsum_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredsum(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredsum_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredsum(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredsum_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredsum(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredsum_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredsum(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredsum_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredsum(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredsum_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredsum(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredsum_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredsum(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredsum_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredsum(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredsum_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredsum(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredsum_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredsum(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredsum_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredsum(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredsum_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredsum(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredsum_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredsum(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredsum_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredsum(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredsum_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredsum(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredsum_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredsum(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredsum_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredsum(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredsum_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredsum(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredsum_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredsum(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredsum_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredsum(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredsum_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredsum(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredsum_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredsum(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredsum_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredsum(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredsum_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredsum(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredsum_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredsum(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredsum_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredsum(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredsum_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredsum(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredsum_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredsum(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredsum_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredsum(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredsum_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredsum(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredsum_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredsum(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredsum_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredsum(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredsum_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredsum(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredsum_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredsum(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredsum_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredsum(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredsum_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredsum(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredsum_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredsum(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredsum_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredsum(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredsum_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredsum(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredsum_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredsum(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredsum_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredsum(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredsum_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredsum(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredsum_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredsum(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredsum_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredmaxu(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredmaxu_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredmaxu(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredmaxu_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredmaxu(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredmaxu_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredmaxu(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredmaxu_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredmaxu(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredmaxu_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredmaxu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredmaxu_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredmaxu(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredmaxu_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredmaxu(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredmaxu_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredmaxu(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredmaxu_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredmaxu(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredmaxu_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredmaxu(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredmaxu_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredmaxu(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredmaxu_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredmaxu(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredmaxu_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredmaxu(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredmaxu_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredmaxu(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredmaxu_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredmaxu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredmaxu_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredmaxu(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredmaxu_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredmaxu(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredmaxu_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredmaxu(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredmaxu_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredmaxu(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredmaxu_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredmaxu(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredmaxu_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredmaxu(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredmaxu_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmax(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredmax_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmax(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredmax_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmax(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredmax_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmax(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredmax_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmax(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredmax_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmax(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredmax_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmax(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredmax_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmax(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredmax_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmax(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredmax_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmax(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredmax_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmax(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredmax_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmax(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredmax_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmax(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredmax_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmax(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredmax_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmax(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredmax_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmax(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredmax_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmax(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredmax_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmax(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredmax_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmax(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredmax_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmax(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredmax_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmax(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredmax_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmax(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredmax_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredminu(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredminu_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredminu(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredminu_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredminu(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredminu_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredminu(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredminu_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredminu(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredminu_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredminu(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredminu_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredminu(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredminu_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredminu(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredminu_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredminu(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredminu_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredminu(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredminu_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredminu(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredminu_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredminu(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredminu_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredminu(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredminu_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredminu(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredminu_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredminu(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredminu_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredminu(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredminu_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredminu(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredminu_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredminu(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredminu_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredminu(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredminu_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredminu(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredminu_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredminu(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredminu_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredminu(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredminu_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredmin(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredmin_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredmin(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredmin_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredmin(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredmin_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredmin(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredmin_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmin(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredmin_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmin(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredmin_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmin(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredmin_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmin(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredmin_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmin(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredmin_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmin(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredmin_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmin(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredmin_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmin(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredmin_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredmin(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredmin_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredmin(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredmin_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmin(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredmin_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmin(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredmin_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmin(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredmin_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmin(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredmin_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmin(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredmin_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmin(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredmin_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredmin(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredmin_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredmin(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredmin_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredand(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredand_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredand(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredand_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredand(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredand_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredand(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredand_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredand(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredand_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredand(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredand_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredand(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredand_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredand(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredand_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredand(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredand_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredand(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredand_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredand(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredand_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredand(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredand_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredand(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredand_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredand(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredand_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredand(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredand_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredand(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredand_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredand(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredand_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredand(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredand_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredand(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredand_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredand(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredand_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredand(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredand_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredand(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredand_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16m1_t op2, size_t op3){
  return vsse16_v_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool16_t op0, int16_t * op1, ptrdiff_t op2, vint16m1_t op3, size_t op4){
  return vsse16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16m2_t op2, size_t op3){
  return vsse16_v_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool8_t op0, int16_t * op1, ptrdiff_t op2, vint16m2_t op3, size_t op4){
  return vsse16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16m4_t op2, size_t op3){
  return vsse16_v_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool4_t op0, int16_t * op1, ptrdiff_t op2, vint16m4_t op3, size_t op4){
  return vsse16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16m8_t op2, size_t op3){
  return vsse16_v_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool2_t op0, int16_t * op1, ptrdiff_t op2, vint16m8_t op3, size_t op4){
  return vsse16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16mf2_t op2, size_t op3){
  return vsse16_v_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool32_t op0, int16_t * op1, ptrdiff_t op2, vint16mf2_t op3, size_t op4){
  return vsse16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(int16_t * op0, ptrdiff_t op1, vint16mf4_t op2, size_t op3){
  return vsse16_v_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool64_t op0, int16_t * op1, ptrdiff_t op2, vint16mf4_t op3, size_t op4){
  return vsse16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredand(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredand_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredand(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredand_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredand(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredand_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredand(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredand_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredand(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredand_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredand(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredand_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredand(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredand_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredand(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredand_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredand(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredand_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredand(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredand_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredand(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredand_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredand(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredand_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredand(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredand_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredand(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredand_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredand(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredand_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredand(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredand_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredand(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredand_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredand(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredand_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredand(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredand_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredand(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredand_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredand(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredand_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredand(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredand_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredor(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredor_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredor(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredor_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredor(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredor_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredor(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredor_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredor(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredor_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredor_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredor(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredor_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredor(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredor_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredor(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredor_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredor(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredor_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredor(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredor_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredor(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredor_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredor(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredor_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredor(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredor_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredor(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredor_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredor_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredor(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredor_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredor(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredor_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredor(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredor_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredor(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredor_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredor(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredor_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredor(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredor_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredor(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredor_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredor(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredor_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredor(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredor_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredor(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredor_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredor(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredor_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredor_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredor(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredor_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredor(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredor_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredor(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredor_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredor(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredor_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredor(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredor_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredor(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredor_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredor(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredor_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredor(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredor_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredor(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredor_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredor_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredor(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredor_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredor(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredor_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredor(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredor_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredor(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredor_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredor(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredor_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredor(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredor_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8m1_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8m1_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8m2_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8m2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool4_t op0, vint8m1_t op1, vint8m2_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8m2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8m4_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8m4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool2_t op0, vint8m1_t op1, vint8m4_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8m4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8m8_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8m8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool1_t op0, vint8m1_t op1, vint8m8_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8m8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8mf2_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8mf2_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool16_t op0, vint8m1_t op1, vint8mf2_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8mf2_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8mf4_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8mf4_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool32_t op0, vint8m1_t op1, vint8mf4_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8mf4_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vredxor(vint8m1_t op0, vint8mf8_t op1, vint8m1_t op2, size_t op3){
  return vredxor_vs_i8mf8_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vredxor(vbool64_t op0, vint8m1_t op1, vint8mf8_t op2, vint8m1_t op3, size_t op4){
  return vredxor_vs_i8mf8_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16m2_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool8_t op0, vint16m1_t op1, vint16m2_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16m4_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool4_t op0, vint16m1_t op1, vint16m4_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16m8_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool2_t op0, vint16m1_t op1, vint16m8_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16mf2_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool32_t op0, vint16m1_t op1, vint16mf2_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vredxor(vint16m1_t op0, vint16mf4_t op1, vint16m1_t op2, size_t op3){
  return vredxor_vs_i16mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vredxor(vbool64_t op0, vint16m1_t op1, vint16mf4_t op2, vint16m1_t op3, size_t op4){
  return vredxor_vs_i16mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredxor(vint32m1_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vredxor_vs_i32m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredxor(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vint32m1_t op3, size_t op4){
  return vredxor_vs_i32m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredxor(vint32m1_t op0, vint32m2_t op1, vint32m1_t op2, size_t op3){
  return vredxor_vs_i32m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredxor(vbool16_t op0, vint32m1_t op1, vint32m2_t op2, vint32m1_t op3, size_t op4){
  return vredxor_vs_i32m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredxor(vint32m1_t op0, vint32m4_t op1, vint32m1_t op2, size_t op3){
  return vredxor_vs_i32m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredxor(vbool8_t op0, vint32m1_t op1, vint32m4_t op2, vint32m1_t op3, size_t op4){
  return vredxor_vs_i32m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredxor(vint32m1_t op0, vint32m8_t op1, vint32m1_t op2, size_t op3){
  return vredxor_vs_i32m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredxor(vbool4_t op0, vint32m1_t op1, vint32m8_t op2, vint32m1_t op3, size_t op4){
  return vredxor_vs_i32m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vredxor(vint32m1_t op0, vint32mf2_t op1, vint32m1_t op2, size_t op3){
  return vredxor_vs_i32mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vredxor(vbool64_t op0, vint32m1_t op1, vint32mf2_t op2, vint32m1_t op3, size_t op4){
  return vredxor_vs_i32mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredxor(vint64m1_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vredxor_vs_i64m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredxor(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vint64m1_t op3, size_t op4){
  return vredxor_vs_i64m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredxor(vint64m1_t op0, vint64m2_t op1, vint64m1_t op2, size_t op3){
  return vredxor_vs_i64m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredxor(vbool32_t op0, vint64m1_t op1, vint64m2_t op2, vint64m1_t op3, size_t op4){
  return vredxor_vs_i64m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredxor(vint64m1_t op0, vint64m4_t op1, vint64m1_t op2, size_t op3){
  return vredxor_vs_i64m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredxor(vbool16_t op0, vint64m1_t op1, vint64m4_t op2, vint64m1_t op3, size_t op4){
  return vredxor_vs_i64m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vredxor(vint64m1_t op0, vint64m8_t op1, vint64m1_t op2, size_t op3){
  return vredxor_vs_i64m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vredxor(vbool8_t op0, vint64m1_t op1, vint64m8_t op2, vint64m1_t op3, size_t op4){
  return vredxor_vs_i64m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8m1_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8m1_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8m2_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8m2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool4_t op0, vuint8m1_t op1, vuint8m2_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8m2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8m4_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8m4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool2_t op0, vuint8m1_t op1, vuint8m4_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8m4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8m8_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8m8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool1_t op0, vuint8m1_t op1, vuint8m8_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8m8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8mf2_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8mf2_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool16_t op0, vuint8m1_t op1, vuint8mf2_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8mf2_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8mf4_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8mf4_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool32_t op0, vuint8m1_t op1, vuint8mf4_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8mf4_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vredxor(vuint8m1_t op0, vuint8mf8_t op1, vuint8m1_t op2, size_t op3){
  return vredxor_vs_u8mf8_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vredxor(vbool64_t op0, vuint8m1_t op1, vuint8mf8_t op2, vuint8m1_t op3, size_t op4){
  return vredxor_vs_u8mf8_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16m2_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool8_t op0, vuint16m1_t op1, vuint16m2_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16m4_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool4_t op0, vuint16m1_t op1, vuint16m4_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16m8_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool2_t op0, vuint16m1_t op1, vuint16m8_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16mf2_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool32_t op0, vuint16m1_t op1, vuint16mf2_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vredxor(vuint16m1_t op0, vuint16mf4_t op1, vuint16m1_t op2, size_t op3){
  return vredxor_vs_u16mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vredxor(vbool64_t op0, vuint16m1_t op1, vuint16mf4_t op2, vuint16m1_t op3, size_t op4){
  return vredxor_vs_u16mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredxor(vuint32m1_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vredxor_vs_u32m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredxor(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vredxor_vs_u32m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredxor(vuint32m1_t op0, vuint32m2_t op1, vuint32m1_t op2, size_t op3){
  return vredxor_vs_u32m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredxor(vbool16_t op0, vuint32m1_t op1, vuint32m2_t op2, vuint32m1_t op3, size_t op4){
  return vredxor_vs_u32m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredxor(vuint32m1_t op0, vuint32m4_t op1, vuint32m1_t op2, size_t op3){
  return vredxor_vs_u32m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredxor(vbool8_t op0, vuint32m1_t op1, vuint32m4_t op2, vuint32m1_t op3, size_t op4){
  return vredxor_vs_u32m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredxor(vuint32m1_t op0, vuint32m8_t op1, vuint32m1_t op2, size_t op3){
  return vredxor_vs_u32m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredxor(vbool4_t op0, vuint32m1_t op1, vuint32m8_t op2, vuint32m1_t op3, size_t op4){
  return vredxor_vs_u32m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vredxor(vuint32m1_t op0, vuint32mf2_t op1, vuint32m1_t op2, size_t op3){
  return vredxor_vs_u32mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vredxor(vbool64_t op0, vuint32m1_t op1, vuint32mf2_t op2, vuint32m1_t op3, size_t op4){
  return vredxor_vs_u32mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredxor(vuint64m1_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vredxor_vs_u64m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredxor(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vredxor_vs_u64m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredxor(vuint64m1_t op0, vuint64m2_t op1, vuint64m1_t op2, size_t op3){
  return vredxor_vs_u64m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredxor(vbool32_t op0, vuint64m1_t op1, vuint64m2_t op2, vuint64m1_t op3, size_t op4){
  return vredxor_vs_u64m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredxor(vuint64m1_t op0, vuint64m4_t op1, vuint64m1_t op2, size_t op3){
  return vredxor_vs_u64m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredxor(vbool16_t op0, vuint64m1_t op1, vuint64m4_t op2, vuint64m1_t op3, size_t op4){
  return vredxor_vs_u64m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vredxor(vuint64m1_t op0, vuint64m8_t op1, vuint64m1_t op2, size_t op3){
  return vredxor_vs_u64m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vredxor(vbool8_t op0, vuint64m1_t op1, vuint64m8_t op2, vuint64m1_t op3, size_t op4){
  return vredxor_vs_u64m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8m1_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8m1_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool8_t op0, vint16m1_t op1, vint8m1_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8m1_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8m2_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8m2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool4_t op0, vint16m1_t op1, vint8m2_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8m2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8m4_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8m4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool2_t op0, vint16m1_t op1, vint8m4_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8m4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8m8_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8m8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool1_t op0, vint16m1_t op1, vint8m8_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8m8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8mf2_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8mf2_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8mf2_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8mf4_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8mf4_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool32_t op0, vint16m1_t op1, vint8mf4_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8mf4_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vwredsum(vint16m1_t op0, vint8mf8_t op1, vint16m1_t op2, size_t op3){
  return vwredsum_vs_i8mf8_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vwredsum(vbool64_t op0, vint16m1_t op1, vint8mf8_t op2, vint16m1_t op3, size_t op4){
  return vwredsum_vs_i8mf8_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16m1_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16m1_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool16_t op0, vint32m1_t op1, vint16m1_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16m1_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16m2_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16m2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool8_t op0, vint32m1_t op1, vint16m2_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16m2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16m4_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16m4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool4_t op0, vint32m1_t op1, vint16m4_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16m4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16m8_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16m8_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool2_t op0, vint32m1_t op1, vint16m8_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16m8_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16mf2_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16mf2_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16mf2_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vwredsum(vint32m1_t op0, vint16mf4_t op1, vint32m1_t op2, size_t op3){
  return vwredsum_vs_i16mf4_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vwredsum(vbool64_t op0, vint32m1_t op1, vint16mf4_t op2, vint32m1_t op3, size_t op4){
  return vwredsum_vs_i16mf4_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwredsum(vint64m1_t op0, vint32m1_t op1, vint64m1_t op2, size_t op3){
  return vwredsum_vs_i32m1_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwredsum(vbool32_t op0, vint64m1_t op1, vint32m1_t op2, vint64m1_t op3, size_t op4){
  return vwredsum_vs_i32m1_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwredsum(vint64m1_t op0, vint32m2_t op1, vint64m1_t op2, size_t op3){
  return vwredsum_vs_i32m2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwredsum(vbool16_t op0, vint64m1_t op1, vint32m2_t op2, vint64m1_t op3, size_t op4){
  return vwredsum_vs_i32m2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwredsum(vint64m1_t op0, vint32m4_t op1, vint64m1_t op2, size_t op3){
  return vwredsum_vs_i32m4_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwredsum(vbool8_t op0, vint64m1_t op1, vint32m4_t op2, vint64m1_t op3, size_t op4){
  return vwredsum_vs_i32m4_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwredsum(vint64m1_t op0, vint32m8_t op1, vint64m1_t op2, size_t op3){
  return vwredsum_vs_i32m8_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwredsum(vbool4_t op0, vint64m1_t op1, vint32m8_t op2, vint64m1_t op3, size_t op4){
  return vwredsum_vs_i32m8_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vwredsum(vint64m1_t op0, vint32mf2_t op1, vint64m1_t op2, size_t op3){
  return vwredsum_vs_i32mf2_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vwredsum(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, vint64m1_t op3, size_t op4){
  return vwredsum_vs_i32mf2_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8m1_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8m1_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool8_t op0, vuint16m1_t op1, vuint8m1_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8m1_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8m2_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8m2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool4_t op0, vuint16m1_t op1, vuint8m2_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8m2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8m4_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8m4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool2_t op0, vuint16m1_t op1, vuint8m4_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8m4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8m8_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8m8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool1_t op0, vuint16m1_t op1, vuint8m8_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8m8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8mf2_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8mf2_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8mf2_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8mf4_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8mf4_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool32_t op0, vuint16m1_t op1, vuint8mf4_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8mf4_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vwredsumu(vuint16m1_t op0, vuint8mf8_t op1, vuint16m1_t op2, size_t op3){
  return vwredsumu_vs_u8mf8_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vwredsumu(vbool64_t op0, vuint16m1_t op1, vuint8mf8_t op2, vuint16m1_t op3, size_t op4){
  return vwredsumu_vs_u8mf8_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16m1_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16m1_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool16_t op0, vuint32m1_t op1, vuint16m1_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16m1_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16m2_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16m2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool8_t op0, vuint32m1_t op1, vuint16m2_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16m2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16m4_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16m4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool4_t op0, vuint32m1_t op1, vuint16m4_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16m4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16m8_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16m8_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool2_t op0, vuint32m1_t op1, vuint16m8_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16m8_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16mf2_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16mf2_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16mf2_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vwredsumu(vuint32m1_t op0, vuint16mf4_t op1, vuint32m1_t op2, size_t op3){
  return vwredsumu_vs_u16mf4_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vwredsumu(vbool64_t op0, vuint32m1_t op1, vuint16mf4_t op2, vuint32m1_t op3, size_t op4){
  return vwredsumu_vs_u16mf4_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwredsumu(vuint64m1_t op0, vuint32m1_t op1, vuint64m1_t op2, size_t op3){
  return vwredsumu_vs_u32m1_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwredsumu(vbool32_t op0, vuint64m1_t op1, vuint32m1_t op2, vuint64m1_t op3, size_t op4){
  return vwredsumu_vs_u32m1_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwredsumu(vuint64m1_t op0, vuint32m2_t op1, vuint64m1_t op2, size_t op3){
  return vwredsumu_vs_u32m2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwredsumu(vbool16_t op0, vuint64m1_t op1, vuint32m2_t op2, vuint64m1_t op3, size_t op4){
  return vwredsumu_vs_u32m2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwredsumu(vuint64m1_t op0, vuint32m4_t op1, vuint64m1_t op2, size_t op3){
  return vwredsumu_vs_u32m4_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwredsumu(vbool8_t op0, vuint64m1_t op1, vuint32m4_t op2, vuint64m1_t op3, size_t op4){
  return vwredsumu_vs_u32m4_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwredsumu(vuint64m1_t op0, vuint32m8_t op1, vuint64m1_t op2, size_t op3){
  return vwredsumu_vs_u32m8_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwredsumu(vbool4_t op0, vuint64m1_t op1, vuint32m8_t op2, vuint64m1_t op3, size_t op4){
  return vwredsumu_vs_u32m8_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vwredsumu(vuint64m1_t op0, vuint32mf2_t op1, vuint64m1_t op2, size_t op3){
  return vwredsumu_vs_u32mf2_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vwredsumu(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, vuint64m1_t op3, size_t op4){
  return vwredsumu_vs_u32mf2_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16m1_t op2, size_t op3){
  return vsse16_v_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool16_t op0, uint16_t * op1, ptrdiff_t op2, vuint16m1_t op3, size_t op4){
  return vsse16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16m2_t op2, size_t op3){
  return vsse16_v_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool8_t op0, uint16_t * op1, ptrdiff_t op2, vuint16m2_t op3, size_t op4){
  return vsse16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16m4_t op2, size_t op3){
  return vsse16_v_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool4_t op0, uint16_t * op1, ptrdiff_t op2, vuint16m4_t op3, size_t op4){
  return vsse16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16m8_t op2, size_t op3){
  return vsse16_v_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool2_t op0, uint16_t * op1, ptrdiff_t op2, vuint16m8_t op3, size_t op4){
  return vsse16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16mf2_t op2, size_t op3){
  return vsse16_v_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool32_t op0, uint16_t * op1, ptrdiff_t op2, vuint16mf2_t op3, size_t op4){
  return vsse16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse16(uint16_t * op0, ptrdiff_t op1, vuint16mf4_t op2, size_t op3){
  return vsse16_v_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse16(vbool64_t op0, uint16_t * op1, ptrdiff_t op2, vuint16mf4_t op3, size_t op4){
  return vsse16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t viota(vbool8_t op0, vuint8m1_t op1, vbool8_t op2, size_t op3){
  return viota_m_u8m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t viota(vbool4_t op0, vuint8m2_t op1, vbool4_t op2, size_t op3){
  return viota_m_u8m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t viota(vbool2_t op0, vuint8m4_t op1, vbool2_t op2, size_t op3){
  return viota_m_u8m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t viota(vbool1_t op0, vuint8m8_t op1, vbool1_t op2, size_t op3){
  return viota_m_u8m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t viota(vbool16_t op0, vuint8mf2_t op1, vbool16_t op2, size_t op3){
  return viota_m_u8mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t viota(vbool32_t op0, vuint8mf4_t op1, vbool32_t op2, size_t op3){
  return viota_m_u8mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t viota(vbool64_t op0, vuint8mf8_t op1, vbool64_t op2, size_t op3){
  return viota_m_u8mf8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t viota(vbool16_t op0, vuint16m1_t op1, vbool16_t op2, size_t op3){
  return viota_m_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t viota(vbool8_t op0, vuint16m2_t op1, vbool8_t op2, size_t op3){
  return viota_m_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t viota(vbool4_t op0, vuint16m4_t op1, vbool4_t op2, size_t op3){
  return viota_m_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t viota(vbool2_t op0, vuint16m8_t op1, vbool2_t op2, size_t op3){
  return viota_m_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t viota(vbool32_t op0, vuint16mf2_t op1, vbool32_t op2, size_t op3){
  return viota_m_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t viota(vbool64_t op0, vuint16mf4_t op1, vbool64_t op2, size_t op3){
  return viota_m_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t viota(vbool32_t op0, vuint32m1_t op1, vbool32_t op2, size_t op3){
  return viota_m_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t viota(vbool16_t op0, vuint32m2_t op1, vbool16_t op2, size_t op3){
  return viota_m_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t viota(vbool8_t op0, vuint32m4_t op1, vbool8_t op2, size_t op3){
  return viota_m_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t viota(vbool4_t op0, vuint32m8_t op1, vbool4_t op2, size_t op3){
  return viota_m_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t viota(vbool64_t op0, vuint32mf2_t op1, vbool64_t op2, size_t op3){
  return viota_m_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t viota(vbool64_t op0, vuint64m1_t op1, vbool64_t op2, size_t op3){
  return viota_m_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t viota(vbool32_t op0, vuint64m2_t op1, vbool32_t op2, size_t op3){
  return viota_m_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t viota(vbool16_t op0, vuint64m4_t op1, vbool16_t op2, size_t op3){
  return viota_m_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t viota(vbool8_t op0, vuint64m8_t op1, vbool8_t op2, size_t op3){
  return viota_m_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vid(vbool8_t op0, vint8m1_t op1, size_t op2){
  return vid_v_i8m1_m(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vid(vbool4_t op0, vint8m2_t op1, size_t op2){
  return vid_v_i8m2_m(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vid(vbool2_t op0, vint8m4_t op1, size_t op2){
  return vid_v_i8m4_m(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vid(vbool1_t op0, vint8m8_t op1, size_t op2){
  return vid_v_i8m8_m(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vid(vbool16_t op0, vint8mf2_t op1, size_t op2){
  return vid_v_i8mf2_m(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vid(vbool32_t op0, vint8mf4_t op1, size_t op2){
  return vid_v_i8mf4_m(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vid(vbool64_t op0, vint8mf8_t op1, size_t op2){
  return vid_v_i8mf8_m(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vid(vbool16_t op0, vint16m1_t op1, size_t op2){
  return vid_v_i16m1_m(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vid(vbool8_t op0, vint16m2_t op1, size_t op2){
  return vid_v_i16m2_m(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vid(vbool4_t op0, vint16m4_t op1, size_t op2){
  return vid_v_i16m4_m(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vid(vbool2_t op0, vint16m8_t op1, size_t op2){
  return vid_v_i16m8_m(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vid(vbool32_t op0, vint16mf2_t op1, size_t op2){
  return vid_v_i16mf2_m(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vid(vbool64_t op0, vint16mf4_t op1, size_t op2){
  return vid_v_i16mf4_m(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vid(vbool32_t op0, vint32m1_t op1, size_t op2){
  return vid_v_i32m1_m(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vid(vbool16_t op0, vint32m2_t op1, size_t op2){
  return vid_v_i32m2_m(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vid(vbool8_t op0, vint32m4_t op1, size_t op2){
  return vid_v_i32m4_m(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vid(vbool4_t op0, vint32m8_t op1, size_t op2){
  return vid_v_i32m8_m(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vid(vbool64_t op0, vint32mf2_t op1, size_t op2){
  return vid_v_i32mf2_m(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vid(vbool64_t op0, vint64m1_t op1, size_t op2){
  return vid_v_i64m1_m(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vid(vbool32_t op0, vint64m2_t op1, size_t op2){
  return vid_v_i64m2_m(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vid(vbool16_t op0, vint64m4_t op1, size_t op2){
  return vid_v_i64m4_m(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vid(vbool8_t op0, vint64m8_t op1, size_t op2){
  return vid_v_i64m8_m(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vid(vbool8_t op0, vuint8m1_t op1, size_t op2){
  return vid_v_u8m1_m(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vid(vbool4_t op0, vuint8m2_t op1, size_t op2){
  return vid_v_u8m2_m(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vid(vbool2_t op0, vuint8m4_t op1, size_t op2){
  return vid_v_u8m4_m(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vid(vbool1_t op0, vuint8m8_t op1, size_t op2){
  return vid_v_u8m8_m(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vid(vbool16_t op0, vuint8mf2_t op1, size_t op2){
  return vid_v_u8mf2_m(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vid(vbool32_t op0, vuint8mf4_t op1, size_t op2){
  return vid_v_u8mf4_m(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vid(vbool64_t op0, vuint8mf8_t op1, size_t op2){
  return vid_v_u8mf8_m(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vid(vbool16_t op0, vuint16m1_t op1, size_t op2){
  return vid_v_u16m1_m(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vid(vbool8_t op0, vuint16m2_t op1, size_t op2){
  return vid_v_u16m2_m(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vid(vbool4_t op0, vuint16m4_t op1, size_t op2){
  return vid_v_u16m4_m(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vid(vbool2_t op0, vuint16m8_t op1, size_t op2){
  return vid_v_u16m8_m(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vid(vbool32_t op0, vuint16mf2_t op1, size_t op2){
  return vid_v_u16mf2_m(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vid(vbool64_t op0, vuint16mf4_t op1, size_t op2){
  return vid_v_u16mf4_m(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vid(vbool32_t op0, vuint32m1_t op1, size_t op2){
  return vid_v_u32m1_m(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vid(vbool16_t op0, vuint32m2_t op1, size_t op2){
  return vid_v_u32m2_m(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vid(vbool8_t op0, vuint32m4_t op1, size_t op2){
  return vid_v_u32m4_m(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vid(vbool4_t op0, vuint32m8_t op1, size_t op2){
  return vid_v_u32m8_m(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vid(vbool64_t op0, vuint32mf2_t op1, size_t op2){
  return vid_v_u32mf2_m(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vid(vbool64_t op0, vuint64m1_t op1, size_t op2){
  return vid_v_u64m1_m(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vid(vbool32_t op0, vuint64m2_t op1, size_t op2){
  return vid_v_u64m2_m(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vid(vbool16_t op0, vuint64m4_t op1, size_t op2){
  return vid_v_u64m4_m(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vid(vbool8_t op0, vuint64m8_t op1, size_t op2){
  return vid_v_u64m8_m(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vslideup(vint8m1_t op0, vint8m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vslideup(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vslideup(vint8m2_t op0, vint8m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vslideup(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vslideup(vint8m4_t op0, vint8m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vslideup(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vslideup(vint8m8_t op0, vint8m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vslideup(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vslideup(vint8mf2_t op0, vint8mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vslideup(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vslideup(vint8mf4_t op0, vint8mf4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vslideup(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vslideup(vint8mf8_t op0, vint8mf8_t op1, size_t op2, size_t op3){
  return vslideup_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vslideup(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vslideup_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vslideup(vint16m1_t op0, vint16m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vslideup(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vslideup(vint16m2_t op0, vint16m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vslideup(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vslideup(vint16m4_t op0, vint16m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vslideup(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vslideup(vint16m8_t op0, vint16m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vslideup(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vslideup(vint16mf2_t op0, vint16mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vslideup(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vslideup(vint16mf4_t op0, vint16mf4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vslideup(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vslideup(vint32m1_t op0, vint32m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vslideup(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vslideup(vint32m2_t op0, vint32m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vslideup(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vslideup(vint32m4_t op0, vint32m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vslideup(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vslideup(vint32m8_t op0, vint32m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vslideup(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vslideup(vint32mf2_t op0, vint32mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vslideup(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vslideup(vint64m1_t op0, vint64m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vslideup(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vslideup(vint64m2_t op0, vint64m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vslideup(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vslideup(vint64m4_t op0, vint64m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vslideup(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vslideup(vint64m8_t op0, vint64m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vslideup(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vslideup(vuint8m1_t op0, vuint8m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vslideup(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vslideup(vuint8m2_t op0, vuint8m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vslideup(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vslideup(vuint8m4_t op0, vuint8m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vslideup(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vslideup(vuint8m8_t op0, vuint8m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vslideup(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vslideup(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vslideup(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vslideup(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vslideup(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vslideup(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2, size_t op3){
  return vslideup_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vslideup(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vslideup_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vslideup(vuint16m1_t op0, vuint16m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vslideup(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vslideup(vuint16m2_t op0, vuint16m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vslideup(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vslideup(vuint16m4_t op0, vuint16m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vslideup(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vslideup(vuint16m8_t op0, vuint16m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vslideup(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vslideup(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vslideup(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vslideup(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vslideup(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vslideup(vuint32m1_t op0, vuint32m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vslideup(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vslideup(vuint32m2_t op0, vuint32m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vslideup(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vslideup(vuint32m4_t op0, vuint32m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vslideup(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vslideup(vuint32m8_t op0, vuint32m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vslideup(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vslideup(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vslideup(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vslideup(vuint64m1_t op0, vuint64m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vslideup(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vslideup(vuint64m2_t op0, vuint64m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vslideup(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vslideup(vuint64m4_t op0, vuint64m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vslideup(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vslideup(vuint64m8_t op0, vuint64m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vslideup(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vslidedown(vint8m1_t op0, vint8m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m1_t vslidedown(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vslidedown(vint8m2_t op0, vint8m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vslidedown(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vslidedown(vint8m4_t op0, vint8m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vslidedown(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vslidedown(vint8m8_t op0, vint8m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vslidedown(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vslidedown(vint8mf2_t op0, vint8mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vslidedown(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vslidedown(vint8mf4_t op0, vint8mf4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vslidedown(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vslidedown(vint8mf8_t op0, vint8mf8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vslidedown(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vslidedown(vint16m1_t op0, vint16m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vslidedown(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vslidedown(vint16m2_t op0, vint16m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vslidedown(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vslidedown(vint16m4_t op0, vint16m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vslidedown(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vslidedown(vint16m8_t op0, vint16m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vslidedown(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vslidedown(vint16mf2_t op0, vint16mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vslidedown(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vslidedown(vint16mf4_t op0, vint16mf4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vslidedown(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vslidedown(vint32m1_t op0, vint32m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vslidedown(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vslidedown(vint32m2_t op0, vint32m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vslidedown(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vslidedown(vint32m4_t op0, vint32m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vslidedown(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vslidedown(vint32m8_t op0, vint32m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vslidedown(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vslidedown(vint32mf2_t op0, vint32mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vslidedown(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vslidedown(vint64m1_t op0, vint64m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vslidedown(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vslidedown(vint64m2_t op0, vint64m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vslidedown(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vslidedown(vint64m4_t op0, vint64m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vslidedown(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vslidedown(vint64m8_t op0, vint64m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vslidedown(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vslidedown(vuint8m1_t op0, vuint8m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vslidedown(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vslidedown(vuint8m2_t op0, vuint8m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vslidedown(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vslidedown(vuint8m4_t op0, vuint8m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vslidedown(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vslidedown(vuint8m8_t op0, vuint8m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vslidedown(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vslidedown(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vslidedown(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vslidedown(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vslidedown(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vslidedown(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vslidedown(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vslidedown(vuint16m1_t op0, vuint16m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vslidedown(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vslidedown(vuint16m2_t op0, vuint16m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vslidedown(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vslidedown(vuint16m4_t op0, vuint16m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vslidedown(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vslidedown(vuint16m8_t op0, vuint16m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vslidedown(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vslidedown(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vslidedown(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vslidedown(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vslidedown(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vslidedown(vuint32m1_t op0, vuint32m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vslidedown(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vslidedown(vuint32m2_t op0, vuint32m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vslidedown(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vslidedown(vuint32m4_t op0, vuint32m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vslidedown(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vslidedown(vuint32m8_t op0, vuint32m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vslidedown(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vslidedown(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vslidedown(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vslidedown(vuint64m1_t op0, vuint64m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vslidedown(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vslidedown(vuint64m2_t op0, vuint64m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vslidedown(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vslidedown(vuint64m4_t op0, vuint64m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vslidedown(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vslidedown(vuint64m8_t op0, vuint64m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vslidedown(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(int32_t * op0, ptrdiff_t op1, vint32m1_t op2, size_t op3){
  return vsse32_v_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool32_t op0, int32_t * op1, ptrdiff_t op2, vint32m1_t op3, size_t op4){
  return vsse32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(int32_t * op0, ptrdiff_t op1, vint32m2_t op2, size_t op3){
  return vsse32_v_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool16_t op0, int32_t * op1, ptrdiff_t op2, vint32m2_t op3, size_t op4){
  return vsse32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(int32_t * op0, ptrdiff_t op1, vint32m4_t op2, size_t op3){
  return vsse32_v_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool8_t op0, int32_t * op1, ptrdiff_t op2, vint32m4_t op3, size_t op4){
  return vsse32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(int32_t * op0, ptrdiff_t op1, vint32m8_t op2, size_t op3){
  return vsse32_v_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool4_t op0, int32_t * op1, ptrdiff_t op2, vint32m8_t op3, size_t op4){
  return vsse32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(int32_t * op0, ptrdiff_t op1, vint32mf2_t op2, size_t op3){
  return vsse32_v_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool64_t op0, int32_t * op1, ptrdiff_t op2, vint32mf2_t op3, size_t op4){
  return vsse32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vslide1up(vint8m1_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vslide1up(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vslide1up(vint8m2_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vslide1up(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vslide1up(vint8m4_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vslide1up(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vslide1up(vint8m8_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vslide1up(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vslide1up(vint8mf2_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vslide1up(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vslide1up(vint8mf4_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vslide1up(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vslide1up(vint8mf8_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vslide1up(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vslide1up(vint16m1_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vslide1up(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vslide1up(vint16m2_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vslide1up(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vslide1up(vint16m4_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vslide1up(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vslide1up(vint16m8_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vslide1up(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vslide1up(vint16mf2_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vslide1up(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vslide1up(vint16mf4_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vslide1up(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vslide1up(vint32m1_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vslide1up(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vslide1up(vint32m2_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vslide1up(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vslide1up(vint32m4_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vslide1up(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vslide1up(vint32m8_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vslide1up(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vslide1up(vint32mf2_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vslide1up(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vslide1up(vint64m1_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vslide1up(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vslide1up(vint64m2_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vslide1up(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vslide1up(vint64m4_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vslide1up(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vslide1up(vint64m8_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vslide1up(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vslide1up(vuint8m1_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vslide1up(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vslide1up(vuint8m2_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vslide1up(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vslide1up(vuint8m4_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vslide1up(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vslide1up(vuint8m8_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vslide1up(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vslide1up(vuint8mf2_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vslide1up(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vslide1up(vuint8mf4_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vslide1up(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vslide1up(vuint8mf8_t op0, int8_t op1, size_t op2){
  return vslide1up_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vslide1up(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, int8_t op3, size_t op4){
  return vslide1up_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vslide1up(vuint16m1_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vslide1up(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vslide1up(vuint16m2_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vslide1up(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vslide1up(vuint16m4_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vslide1up(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vslide1up(vuint16m8_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vslide1up(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vslide1up(vuint16mf2_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vslide1up(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vslide1up(vuint16mf4_t op0, int16_t op1, size_t op2){
  return vslide1up_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vslide1up(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, int16_t op3, size_t op4){
  return vslide1up_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vslide1up(vuint32m1_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vslide1up(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vslide1up(vuint32m2_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vslide1up(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vslide1up(vuint32m4_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vslide1up(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vslide1up(vuint32m8_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vslide1up(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vslide1up(vuint32mf2_t op0, int32_t op1, size_t op2){
  return vslide1up_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vslide1up(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, int32_t op3, size_t op4){
  return vslide1up_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vslide1up(vuint64m1_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vslide1up(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vslide1up(vuint64m2_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vslide1up(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vslide1up(vuint64m4_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vslide1up(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vslide1up(vuint64m8_t op0, int64_t op1, size_t op2){
  return vslide1up_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vslide1up(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, int64_t op3, size_t op4){
  return vslide1up_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vslide1down(vint8m1_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vslide1down(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vslide1down(vint8m2_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vslide1down(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vslide1down(vint8m4_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vslide1down(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vslide1down(vint8m8_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vslide1down(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vslide1down(vint8mf2_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vslide1down(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vslide1down(vint8mf4_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vslide1down(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vslide1down(vint8mf8_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vslide1down(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vslide1down(vint16m1_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vslide1down(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vslide1down(vint16m2_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vslide1down(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vslide1down(vint16m4_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vslide1down(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vslide1down(vint16m8_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vslide1down(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vslide1down(vint16mf2_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vslide1down(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vslide1down(vint16mf4_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vslide1down(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vslide1down(vint32m1_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vslide1down(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vslide1down(vint32m2_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vslide1down(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vslide1down(vint32m4_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vslide1down(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vslide1down(vint32m8_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vslide1down(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vslide1down(vint32mf2_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vslide1down(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vslide1down(vint64m1_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vslide1down(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vslide1down(vint64m2_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vslide1down(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vslide1down(vint64m4_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vslide1down(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vslide1down(vint64m8_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vslide1down(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vslide1down(vuint8m1_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vslide1down(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vslide1down(vuint8m2_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vslide1down(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vslide1down(vuint8m4_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vslide1down(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vslide1down(vuint8m8_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vslide1down(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vslide1down(vuint8mf2_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vslide1down(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vslide1down(vuint8mf4_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vslide1down(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vslide1down(vuint8mf8_t op0, int8_t op1, size_t op2){
  return vslide1down_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vslide1down(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, int8_t op3, size_t op4){
  return vslide1down_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vslide1down(vuint16m1_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vslide1down(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vslide1down(vuint16m2_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vslide1down(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vslide1down(vuint16m4_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vslide1down(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vslide1down(vuint16m8_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vslide1down(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vslide1down(vuint16mf2_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vslide1down(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vslide1down(vuint16mf4_t op0, int16_t op1, size_t op2){
  return vslide1down_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vslide1down(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, int16_t op3, size_t op4){
  return vslide1down_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vslide1down(vuint32m1_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vslide1down(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vslide1down(vuint32m2_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vslide1down(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vslide1down(vuint32m4_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vslide1down(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vslide1down(vuint32m8_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vslide1down(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vslide1down(vuint32mf2_t op0, int32_t op1, size_t op2){
  return vslide1down_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vslide1down(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, int32_t op3, size_t op4){
  return vslide1down_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vslide1down(vuint64m1_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vslide1down(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vslide1down(vuint64m2_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vslide1down(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vslide1down(vuint64m4_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vslide1down(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vslide1down(vuint64m8_t op0, int64_t op1, size_t op2){
  return vslide1down_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vslide1down(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, int64_t op3, size_t op4){
  return vslide1down_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrgather(vint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vrgather_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrgather(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vrgather_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrgather(vint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vrgather_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrgather(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vrgather_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrgather(vint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vrgather_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrgather(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vrgather_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrgather(vint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vrgather_vv_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrgather(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vrgather_vv_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrgather(vint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vrgather_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrgather(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vrgather_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrgather(vint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vrgather_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrgather(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vrgather_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrgather(vint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vrgather_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrgather(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vrgather_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrgather(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vrgather_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrgather(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vrgather_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrgather(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vrgather_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrgather(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vrgather_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrgather(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vrgather_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrgather(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vrgather_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrgather(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vrgather_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrgather(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vrgather_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrgather(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgather_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrgather(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgather_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrgather(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vrgather_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrgather(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vrgather_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrgather(vint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vrgather_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrgather(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vrgather_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrgather(vint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vrgather_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrgather(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vrgather_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrgather(vint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vrgather_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrgather(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vrgather_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrgather(vint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vrgather_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrgather(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vrgather_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrgather(vint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vrgather_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrgather(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vrgather_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrgather(vint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vrgather_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrgather(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vrgather_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrgather(vint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vrgather_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrgather(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vrgather_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrgather(vint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vrgather_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrgather(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vrgather_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrgather(vint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vrgather_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrgather(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vrgather_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrgather(vint8m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrgather(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrgather(vint8m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrgather(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrgather(vint8m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrgather(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vrgather(vint8m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vrgather(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrgather(vint8mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrgather(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrgather(vint8mf4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrgather(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrgather(vint8mf8_t op0, size_t op1, size_t op2){
  return vrgather_vx_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrgather(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3, size_t op4){
  return vrgather_vx_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrgather(vint16m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrgather(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrgather(vint16m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrgather(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrgather(vint16m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrgather(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrgather(vint16m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrgather(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrgather(vint16mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrgather(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrgather(vint16mf4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrgather(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrgather(vint32m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrgather(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrgather(vint32m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrgather(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrgather(vint32m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrgather(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrgather(vint32m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrgather(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrgather(vint32mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrgather(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrgather(vint64m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrgather(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrgather(vint64m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrgather(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrgather(vint64m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrgather(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrgather(vint64m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrgather(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vrgatherei16(vint8m1_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vrgatherei16(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vrgatherei16(vint8m2_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vrgatherei16(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vrgatherei16(vint8m4_t op0, vuint16m8_t op1, size_t op2){
  return vrgatherei16_vv_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vrgatherei16(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, vuint16m8_t op3, size_t op4){
  return vrgatherei16_vv_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vrgatherei16(vint8mf2_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vrgatherei16(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vrgatherei16(vint8mf4_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vrgatherei16(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vrgatherei16(vint8mf8_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vrgatherei16(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vrgatherei16(vint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vrgatherei16(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vrgatherei16(vint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vrgatherei16(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vrgatherei16(vint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vrgatherei16(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vrgatherei16(vint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vrgatherei16_vv_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vrgatherei16(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vrgatherei16_vv_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vrgatherei16(vint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vrgatherei16(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vrgatherei16(vint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vrgatherei16(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vrgatherei16(vint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vrgatherei16(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vrgatherei16(vint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vrgatherei16(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vrgatherei16(vint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vrgatherei16(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vrgatherei16(vint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vrgatherei16(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vrgatherei16(vint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vrgatherei16(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vrgatherei16(vint64m1_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vrgatherei16(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vrgatherei16(vint64m2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vrgatherei16(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vrgatherei16(vint64m4_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vrgatherei16(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vrgatherei16(vint64m8_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vrgatherei16(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vrgather(vuint8m1_t op0, vuint8m1_t op1, size_t op2){
  return vrgather_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vrgather(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint8m1_t op3, size_t op4){
  return vrgather_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vrgather(vuint8m2_t op0, vuint8m2_t op1, size_t op2){
  return vrgather_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vrgather(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint8m2_t op3, size_t op4){
  return vrgather_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vrgather(vuint8m4_t op0, vuint8m4_t op1, size_t op2){
  return vrgather_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vrgather(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint8m4_t op3, size_t op4){
  return vrgather_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vrgather(vuint8m8_t op0, vuint8m8_t op1, size_t op2){
  return vrgather_vv_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vrgather(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, vuint8m8_t op3, size_t op4){
  return vrgather_vv_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vrgather(vuint8mf2_t op0, vuint8mf2_t op1, size_t op2){
  return vrgather_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vrgather(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint8mf2_t op3, size_t op4){
  return vrgather_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vrgather(vuint8mf4_t op0, vuint8mf4_t op1, size_t op2){
  return vrgather_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vrgather(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint8mf4_t op3, size_t op4){
  return vrgather_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vrgather(vuint8mf8_t op0, vuint8mf8_t op1, size_t op2){
  return vrgather_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vrgather(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint8mf8_t op3, size_t op4){
  return vrgather_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vrgather(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vrgather_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vrgather(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vrgather_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vrgather(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vrgather_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vrgather(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vrgather_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vrgather(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vrgather_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vrgather(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vrgather_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vrgather(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vrgather_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vrgather(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vrgather_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vrgather(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgather_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vrgather(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgather_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vrgather(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vrgather_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vrgather(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vrgather_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vrgather(vuint32m1_t op0, vuint32m1_t op1, size_t op2){
  return vrgather_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vrgather(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint32m1_t op3, size_t op4){
  return vrgather_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vrgather(vuint32m2_t op0, vuint32m2_t op1, size_t op2){
  return vrgather_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vrgather(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint32m2_t op3, size_t op4){
  return vrgather_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vrgather(vuint32m4_t op0, vuint32m4_t op1, size_t op2){
  return vrgather_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vrgather(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint32m4_t op3, size_t op4){
  return vrgather_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vrgather(vuint32m8_t op0, vuint32m8_t op1, size_t op2){
  return vrgather_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vrgather(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint32m8_t op3, size_t op4){
  return vrgather_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vrgather(vuint32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vrgather_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vrgather(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vrgather_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vrgather(vuint64m1_t op0, vuint64m1_t op1, size_t op2){
  return vrgather_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vrgather(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint64m1_t op3, size_t op4){
  return vrgather_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vrgather(vuint64m2_t op0, vuint64m2_t op1, size_t op2){
  return vrgather_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vrgather(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint64m2_t op3, size_t op4){
  return vrgather_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vrgather(vuint64m4_t op0, vuint64m4_t op1, size_t op2){
  return vrgather_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vrgather(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint64m4_t op3, size_t op4){
  return vrgather_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vrgather(vuint64m8_t op0, vuint64m8_t op1, size_t op2){
  return vrgather_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vrgather(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint64m8_t op3, size_t op4){
  return vrgather_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vle8ff(vbool8_t op0, vint8m1_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vle8ff(vbool4_t op0, vint8m2_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vle8ff(vbool2_t op0, vint8m4_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vle8ff(vbool1_t op0, vint8m8_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vle8ff(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vle8ff(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vle8ff(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(uint32_t * op0, ptrdiff_t op1, vuint32m1_t op2, size_t op3){
  return vsse32_v_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool32_t op0, uint32_t * op1, ptrdiff_t op2, vuint32m1_t op3, size_t op4){
  return vsse32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(uint32_t * op0, ptrdiff_t op1, vuint32m2_t op2, size_t op3){
  return vsse32_v_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool16_t op0, uint32_t * op1, ptrdiff_t op2, vuint32m2_t op3, size_t op4){
  return vsse32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(uint32_t * op0, ptrdiff_t op1, vuint32m4_t op2, size_t op3){
  return vsse32_v_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool8_t op0, uint32_t * op1, ptrdiff_t op2, vuint32m4_t op3, size_t op4){
  return vsse32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(uint32_t * op0, ptrdiff_t op1, vuint32m8_t op2, size_t op3){
  return vsse32_v_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool4_t op0, uint32_t * op1, ptrdiff_t op2, vuint32m8_t op3, size_t op4){
  return vsse32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(uint32_t * op0, ptrdiff_t op1, vuint32mf2_t op2, size_t op3){
  return vsse32_v_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool64_t op0, uint32_t * op1, ptrdiff_t op2, vuint32mf2_t op3, size_t op4){
  return vsse32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vrgather(vuint8m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vrgather(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vrgather(vuint8m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vrgather(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vrgather(vuint8m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vrgather(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vrgather(vuint8m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vrgather(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vrgather(vuint8mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vrgather(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vrgather(vuint8mf4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vrgather(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vrgather(vuint8mf8_t op0, size_t op1, size_t op2){
  return vrgather_vx_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vrgather(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3, size_t op4){
  return vrgather_vx_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vrgather(vuint16m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vrgather(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vrgather(vuint16m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vrgather(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vrgather(vuint16m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vrgather(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vrgather(vuint16m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vrgather(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vrgather(vuint16mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vrgather(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vrgather(vuint16mf4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vrgather(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vrgather(vuint32m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vrgather(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vrgather(vuint32m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vrgather(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vrgather(vuint32m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vrgather(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vrgather(vuint32m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vrgather(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vrgather(vuint32mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vrgather(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vrgather(vuint64m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vrgather(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vrgather(vuint64m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vrgather(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vrgather(vuint64m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vrgather(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vrgather(vuint64m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vrgather(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vrgatherei16(vuint8m1_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vrgatherei16(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vrgatherei16(vuint8m2_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vrgatherei16(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vrgatherei16(vuint8m4_t op0, vuint16m8_t op1, size_t op2){
  return vrgatherei16_vv_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vrgatherei16(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, vuint16m8_t op3, size_t op4){
  return vrgatherei16_vv_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vrgatherei16(vuint8mf2_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vrgatherei16(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vrgatherei16(vuint8mf4_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vrgatherei16(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vrgatherei16(vuint8mf8_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vrgatherei16(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vrgatherei16(vuint16m1_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vrgatherei16(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vrgatherei16(vuint16m2_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vrgatherei16(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vrgatherei16(vuint16m4_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vrgatherei16(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vrgatherei16(vuint16m8_t op0, vuint16m8_t op1, size_t op2){
  return vrgatherei16_vv_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vrgatherei16(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, vuint16m8_t op3, size_t op4){
  return vrgatherei16_vv_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vrgatherei16(vuint16mf2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vrgatherei16(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vrgatherei16(vuint16mf4_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vrgatherei16(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vrgatherei16(vuint32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vrgatherei16(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vrgatherei16(vuint32m2_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vrgatherei16(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vrgatherei16(vuint32m4_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vrgatherei16(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vrgatherei16(vuint32m8_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vrgatherei16(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vrgatherei16(vuint32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vrgatherei16(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vrgatherei16(vuint64m1_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vrgatherei16(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vrgatherei16(vuint64m2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vrgatherei16(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vrgatherei16(vuint64m4_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vrgatherei16(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vrgatherei16(vuint64m8_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vrgatherei16(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vcompress(vbool8_t op0, vint8m1_t op1, vint8m1_t op2, size_t op3){
  return vcompress_vm_i8m1(op0, op1, op2, op3);
}

__rvv_overloaded vint8m2_t vcompress(vbool4_t op0, vint8m2_t op1, vint8m2_t op2, size_t op3){
  return vcompress_vm_i8m2(op0, op1, op2, op3);
}

__rvv_overloaded vint8m4_t vcompress(vbool2_t op0, vint8m4_t op1, vint8m4_t op2, size_t op3){
  return vcompress_vm_i8m4(op0, op1, op2, op3);
}

__rvv_overloaded vint8m8_t vcompress(vbool1_t op0, vint8m8_t op1, vint8m8_t op2, size_t op3){
  return vcompress_vm_i8m8(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf2_t vcompress(vbool16_t op0, vint8mf2_t op1, vint8mf2_t op2, size_t op3){
  return vcompress_vm_i8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf4_t vcompress(vbool32_t op0, vint8mf4_t op1, vint8mf4_t op2, size_t op3){
  return vcompress_vm_i8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint8mf8_t vcompress(vbool64_t op0, vint8mf8_t op1, vint8mf8_t op2, size_t op3){
  return vcompress_vm_i8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vcompress(vbool16_t op0, vint16m1_t op1, vint16m1_t op2, size_t op3){
  return vcompress_vm_i16m1(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vcompress(vbool8_t op0, vint16m2_t op1, vint16m2_t op2, size_t op3){
  return vcompress_vm_i16m2(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vcompress(vbool4_t op0, vint16m4_t op1, vint16m4_t op2, size_t op3){
  return vcompress_vm_i16m4(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vcompress(vbool2_t op0, vint16m8_t op1, vint16m8_t op2, size_t op3){
  return vcompress_vm_i16m8(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vcompress(vbool32_t op0, vint16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vcompress_vm_i16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vcompress(vbool64_t op0, vint16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vcompress_vm_i16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vcompress(vbool32_t op0, vint32m1_t op1, vint32m1_t op2, size_t op3){
  return vcompress_vm_i32m1(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vcompress(vbool16_t op0, vint32m2_t op1, vint32m2_t op2, size_t op3){
  return vcompress_vm_i32m2(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vcompress(vbool8_t op0, vint32m4_t op1, vint32m4_t op2, size_t op3){
  return vcompress_vm_i32m4(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vcompress(vbool4_t op0, vint32m8_t op1, vint32m8_t op2, size_t op3){
  return vcompress_vm_i32m8(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vcompress(vbool64_t op0, vint32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vcompress_vm_i32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vcompress(vbool64_t op0, vint64m1_t op1, vint64m1_t op2, size_t op3){
  return vcompress_vm_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vcompress(vbool32_t op0, vint64m2_t op1, vint64m2_t op2, size_t op3){
  return vcompress_vm_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vcompress(vbool16_t op0, vint64m4_t op1, vint64m4_t op2, size_t op3){
  return vcompress_vm_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vcompress(vbool8_t op0, vint64m8_t op1, vint64m8_t op2, size_t op3){
  return vcompress_vm_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m1_t vcompress(vbool8_t op0, vuint8m1_t op1, vuint8m1_t op2, size_t op3){
  return vcompress_vm_u8m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m2_t vcompress(vbool4_t op0, vuint8m2_t op1, vuint8m2_t op2, size_t op3){
  return vcompress_vm_u8m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m4_t vcompress(vbool2_t op0, vuint8m4_t op1, vuint8m4_t op2, size_t op3){
  return vcompress_vm_u8m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8m8_t vcompress(vbool1_t op0, vuint8m8_t op1, vuint8m8_t op2, size_t op3){
  return vcompress_vm_u8m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf2_t vcompress(vbool16_t op0, vuint8mf2_t op1, vuint8mf2_t op2, size_t op3){
  return vcompress_vm_u8mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf4_t vcompress(vbool32_t op0, vuint8mf4_t op1, vuint8mf4_t op2, size_t op3){
  return vcompress_vm_u8mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint8mf8_t vcompress(vbool64_t op0, vuint8mf8_t op1, vuint8mf8_t op2, size_t op3){
  return vcompress_vm_u8mf8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vcompress(vbool16_t op0, vuint16m1_t op1, vuint16m1_t op2, size_t op3){
  return vcompress_vm_u16m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vcompress(vbool8_t op0, vuint16m2_t op1, vuint16m2_t op2, size_t op3){
  return vcompress_vm_u16m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vcompress(vbool4_t op0, vuint16m4_t op1, vuint16m4_t op2, size_t op3){
  return vcompress_vm_u16m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vcompress(vbool2_t op0, vuint16m8_t op1, vuint16m8_t op2, size_t op3){
  return vcompress_vm_u16m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vcompress(vbool32_t op0, vuint16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vcompress_vm_u16mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vcompress(vbool64_t op0, vuint16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vcompress_vm_u16mf4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vcompress(vbool32_t op0, vuint32m1_t op1, vuint32m1_t op2, size_t op3){
  return vcompress_vm_u32m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vcompress(vbool16_t op0, vuint32m2_t op1, vuint32m2_t op2, size_t op3){
  return vcompress_vm_u32m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vcompress(vbool8_t op0, vuint32m4_t op1, vuint32m4_t op2, size_t op3){
  return vcompress_vm_u32m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vcompress(vbool4_t op0, vuint32m8_t op1, vuint32m8_t op2, size_t op3){
  return vcompress_vm_u32m8(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vcompress(vbool64_t op0, vuint32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vcompress_vm_u32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vcompress(vbool64_t op0, vuint64m1_t op1, vuint64m1_t op2, size_t op3){
  return vcompress_vm_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vcompress(vbool32_t op0, vuint64m2_t op1, vuint64m2_t op2, size_t op3){
  return vcompress_vm_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vcompress(vbool16_t op0, vuint64m4_t op1, vuint64m4_t op2, size_t op3){
  return vcompress_vm_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vcompress(vbool8_t op0, vuint64m8_t op1, vuint64m8_t op2, size_t op3){
  return vcompress_vm_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(int64_t * op0, ptrdiff_t op1, vint64m1_t op2, size_t op3){
  return vsse64_v_i64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool64_t op0, int64_t * op1, ptrdiff_t op2, vint64m1_t op3, size_t op4){
  return vsse64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(int64_t * op0, ptrdiff_t op1, vint64m2_t op2, size_t op3){
  return vsse64_v_i64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool32_t op0, int64_t * op1, ptrdiff_t op2, vint64m2_t op3, size_t op4){
  return vsse64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(int64_t * op0, ptrdiff_t op1, vint64m4_t op2, size_t op3){
  return vsse64_v_i64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool16_t op0, int64_t * op1, ptrdiff_t op2, vint64m4_t op3, size_t op4){
  return vsse64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(int64_t * op0, ptrdiff_t op1, vint64m8_t op2, size_t op3){
  return vsse64_v_i64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool8_t op0, int64_t * op1, ptrdiff_t op2, vint64m8_t op3, size_t op4){
  return vsse64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(uint64_t * op0, ptrdiff_t op1, vuint64m1_t op2, size_t op3){
  return vsse64_v_u64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool64_t op0, uint64_t * op1, ptrdiff_t op2, vuint64m1_t op3, size_t op4){
  return vsse64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(uint64_t * op0, ptrdiff_t op1, vuint64m2_t op2, size_t op3){
  return vsse64_v_u64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool32_t op0, uint64_t * op1, ptrdiff_t op2, vuint64m2_t op3, size_t op4){
  return vsse64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(uint64_t * op0, ptrdiff_t op1, vuint64m4_t op2, size_t op3){
  return vsse64_v_u64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool16_t op0, uint64_t * op1, ptrdiff_t op2, vuint64m4_t op3, size_t op4){
  return vsse64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(uint64_t * op0, ptrdiff_t op1, vuint64m8_t op2, size_t op3){
  return vsse64_v_u64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool8_t op0, uint64_t * op1, ptrdiff_t op2, vuint64m8_t op3, size_t op4){
  return vsse64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei16(const int8_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei16(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei16(const int8_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei16(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vluxei16(const int8_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vluxei16(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei16(const int8_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei16(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei16(const int8_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei16(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei16(const int8_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei16(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei16(const uint8_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei16(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei16(const uint8_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei16(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vluxei16(const uint8_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vluxei16(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei16(const uint8_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei16(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei16(const uint8_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei16(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei16(const uint8_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei16(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei32(const int8_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei32(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei32(const int8_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei32(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei32(const int8_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei32(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei32(const int8_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei32(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei32(const int8_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei32(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei32(const uint8_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei32(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vluxei32(const uint8_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vluxei32(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei32(const uint8_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei32(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei32(const uint8_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei32(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei32(const uint8_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei32(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vle8ff(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vle8ff(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vle8ff(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vle8ff(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vle8ff(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vle8ff(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vle8ff(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, size_t * op3, size_t op4){
  return vle8ff_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei64(const int8_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei64(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei64(const int8_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei64(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei64(const int8_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei64(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei64(const int8_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei64(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vluxei64(const uint8_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vluxei64(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vluxei64(const uint8_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vluxei64(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vluxei64(const uint8_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vluxei64(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vluxei64(const uint8_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vluxei64(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei8(const int16_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei8(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei8(const int16_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei8(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei8(const int16_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei8(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vluxei8(const int16_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vluxei8(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei8(const int16_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei8(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei8(const int16_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei8(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei8(const uint16_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei8(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei8(const uint16_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei8(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei8(const uint16_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei8(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vluxei8(const uint16_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vluxei8(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei8(const uint16_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei8(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei8(const uint16_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei8(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei16(const int16_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei16(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei16(const int16_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei16(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei16(const int16_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei16(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m8_t vluxei16(const int16_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_i16m8(op0, op1, op2);
}

__rvv_overloaded vint16m8_t vluxei16(vbool2_t op0, vint16m8_t op1, const int16_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_i16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei16(const int16_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei16(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei16(const int16_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei16(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei16(const uint16_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei16(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei16(const uint16_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei16(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei16(const uint16_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei16(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m8_t vluxei16(const uint16_t * op0, vuint16m8_t op1, size_t op2){
  return vluxei16_v_u16m8(op0, op1, op2);
}

__rvv_overloaded vuint16m8_t vluxei16(vbool2_t op0, vuint16m8_t op1, const uint16_t * op2, vuint16m8_t op3, size_t op4){
  return vluxei16_v_u16m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei16(const uint16_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei16(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei16(const uint16_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei16(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei32(const int16_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei32(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei32(const int16_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei32(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m4_t vluxei32(const int16_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i16m4(op0, op1, op2);
}

__rvv_overloaded vint16m4_t vluxei32(vbool4_t op0, vint16m4_t op1, const int16_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei32(const int16_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei32(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei32(const int16_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei32(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei32(const uint16_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei32(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei32(const uint16_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei32(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m4_t vluxei32(const uint16_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u16m4(op0, op1, op2);
}

__rvv_overloaded vuint16m4_t vluxei32(vbool4_t op0, vuint16m4_t op1, const uint16_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u16m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei32(const uint16_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei32(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei32(const uint16_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei32(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m1_t vluxei64(const int16_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i16m1(op0, op1, op2);
}

__rvv_overloaded vint16m1_t vluxei64(vbool16_t op0, vint16m1_t op1, const int16_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16m2_t vluxei64(const int16_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i16m2(op0, op1, op2);
}

__rvv_overloaded vint16m2_t vluxei64(vbool8_t op0, vint16m2_t op1, const int16_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf2_t vluxei64(const int16_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i16mf2(op0, op1, op2);
}

__rvv_overloaded vint16mf2_t vluxei64(vbool32_t op0, vint16mf2_t op1, const int16_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint16mf4_t vluxei64(const int16_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i16mf4(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vluxei64(vbool64_t op0, vint16mf4_t op1, const int16_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m1_t vluxei64(const uint16_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u16m1(op0, op1, op2);
}

__rvv_overloaded vuint16m1_t vluxei64(vbool16_t op0, vuint16m1_t op1, const uint16_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u16m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16m2_t vluxei64(const uint16_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u16m2(op0, op1, op2);
}

__rvv_overloaded vuint16m2_t vluxei64(vbool8_t op0, vuint16m2_t op1, const uint16_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u16m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf2_t vluxei64(const uint16_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u16mf2(op0, op1, op2);
}

__rvv_overloaded vuint16mf2_t vluxei64(vbool32_t op0, vuint16mf2_t op1, const uint16_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u16mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint16mf4_t vluxei64(const uint16_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u16mf4(op0, op1, op2);
}

__rvv_overloaded vuint16mf4_t vluxei64(vbool64_t op0, vuint16mf4_t op1, const uint16_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u16mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vlse8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vlse8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vlse8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vlse8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vlse8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vlse8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vlse8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei8(const int32_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei8(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei8(const int32_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei8(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei8(const int32_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei8(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei8(const int32_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei8(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei8(const int32_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei8(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei8(const uint32_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei8(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei8(const uint32_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei8(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei8(const uint32_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei8(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei8(const uint32_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei8(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei8(const uint32_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei8(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei16(const int32_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei16(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei16(const int32_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei16(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei16(const int32_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei16(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei16(const int32_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei16(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei16(const int32_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei16(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei16(const uint32_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei16(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei16(const uint32_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei16(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei16(const uint32_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei16(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei16(const uint32_t * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei16(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei16(const uint32_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei16(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei32(const int32_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei32(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei32(const int32_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei32(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei32(const int32_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei32(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m8_t vluxei32(const int32_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_i32m8(op0, op1, op2);
}

__rvv_overloaded vint32m8_t vluxei32(vbool4_t op0, vint32m8_t op1, const int32_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_i32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei32(const int32_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei32(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei32(const uint32_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei32(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei32(const uint32_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei32(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei32(const uint32_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei32(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m8_t vluxei32(const uint32_t * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_u32m8(op0, op1, op2);
}

__rvv_overloaded vuint32m8_t vluxei32(vbool4_t op0, vuint32m8_t op1, const uint32_t * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_u32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei32(const uint32_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei32(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m1_t vluxei64(const int32_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i32m1(op0, op1, op2);
}

__rvv_overloaded vint32m1_t vluxei64(vbool32_t op0, vint32m1_t op1, const int32_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m2_t vluxei64(const int32_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i32m2(op0, op1, op2);
}

__rvv_overloaded vint32m2_t vluxei64(vbool16_t op0, vint32m2_t op1, const int32_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32m4_t vluxei64(const int32_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i32m4(op0, op1, op2);
}

__rvv_overloaded vint32m4_t vluxei64(vbool8_t op0, vint32m4_t op1, const int32_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint32mf2_t vluxei64(const int32_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i32mf2(op0, op1, op2);
}

__rvv_overloaded vint32mf2_t vluxei64(vbool64_t op0, vint32mf2_t op1, const int32_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vluxei64(const uint32_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u32m1(op0, op1, op2);
}

__rvv_overloaded vuint32m1_t vluxei64(vbool32_t op0, vuint32m1_t op1, const uint32_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m2_t vluxei64(const uint32_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u32m2(op0, op1, op2);
}

__rvv_overloaded vuint32m2_t vluxei64(vbool16_t op0, vuint32m2_t op1, const uint32_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m4_t vluxei64(const uint32_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u32m4(op0, op1, op2);
}

__rvv_overloaded vuint32m4_t vluxei64(vbool8_t op0, vuint32m4_t op1, const uint32_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32mf2_t vluxei64(const uint32_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u32mf2(op0, op1, op2);
}

__rvv_overloaded vuint32mf2_t vluxei64(vbool64_t op0, vuint32mf2_t op1, const uint32_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei8(const int64_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei8(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei8(const int64_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei8(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei8(const int64_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei8(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei8(const int64_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei8(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei8(const uint64_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei8(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei8(const uint64_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei8(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei8(const uint64_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei8(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei8(const uint64_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei8(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vlse8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vlse8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vlse8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vlse8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vlse8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vlse8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vlse8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, ptrdiff_t op3, size_t op4){
  return vlse8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei16(const int64_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei16(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei16(const int64_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei16(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei16(const int64_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei16(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei16(const int64_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei16(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei16(const uint64_t * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei16(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei16(const uint64_t * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei16(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei16(const uint64_t * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei16(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei16(const uint64_t * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei16(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei32(const int64_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei32(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei32(const int64_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei32(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei32(const int64_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei32(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei32(const int64_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei32(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei32(const uint64_t * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei32(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei32(const uint64_t * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei32(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei32(const uint64_t * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei32(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei32(const uint64_t * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei32(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m1_t vluxei64(const int64_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_i64m1(op0, op1, op2);
}

__rvv_overloaded vint64m1_t vluxei64(vbool64_t op0, vint64m1_t op1, const int64_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_i64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m2_t vluxei64(const int64_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_i64m2(op0, op1, op2);
}

__rvv_overloaded vint64m2_t vluxei64(vbool32_t op0, vint64m2_t op1, const int64_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_i64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m4_t vluxei64(const int64_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_i64m4(op0, op1, op2);
}

__rvv_overloaded vint64m4_t vluxei64(vbool16_t op0, vint64m4_t op1, const int64_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_i64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint64m8_t vluxei64(const int64_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_i64m8(op0, op1, op2);
}

__rvv_overloaded vint64m8_t vluxei64(vbool8_t op0, vint64m8_t op1, const int64_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_i64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vluxei64(const uint64_t * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_u64m1(op0, op1, op2);
}

__rvv_overloaded vuint64m1_t vluxei64(vbool64_t op0, vuint64m1_t op1, const uint64_t * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_u64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m2_t vluxei64(const uint64_t * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_u64m2(op0, op1, op2);
}

__rvv_overloaded vuint64m2_t vluxei64(vbool32_t op0, vuint64m2_t op1, const uint64_t * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_u64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m4_t vluxei64(const uint64_t * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_u64m4(op0, op1, op2);
}

__rvv_overloaded vuint64m4_t vluxei64(vbool16_t op0, vuint64m4_t op1, const uint64_t * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_u64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m8_t vluxei64(const uint64_t * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_u64m8(op0, op1, op2);
}

__rvv_overloaded vuint64m8_t vluxei64(vbool8_t op0, vuint64m8_t op1, const uint64_t * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_u64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vluxei8(const int8_t * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vluxei8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vluxei8(const int8_t * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vluxei8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vluxei8(const int8_t * op0, vuint8m4_t op1, size_t op2){
  return vluxei8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vluxei8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint8m4_t op3, size_t op4){
  return vluxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vluxei8(const int8_t * op0, vuint8m8_t op1, size_t op2){
  return vluxei8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vluxei8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, vuint8m8_t op3, size_t op4){
  return vluxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vluxei8(const int8_t * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vluxei8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vluxei8(const int8_t * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vluxei8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vluxei8(const int8_t * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vluxei8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei8(const int8_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei8(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei8(const int8_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei8(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vloxei8(const int8_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vloxei8(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m8_t vloxei8(const int8_t * op0, vuint8m8_t op1, size_t op2){
  return vloxei8_v_i8m8(op0, op1, op2);
}

__rvv_overloaded vint8m8_t vloxei8(vbool1_t op0, vint8m8_t op1, const int8_t * op2, vuint8m8_t op3, size_t op4){
  return vloxei8_v_i8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei8(const int8_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei8(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei8(const int8_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei8(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei8(const int8_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei8(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei8(const uint8_t * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei8(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei8(const uint8_t * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei8(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vloxei8(const uint8_t * op0, vuint8m4_t op1, size_t op2){
  return vloxei8_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vloxei8(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint8m4_t op3, size_t op4){
  return vloxei8_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m8_t vloxei8(const uint8_t * op0, vuint8m8_t op1, size_t op2){
  return vloxei8_v_u8m8(op0, op1, op2);
}

__rvv_overloaded vuint8m8_t vloxei8(vbool1_t op0, vuint8m8_t op1, const uint8_t * op2, vuint8m8_t op3, size_t op4){
  return vloxei8_v_u8m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei8(const uint8_t * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei8(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei8(const uint8_t * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei8(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei8(const uint8_t * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei8(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei16(const int8_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei16(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei16(const int8_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei16(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m4_t vloxei16(const int8_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_i8m4(op0, op1, op2);
}

__rvv_overloaded vint8m4_t vloxei16(vbool2_t op0, vint8m4_t op1, const int8_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_i8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei16(const int8_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei16(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei16(const int8_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei16(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei16(const int8_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei16(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m1_t vloxei16(const uint8_t * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_u8m1(op0, op1, op2);
}

__rvv_overloaded vuint8m1_t vloxei16(vbool8_t op0, vuint8m1_t op1, const uint8_t * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_u8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m2_t vloxei16(const uint8_t * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_u8m2(op0, op1, op2);
}

__rvv_overloaded vuint8m2_t vloxei16(vbool4_t op0, vuint8m2_t op1, const uint8_t * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_u8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8m4_t vloxei16(const uint8_t * op0, vuint16m8_t op1, size_t op2){
  return vloxei16_v_u8m4(op0, op1, op2);
}

__rvv_overloaded vuint8m4_t vloxei16(vbool2_t op0, vuint8m4_t op1, const uint8_t * op2, vuint16m8_t op3, size_t op4){
  return vloxei16_v_u8m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf2_t vloxei16(const uint8_t * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_u8mf2(op0, op1, op2);
}

__rvv_overloaded vuint8mf2_t vloxei16(vbool16_t op0, vuint8mf2_t op1, const uint8_t * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_u8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf4_t vloxei16(const uint8_t * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_u8mf4(op0, op1, op2);
}

__rvv_overloaded vuint8mf4_t vloxei16(vbool32_t op0, vuint8mf4_t op1, const uint8_t * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_u8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint8mf8_t vloxei16(const uint8_t * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_u8mf8(op0, op1, op2);
}

__rvv_overloaded vuint8mf8_t vloxei16(vbool64_t op0, vuint8mf8_t op1, const uint8_t * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_u8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m1_t vloxei32(const int8_t * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_i8m1(op0, op1, op2);
}

__rvv_overloaded vint8m1_t vloxei32(vbool8_t op0, vint8m1_t op1, const int8_t * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_i8m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8m2_t vloxei32(const int8_t * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_i8m2(op0, op1, op2);
}

__rvv_overloaded vint8m2_t vloxei32(vbool4_t op0, vint8m2_t op1, const int8_t * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_i8m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf2_t vloxei32(const int8_t * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_i8mf2(op0, op1, op2);
}

__rvv_overloaded vint8mf2_t vloxei32(vbool16_t op0, vint8mf2_t op1, const int8_t * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_i8mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf4_t vloxei32(const int8_t * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_i8mf4(op0, op1, op2);
}

__rvv_overloaded vint8mf4_t vloxei32(vbool32_t op0, vint8mf4_t op1, const int8_t * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_i8mf4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vint8mf8_t vloxei32(const int8_t * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_i8mf8(op0, op1, op2);
}

__rvv_overloaded vint8mf8_t vloxei32(vbool64_t op0, vint8mf8_t op1, const int8_t * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_i8mf8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded long vfirst(vbool8_t op0, size_t op1){
  return vfirst_m_b8(op0, op1);
}

__rvv_overloaded long vfirst(vbool8_t op0, vbool8_t op1, size_t op2){
  return vfirst_m_b8_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool4_t op0, size_t op1){
  return vfirst_m_b4(op0, op1);
}

__rvv_overloaded long vfirst(vbool4_t op0, vbool4_t op1, size_t op2){
  return vfirst_m_b4_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool2_t op0, size_t op1){
  return vfirst_m_b2(op0, op1);
}

__rvv_overloaded long vfirst(vbool2_t op0, vbool2_t op1, size_t op2){
  return vfirst_m_b2_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool1_t op0, size_t op1){
  return vfirst_m_b1(op0, op1);
}

__rvv_overloaded long vfirst(vbool1_t op0, vbool1_t op1, size_t op2){
  return vfirst_m_b1_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool16_t op0, size_t op1){
  return vfirst_m_b16(op0, op1);
}

__rvv_overloaded long vfirst(vbool16_t op0, vbool16_t op1, size_t op2){
  return vfirst_m_b16_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool32_t op0, size_t op1){
  return vfirst_m_b32(op0, op1);
}

__rvv_overloaded long vfirst(vbool32_t op0, vbool32_t op1, size_t op2){
  return vfirst_m_b32_m(op0, op1, op2);
}

__rvv_overloaded long vfirst(vbool64_t op0, size_t op1){
  return vfirst_m_b64(op0, op1);
}

__rvv_overloaded long vfirst(vbool64_t op0, vbool64_t op1, size_t op2){
  return vfirst_m_b64_m(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmand(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmand_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmand(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmand_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmand(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmand_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmand(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmand_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmand(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmand_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmand(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmand_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmand(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmand_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmandnot(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmandnot_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmandnot(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmandnot_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmandnot(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmandnot_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmandnot(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmandnot_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmandnot(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmandnot_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmandnot(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmandnot_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmandnot(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmandnot_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmnand(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmnand_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmnand(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmnand_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmnand(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmnand_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmnand(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmnand_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmnand(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmnand_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmnand(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmnand_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmnand(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmnand_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmnor(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmnor_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmnor(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmnor_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmnor(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmnor_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmnor(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmnor_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmnor(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmnor_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmnor(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmnor_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmnor(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmnor_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmor(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmor_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmor(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmor_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmor(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmor_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmor(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmor_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmor(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmor_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmor(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmor_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmor(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmor_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmornot(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmornot_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmornot(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmornot_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmornot(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmornot_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmornot(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmornot_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmornot(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmornot_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmornot(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmornot_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmornot(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmornot_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmsbf(vbool8_t op0, size_t op1){
  return vmsbf_m_b8(op0, op1);
}

__rvv_overloaded vbool8_t vmsbf(vbool8_t op0, vbool8_t op1, vbool8_t op2, size_t op3){
  return vmsbf_m_b8_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsbf(vbool4_t op0, size_t op1){
  return vmsbf_m_b4(op0, op1);
}

__rvv_overloaded vbool4_t vmsbf(vbool4_t op0, vbool4_t op1, vbool4_t op2, size_t op3){
  return vmsbf_m_b4_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsbf(vbool2_t op0, size_t op1){
  return vmsbf_m_b2(op0, op1);
}

__rvv_overloaded vbool2_t vmsbf(vbool2_t op0, vbool2_t op1, vbool2_t op2, size_t op3){
  return vmsbf_m_b2_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsbf(vbool1_t op0, size_t op1){
  return vmsbf_m_b1(op0, op1);
}

__rvv_overloaded vbool1_t vmsbf(vbool1_t op0, vbool1_t op1, vbool1_t op2, size_t op3){
  return vmsbf_m_b1_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsbf(vbool16_t op0, size_t op1){
  return vmsbf_m_b16(op0, op1);
}

__rvv_overloaded vbool16_t vmsbf(vbool16_t op0, vbool16_t op1, vbool16_t op2, size_t op3){
  return vmsbf_m_b16_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsbf(vbool32_t op0, size_t op1){
  return vmsbf_m_b32(op0, op1);
}

__rvv_overloaded vbool32_t vmsbf(vbool32_t op0, vbool32_t op1, vbool32_t op2, size_t op3){
  return vmsbf_m_b32_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsbf(vbool64_t op0, size_t op1){
  return vmsbf_m_b64(op0, op1);
}

__rvv_overloaded vbool64_t vmsbf(vbool64_t op0, vbool64_t op1, vbool64_t op2, size_t op3){
  return vmsbf_m_b64_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsif(vbool8_t op0, size_t op1){
  return vmsif_m_b8(op0, op1);
}

__rvv_overloaded vbool8_t vmsif(vbool8_t op0, vbool8_t op1, vbool8_t op2, size_t op3){
  return vmsif_m_b8_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsif(vbool4_t op0, size_t op1){
  return vmsif_m_b4(op0, op1);
}

__rvv_overloaded vbool4_t vmsif(vbool4_t op0, vbool4_t op1, vbool4_t op2, size_t op3){
  return vmsif_m_b4_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsif(vbool2_t op0, size_t op1){
  return vmsif_m_b2(op0, op1);
}

__rvv_overloaded vbool2_t vmsif(vbool2_t op0, vbool2_t op1, vbool2_t op2, size_t op3){
  return vmsif_m_b2_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsif(vbool1_t op0, size_t op1){
  return vmsif_m_b1(op0, op1);
}

__rvv_overloaded vbool1_t vmsif(vbool1_t op0, vbool1_t op1, vbool1_t op2, size_t op3){
  return vmsif_m_b1_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsif(vbool16_t op0, size_t op1){
  return vmsif_m_b16(op0, op1);
}

__rvv_overloaded vbool16_t vmsif(vbool16_t op0, vbool16_t op1, vbool16_t op2, size_t op3){
  return vmsif_m_b16_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsif(vbool32_t op0, size_t op1){
  return vmsif_m_b32(op0, op1);
}

__rvv_overloaded vbool32_t vmsif(vbool32_t op0, vbool32_t op1, vbool32_t op2, size_t op3){
  return vmsif_m_b32_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsif(vbool64_t op0, size_t op1){
  return vmsif_m_b64(op0, op1);
}

__rvv_overloaded vbool64_t vmsif(vbool64_t op0, vbool64_t op1, vbool64_t op2, size_t op3){
  return vmsif_m_b64_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmsof(vbool8_t op0, size_t op1){
  return vmsof_m_b8(op0, op1);
}

__rvv_overloaded vbool8_t vmsof(vbool8_t op0, vbool8_t op1, vbool8_t op2, size_t op3){
  return vmsof_m_b8_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool4_t vmsof(vbool4_t op0, size_t op1){
  return vmsof_m_b4(op0, op1);
}

__rvv_overloaded vbool4_t vmsof(vbool4_t op0, vbool4_t op1, vbool4_t op2, size_t op3){
  return vmsof_m_b4_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool2_t vmsof(vbool2_t op0, size_t op1){
  return vmsof_m_b2(op0, op1);
}

__rvv_overloaded vbool2_t vmsof(vbool2_t op0, vbool2_t op1, vbool2_t op2, size_t op3){
  return vmsof_m_b2_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool1_t vmsof(vbool1_t op0, size_t op1){
  return vmsof_m_b1(op0, op1);
}

__rvv_overloaded vbool1_t vmsof(vbool1_t op0, vbool1_t op1, vbool1_t op2, size_t op3){
  return vmsof_m_b1_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool16_t vmsof(vbool16_t op0, size_t op1){
  return vmsof_m_b16(op0, op1);
}

__rvv_overloaded vbool16_t vmsof(vbool16_t op0, vbool16_t op1, vbool16_t op2, size_t op3){
  return vmsof_m_b16_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool32_t vmsof(vbool32_t op0, size_t op1){
  return vmsof_m_b32(op0, op1);
}

__rvv_overloaded vbool32_t vmsof(vbool32_t op0, vbool32_t op1, vbool32_t op2, size_t op3){
  return vmsof_m_b32_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool64_t vmsof(vbool64_t op0, size_t op1){
  return vmsof_m_b64(op0, op1);
}

__rvv_overloaded vbool64_t vmsof(vbool64_t op0, vbool64_t op1, vbool64_t op2, size_t op3){
  return vmsof_m_b64_m(op0, op1, op2, op3);
}

__rvv_overloaded vbool8_t vmxnor(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmxnor_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmxnor(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmxnor_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmxnor(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmxnor_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmxnor(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmxnor_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmxnor(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmxnor_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmxnor(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmxnor_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmxnor(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmxnor_mm_b64(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmxor(vbool8_t op0, vbool8_t op1, size_t op2){
  return vmxor_mm_b8(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmxor(vbool4_t op0, vbool4_t op1, size_t op2){
  return vmxor_mm_b4(op0, op1, op2);
}

__rvv_overloaded vbool2_t vmxor(vbool2_t op0, vbool2_t op1, size_t op2){
  return vmxor_mm_b2(op0, op1, op2);
}

__rvv_overloaded vbool1_t vmxor(vbool1_t op0, vbool1_t op1, size_t op2){
  return vmxor_mm_b1(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmxor(vbool16_t op0, vbool16_t op1, size_t op2){
  return vmxor_mm_b16(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmxor(vbool32_t op0, vbool32_t op1, size_t op2){
  return vmxor_mm_b32(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmxor(vbool64_t op0, vbool64_t op1, size_t op2){
  return vmxor_mm_b64(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool8_t op0, size_t op1){
  return vpopc_m_b8(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool8_t op0, vbool8_t op1, size_t op2){
  return vpopc_m_b8_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool4_t op0, size_t op1){
  return vpopc_m_b4(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool4_t op0, vbool4_t op1, size_t op2){
  return vpopc_m_b4_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool2_t op0, size_t op1){
  return vpopc_m_b2(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool2_t op0, vbool2_t op1, size_t op2){
  return vpopc_m_b2_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool1_t op0, size_t op1){
  return vpopc_m_b1(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool1_t op0, vbool1_t op1, size_t op2){
  return vpopc_m_b1_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool16_t op0, size_t op1){
  return vpopc_m_b16(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool16_t op0, vbool16_t op1, size_t op2){
  return vpopc_m_b16_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool32_t op0, size_t op1){
  return vpopc_m_b32(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool32_t op0, vbool32_t op1, size_t op2){
  return vpopc_m_b32_m(op0, op1, op2);
}

__rvv_overloaded unsigned long vpopc(vbool64_t op0, size_t op1){
  return vpopc_m_b64(op0, op1);
}

__rvv_overloaded unsigned long vpopc(vbool64_t op0, vbool64_t op1, size_t op2){
  return vpopc_m_b64_m(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool8_t op1, size_t op2){
  return vse1_v_b8(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool4_t op1, size_t op2){
  return vse1_v_b4(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool2_t op1, size_t op2){
  return vse1_v_b2(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool1_t op1, size_t op2){
  return vse1_v_b1(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool16_t op1, size_t op2){
  return vse1_v_b16(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool32_t op1, size_t op2){
  return vse1_v_b32(op0, op1, op2);
}

__rvv_overloaded void vse1(uint8_t * op0, vbool64_t op1, size_t op2){
  return vse1_v_b64(op0, op1, op2);
}

__rvv_overloaded vint16mf4_t vsext_vf2(vint8mf8_t op0, size_t op1){
  return vsext_vf2_i16mf4(op0, op1);
}

__rvv_overloaded vint16mf4_t vsext_vf2(vbool64_t op0, vint16mf4_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf2_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vsext_vf2(vint8mf4_t op0, size_t op1){
  return vsext_vf2_i16mf2(op0, op1);
}

__rvv_overloaded vint16mf2_t vsext_vf2(vbool32_t op0, vint16mf2_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf2_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vsext_vf2(vint8mf2_t op0, size_t op1){
  return vsext_vf2_i16m1(op0, op1);
}

__rvv_overloaded vint16m1_t vsext_vf2(vbool16_t op0, vint16m1_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf2_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vsext_vf2(vint8m1_t op0, size_t op1){
  return vsext_vf2_i16m2(op0, op1);
}

__rvv_overloaded vint16m2_t vsext_vf2(vbool8_t op0, vint16m2_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf2_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vsext_vf2(vint8m2_t op0, size_t op1){
  return vsext_vf2_i16m4(op0, op1);
}

__rvv_overloaded vint16m4_t vsext_vf2(vbool4_t op0, vint16m4_t op1, vint8m2_t op2, size_t op3){
  return vsext_vf2_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m8_t vsext_vf2(vint8m4_t op0, size_t op1){
  return vsext_vf2_i16m8(op0, op1);
}

__rvv_overloaded vint16m8_t vsext_vf2(vbool2_t op0, vint16m8_t op1, vint8m4_t op2, size_t op3){
  return vsext_vf2_i16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsext_vf2(vint16mf4_t op0, size_t op1){
  return vsext_vf2_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vsext_vf2(vbool64_t op0, vint32mf2_t op1, vint16mf4_t op2, size_t op3){
  return vsext_vf2_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsext_vf2(vint16mf2_t op0, size_t op1){
  return vsext_vf2_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vsext_vf2(vbool32_t op0, vint32m1_t op1, vint16mf2_t op2, size_t op3){
  return vsext_vf2_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsext_vf2(vint16m1_t op0, size_t op1){
  return vsext_vf2_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vsext_vf2(vbool16_t op0, vint32m2_t op1, vint16m1_t op2, size_t op3){
  return vsext_vf2_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsext_vf2(vint16m2_t op0, size_t op1){
  return vsext_vf2_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vsext_vf2(vbool8_t op0, vint32m4_t op1, vint16m2_t op2, size_t op3){
  return vsext_vf2_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsext_vf2(vint16m4_t op0, size_t op1){
  return vsext_vf2_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vsext_vf2(vbool4_t op0, vint32m8_t op1, vint16m4_t op2, size_t op3){
  return vsext_vf2_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf2(vint32mf2_t op0, size_t op1){
  return vsext_vf2_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf2(vbool64_t op0, vint64m1_t op1, vint32mf2_t op2, size_t op3){
  return vsext_vf2_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf2(vint32m1_t op0, size_t op1){
  return vsext_vf2_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf2(vbool32_t op0, vint64m2_t op1, vint32m1_t op2, size_t op3){
  return vsext_vf2_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf2(vint32m2_t op0, size_t op1){
  return vsext_vf2_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf2(vbool16_t op0, vint64m4_t op1, vint32m2_t op2, size_t op3){
  return vsext_vf2_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf2(vint32m4_t op0, size_t op1){
  return vsext_vf2_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf2(vbool8_t op0, vint64m8_t op1, vint32m4_t op2, size_t op3){
  return vsext_vf2_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vsext_vf4(vint8mf8_t op0, size_t op1){
  return vsext_vf4_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vsext_vf4(vbool64_t op0, vint32mf2_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf4_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vsext_vf4(vint8mf4_t op0, size_t op1){
  return vsext_vf4_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vsext_vf4(vbool32_t op0, vint32m1_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf4_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vsext_vf4(vint8mf2_t op0, size_t op1){
  return vsext_vf4_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vsext_vf4(vbool16_t op0, vint32m2_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf4_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vsext_vf4(vint8m1_t op0, size_t op1){
  return vsext_vf4_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vsext_vf4(vbool8_t op0, vint32m4_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf4_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vsext_vf4(vint8m2_t op0, size_t op1){
  return vsext_vf4_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vsext_vf4(vbool4_t op0, vint32m8_t op1, vint8m2_t op2, size_t op3){
  return vsext_vf4_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf4(vint16mf4_t op0, size_t op1){
  return vsext_vf4_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf4(vbool64_t op0, vint64m1_t op1, vint16mf4_t op2, size_t op3){
  return vsext_vf4_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf4(vint16mf2_t op0, size_t op1){
  return vsext_vf4_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf4(vbool32_t op0, vint64m2_t op1, vint16mf2_t op2, size_t op3){
  return vsext_vf4_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf4(vint16m1_t op0, size_t op1){
  return vsext_vf4_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf4(vbool16_t op0, vint64m4_t op1, vint16m1_t op2, size_t op3){
  return vsext_vf4_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf4(vint16m2_t op0, size_t op1){
  return vsext_vf4_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf4(vbool8_t op0, vint64m8_t op1, vint16m2_t op2, size_t op3){
  return vsext_vf4_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vsext_vf8(vint8mf8_t op0, size_t op1){
  return vsext_vf8_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vsext_vf8(vbool64_t op0, vint64m1_t op1, vint8mf8_t op2, size_t op3){
  return vsext_vf8_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vsext_vf8(vint8mf4_t op0, size_t op1){
  return vsext_vf8_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vsext_vf8(vbool32_t op0, vint64m2_t op1, vint8mf4_t op2, size_t op3){
  return vsext_vf8_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vsext_vf8(vint8mf2_t op0, size_t op1){
  return vsext_vf8_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vsext_vf8(vbool16_t op0, vint64m4_t op1, vint8mf2_t op2, size_t op3){
  return vsext_vf8_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vsext_vf8(vint8m1_t op0, size_t op1){
  return vsext_vf8_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vsext_vf8(vbool8_t op0, vint64m8_t op1, vint8m1_t op2, size_t op3){
  return vsext_vf8_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vzext_vf2(vuint8mf8_t op0, size_t op1){
  return vzext_vf2_u16mf4(op0, op1);
}

__rvv_overloaded vuint16mf4_t vzext_vf2(vbool64_t op0, vuint16mf4_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf2_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vzext_vf2(vuint8mf4_t op0, size_t op1){
  return vzext_vf2_u16mf2(op0, op1);
}

__rvv_overloaded vuint16mf2_t vzext_vf2(vbool32_t op0, vuint16mf2_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf2_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vzext_vf2(vuint8mf2_t op0, size_t op1){
  return vzext_vf2_u16m1(op0, op1);
}

__rvv_overloaded vuint16m1_t vzext_vf2(vbool16_t op0, vuint16m1_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf2_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vzext_vf2(vuint8m1_t op0, size_t op1){
  return vzext_vf2_u16m2(op0, op1);
}

__rvv_overloaded vuint16m2_t vzext_vf2(vbool8_t op0, vuint16m2_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf2_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vzext_vf2(vuint8m2_t op0, size_t op1){
  return vzext_vf2_u16m4(op0, op1);
}

__rvv_overloaded vuint16m4_t vzext_vf2(vbool4_t op0, vuint16m4_t op1, vuint8m2_t op2, size_t op3){
  return vzext_vf2_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m8_t vzext_vf2(vuint8m4_t op0, size_t op1){
  return vzext_vf2_u16m8(op0, op1);
}

__rvv_overloaded vuint16m8_t vzext_vf2(vbool2_t op0, vuint16m8_t op1, vuint8m4_t op2, size_t op3){
  return vzext_vf2_u16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vzext_vf2(vuint16mf4_t op0, size_t op1){
  return vzext_vf2_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vzext_vf2(vbool64_t op0, vuint32mf2_t op1, vuint16mf4_t op2, size_t op3){
  return vzext_vf2_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vzext_vf2(vuint16mf2_t op0, size_t op1){
  return vzext_vf2_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vzext_vf2(vbool32_t op0, vuint32m1_t op1, vuint16mf2_t op2, size_t op3){
  return vzext_vf2_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vzext_vf2(vuint16m1_t op0, size_t op1){
  return vzext_vf2_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vzext_vf2(vbool16_t op0, vuint32m2_t op1, vuint16m1_t op2, size_t op3){
  return vzext_vf2_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vzext_vf2(vuint16m2_t op0, size_t op1){
  return vzext_vf2_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vzext_vf2(vbool8_t op0, vuint32m4_t op1, vuint16m2_t op2, size_t op3){
  return vzext_vf2_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vzext_vf2(vuint16m4_t op0, size_t op1){
  return vzext_vf2_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vzext_vf2(vbool4_t op0, vuint32m8_t op1, vuint16m4_t op2, size_t op3){
  return vzext_vf2_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf2(vuint32mf2_t op0, size_t op1){
  return vzext_vf2_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf2(vbool64_t op0, vuint64m1_t op1, vuint32mf2_t op2, size_t op3){
  return vzext_vf2_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf2(vuint32m1_t op0, size_t op1){
  return vzext_vf2_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf2(vbool32_t op0, vuint64m2_t op1, vuint32m1_t op2, size_t op3){
  return vzext_vf2_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf2(vuint32m2_t op0, size_t op1){
  return vzext_vf2_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf2(vbool16_t op0, vuint64m4_t op1, vuint32m2_t op2, size_t op3){
  return vzext_vf2_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf2(vuint32m4_t op0, size_t op1){
  return vzext_vf2_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf2(vbool8_t op0, vuint64m8_t op1, vuint32m4_t op2, size_t op3){
  return vzext_vf2_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vzext_vf4(vuint8mf8_t op0, size_t op1){
  return vzext_vf4_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vzext_vf4(vbool64_t op0, vuint32mf2_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf4_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vzext_vf4(vuint8mf4_t op0, size_t op1){
  return vzext_vf4_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vzext_vf4(vbool32_t op0, vuint32m1_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf4_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vzext_vf4(vuint8mf2_t op0, size_t op1){
  return vzext_vf4_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vzext_vf4(vbool16_t op0, vuint32m2_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf4_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vzext_vf4(vuint8m1_t op0, size_t op1){
  return vzext_vf4_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vzext_vf4(vbool8_t op0, vuint32m4_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf4_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vzext_vf4(vuint8m2_t op0, size_t op1){
  return vzext_vf4_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vzext_vf4(vbool4_t op0, vuint32m8_t op1, vuint8m2_t op2, size_t op3){
  return vzext_vf4_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf4(vuint16mf4_t op0, size_t op1){
  return vzext_vf4_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf4(vbool64_t op0, vuint64m1_t op1, vuint16mf4_t op2, size_t op3){
  return vzext_vf4_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf4(vuint16mf2_t op0, size_t op1){
  return vzext_vf4_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf4(vbool32_t op0, vuint64m2_t op1, vuint16mf2_t op2, size_t op3){
  return vzext_vf4_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf4(vuint16m1_t op0, size_t op1){
  return vzext_vf4_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf4(vbool16_t op0, vuint64m4_t op1, vuint16m1_t op2, size_t op3){
  return vzext_vf4_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf4(vuint16m2_t op0, size_t op1){
  return vzext_vf4_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf4(vbool8_t op0, vuint64m8_t op1, vuint16m2_t op2, size_t op3){
  return vzext_vf4_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vzext_vf8(vuint8mf8_t op0, size_t op1){
  return vzext_vf8_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vzext_vf8(vbool64_t op0, vuint64m1_t op1, vuint8mf8_t op2, size_t op3){
  return vzext_vf8_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vzext_vf8(vuint8mf4_t op0, size_t op1){
  return vzext_vf8_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vzext_vf8(vbool32_t op0, vuint64m2_t op1, vuint8mf4_t op2, size_t op3){
  return vzext_vf8_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vzext_vf8(vuint8mf2_t op0, size_t op1){
  return vzext_vf8_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vzext_vf8(vbool16_t op0, vuint64m4_t op1, vuint8mf2_t op2, size_t op3){
  return vzext_vf8_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vzext_vf8(vuint8m1_t op0, size_t op1){
  return vzext_vf8_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vzext_vf8(vbool8_t op0, vuint64m8_t op1, vuint8m1_t op2, size_t op3){
  return vzext_vf8_u64m8_m(op0, op1, op2, op3);
}

#if defined(__riscv_f)
__rvv_overloaded vfloat32m1_t vloxei8(const float * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei8(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei8(const float * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei8(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei8(const float * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei8(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei8(const float * op0, vuint8m2_t op1, size_t op2){
  return vloxei8_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei8(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint8m2_t op3, size_t op4){
  return vloxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei8(const float * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei8(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei16(const float * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei16(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei16(const float * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei16(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei16(const float * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei16(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei16(const float * op0, vuint16m4_t op1, size_t op2){
  return vloxei16_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei16(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint16m4_t op3, size_t op4){
  return vloxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei16(const float * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei16(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei32(const float * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei32(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei32(const float * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei32(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei32(const float * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei32(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vloxei32(const float * op0, vuint32m8_t op1, size_t op2){
  return vloxei32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vloxei32(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint32m8_t op3, size_t op4){
  return vloxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei32(const float * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vloxei64(const float * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vloxei64(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vloxei64(const float * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vloxei64(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vloxei64(const float * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vloxei64(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vloxei64(const float * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vloxei64(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(float * op0, vuint8mf4_t op1, vfloat32m1_t op2, size_t op3){
  return vsuxei8_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, float * op1, vuint8mf4_t op2, vfloat32m1_t op3, size_t op4){
  return vsuxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(float * op0, vuint8mf2_t op1, vfloat32m2_t op2, size_t op3){
  return vsuxei8_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, float * op1, vuint8mf2_t op2, vfloat32m2_t op3, size_t op4){
  return vsuxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(float * op0, vuint8m1_t op1, vfloat32m4_t op2, size_t op3){
  return vsuxei8_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, float * op1, vuint8m1_t op2, vfloat32m4_t op3, size_t op4){
  return vsuxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(float * op0, vuint8m2_t op1, vfloat32m8_t op2, size_t op3){
  return vsuxei8_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool4_t op0, float * op1, vuint8m2_t op2, vfloat32m8_t op3, size_t op4){
  return vsuxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(float * op0, vuint8mf8_t op1, vfloat32mf2_t op2, size_t op3){
  return vsuxei8_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, float * op1, vuint8mf8_t op2, vfloat32mf2_t op3, size_t op4){
  return vsuxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(float * op0, vuint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vsuxei16_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, float * op1, vuint16mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vsuxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(float * op0, vuint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vsuxei16_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, float * op1, vuint16m1_t op2, vfloat32m2_t op3, size_t op4){
  return vsuxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(float * op0, vuint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vsuxei16_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, float * op1, vuint16m2_t op2, vfloat32m4_t op3, size_t op4){
  return vsuxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(float * op0, vuint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vsuxei16_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool4_t op0, float * op1, vuint16m4_t op2, vfloat32m8_t op3, size_t op4){
  return vsuxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(float * op0, vuint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vsuxei16_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, float * op1, vuint16mf4_t op2, vfloat32mf2_t op3, size_t op4){
  return vsuxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(float * op0, vuint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vsuxei32_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, float * op1, vuint32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vsuxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(float * op0, vuint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vsuxei32_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, float * op1, vuint32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vsuxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(float * op0, vuint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vsuxei32_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, float * op1, vuint32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vsuxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(float * op0, vuint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vsuxei32_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool4_t op0, float * op1, vuint32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vsuxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(float * op0, vuint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vsuxei32_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, float * op1, vuint32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vsuxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(float * op0, vuint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vsuxei64_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, float * op1, vuint64m2_t op2, vfloat32m1_t op3, size_t op4){
  return vsuxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(float * op0, vuint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vsuxei64_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, float * op1, vuint64m4_t op2, vfloat32m2_t op3, size_t op4){
  return vsuxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(float * op0, vuint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vsuxei64_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, float * op1, vuint64m8_t op2, vfloat32m4_t op3, size_t op4){
  return vsuxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(float * op0, vuint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vsuxei64_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, float * op1, vuint64m1_t op2, vfloat32mf2_t op3, size_t op4){
  return vsuxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(float * op0, vuint8mf4_t op1, vfloat32m1_t op2, size_t op3){
  return vsoxei8_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, float * op1, vuint8mf4_t op2, vfloat32m1_t op3, size_t op4){
  return vsoxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(float * op0, vuint8mf2_t op1, vfloat32m2_t op2, size_t op3){
  return vsoxei8_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, float * op1, vuint8mf2_t op2, vfloat32m2_t op3, size_t op4){
  return vsoxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(float * op0, vuint8m1_t op1, vfloat32m4_t op2, size_t op3){
  return vsoxei8_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, float * op1, vuint8m1_t op2, vfloat32m4_t op3, size_t op4){
  return vsoxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(float * op0, vuint8m2_t op1, vfloat32m8_t op2, size_t op3){
  return vsoxei8_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool4_t op0, float * op1, vuint8m2_t op2, vfloat32m8_t op3, size_t op4){
  return vsoxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(float * op0, vuint8mf8_t op1, vfloat32mf2_t op2, size_t op3){
  return vsoxei8_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, float * op1, vuint8mf8_t op2, vfloat32mf2_t op3, size_t op4){
  return vsoxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(float * op0, vuint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vsoxei16_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, float * op1, vuint16mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vsoxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(float * op0, vuint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vsoxei16_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, float * op1, vuint16m1_t op2, vfloat32m2_t op3, size_t op4){
  return vsoxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(float * op0, vuint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vsoxei16_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, float * op1, vuint16m2_t op2, vfloat32m4_t op3, size_t op4){
  return vsoxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(float * op0, vuint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vsoxei16_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool4_t op0, float * op1, vuint16m4_t op2, vfloat32m8_t op3, size_t op4){
  return vsoxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(float * op0, vuint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vsoxei16_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, float * op1, vuint16mf4_t op2, vfloat32mf2_t op3, size_t op4){
  return vsoxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(float * op0, vuint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vsoxei32_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, float * op1, vuint32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vsoxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(float * op0, vuint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vsoxei32_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, float * op1, vuint32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vsoxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(float * op0, vuint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vsoxei32_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, float * op1, vuint32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vsoxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(float * op0, vuint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vsoxei32_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool4_t op0, float * op1, vuint32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vsoxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(float * op0, vuint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vsoxei32_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, float * op1, vuint32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vsoxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(float * op0, vuint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vsoxei64_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, float * op1, vuint64m2_t op2, vfloat32m1_t op3, size_t op4){
  return vsoxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(float * op0, vuint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vsoxei64_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, float * op1, vuint64m4_t op2, vfloat32m2_t op3, size_t op4){
  return vsoxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(float * op0, vuint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vsoxei64_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, float * op1, vuint64m8_t op2, vfloat32m4_t op3, size_t op4){
  return vsoxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(float * op0, vuint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vsoxei64_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, float * op1, vuint64m1_t op2, vfloat32mf2_t op3, size_t op4){
  return vsoxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vle32ff(vbool32_t op0, vfloat32m1_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vle32ff(vbool16_t op0, vfloat32m2_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vle32ff(vbool8_t op0, vfloat32m4_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vle32ff(vbool4_t op0, vfloat32m8_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vle32ff(vbool64_t op0, vfloat32mf2_t op1, const float * op2, size_t * op3, size_t op4){
  return vle32ff_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vle32(vbool32_t op0, vfloat32m1_t op1, const float * op2, size_t op3){
  return vle32_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vle32(vbool16_t op0, vfloat32m2_t op1, const float * op2, size_t op3){
  return vle32_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vle32(vbool8_t op0, vfloat32m4_t op1, const float * op2, size_t op3){
  return vle32_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vle32(vbool4_t op0, vfloat32m8_t op1, const float * op2, size_t op3){
  return vle32_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vle32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, size_t op3){
  return vle32_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m1_t op1, size_t op2){
  return vse32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool32_t op0, float * op1, vfloat32m1_t op2, size_t op3){
  return vse32_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m2_t op1, size_t op2){
  return vse32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool16_t op0, float * op1, vfloat32m2_t op2, size_t op3){
  return vse32_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m4_t op1, size_t op2){
  return vse32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool8_t op0, float * op1, vfloat32m4_t op2, size_t op3){
  return vse32_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32m8_t op1, size_t op2){
  return vse32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool4_t op0, float * op1, vfloat32m8_t op2, size_t op3){
  return vse32_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse32(float * op0, vfloat32mf2_t op1, size_t op2){
  return vse32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded void vse32(vbool64_t op0, float * op1, vfloat32mf2_t op2, size_t op3){
  return vse32_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfadd(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfadd_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfadd_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfadd(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfadd_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfadd_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfadd(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfadd_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfadd_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfadd(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfadd_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfadd_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfadd(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfadd_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfadd_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfadd(vfloat32m1_t op0, float op1, size_t op2){
  return vfadd_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfadd_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfadd(vfloat32m2_t op0, float op1, size_t op2){
  return vfadd_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfadd_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfadd(vfloat32m4_t op0, float op1, size_t op2){
  return vfadd_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfadd_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfadd(vfloat32m8_t op0, float op1, size_t op2){
  return vfadd_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfadd_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfadd(vfloat32mf2_t op0, float op1, size_t op2){
  return vfadd_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfadd_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsub(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfsub_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsub(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfsub_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsub(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfsub_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsub(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfsub_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsub(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfsub_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsub(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfsub_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsub(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfsub_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsub(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfsub_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsub(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfsub_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsub(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfsub_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsub(vfloat32m1_t op0, float op1, size_t op2){
  return vfsub_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsub(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfsub_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsub(vfloat32m2_t op0, float op1, size_t op2){
  return vfsub_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsub(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfsub_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsub(vfloat32m4_t op0, float op1, size_t op2){
  return vfsub_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsub(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfsub_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsub(vfloat32m8_t op0, float op1, size_t op2){
  return vfsub_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsub(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfsub_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsub(vfloat32mf2_t op0, float op1, size_t op2){
  return vfsub_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsub(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfsub_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfrsub(vfloat32m1_t op0, float op1, size_t op2){
  return vfrsub_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfrsub(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfrsub_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfrsub(vfloat32m2_t op0, float op1, size_t op2){
  return vfrsub_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfrsub(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfrsub_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfrsub(vfloat32m4_t op0, float op1, size_t op2){
  return vfrsub_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfrsub(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfrsub_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfrsub(vfloat32m8_t op0, float op1, size_t op2){
  return vfrsub_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfrsub(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfrsub_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfrsub(vfloat32mf2_t op0, float op1, size_t op2){
  return vfrsub_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfrsub(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfrsub_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmul(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfmul_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmul(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmul_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmul(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfmul_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmul(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmul_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmul(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfmul_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmul(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmul_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmul(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfmul_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmul(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmul_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmul(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfmul_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmul(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmul_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmul(vfloat32m1_t op0, float op1, size_t op2){
  return vfmul_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmul(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfmul_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmul(vfloat32m2_t op0, float op1, size_t op2){
  return vfmul_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmul(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfmul_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmul(vfloat32m4_t op0, float op1, size_t op2){
  return vfmul_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmul(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfmul_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmul(vfloat32m8_t op0, float op1, size_t op2){
  return vfmul_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmul(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfmul_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmul(vfloat32mf2_t op0, float op1, size_t op2){
  return vfmul_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmul(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfmul_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfdiv(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfdiv_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfdiv(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfdiv_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfdiv(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfdiv_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfdiv(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfdiv_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfdiv(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfdiv_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfdiv(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfdiv_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfdiv(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfdiv_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfdiv(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfdiv_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfdiv(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfdiv_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfdiv(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfdiv_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfdiv(vfloat32m1_t op0, float op1, size_t op2){
  return vfdiv_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfdiv(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfdiv_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfdiv(vfloat32m2_t op0, float op1, size_t op2){
  return vfdiv_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfdiv(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfdiv_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfdiv(vfloat32m4_t op0, float op1, size_t op2){
  return vfdiv_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfdiv(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfdiv_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfdiv(vfloat32m8_t op0, float op1, size_t op2){
  return vfdiv_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfdiv(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfdiv_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfdiv(vfloat32mf2_t op0, float op1, size_t op2){
  return vfdiv_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfdiv(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfdiv_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfrdiv(vfloat32m1_t op0, float op1, size_t op2){
  return vfrdiv_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfrdiv(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfrdiv_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfrdiv(vfloat32m2_t op0, float op1, size_t op2){
  return vfrdiv_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfrdiv(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfrdiv_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfrdiv(vfloat32m4_t op0, float op1, size_t op2){
  return vfrdiv_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfrdiv(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfrdiv_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfrdiv(vfloat32m8_t op0, float op1, size_t op2){
  return vfrdiv_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfrdiv(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfrdiv_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfrdiv(vfloat32mf2_t op0, float op1, size_t op2){
  return vfrdiv_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfrdiv(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfrdiv_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmacc(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfmacc_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmacc(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmacc_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmacc(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfmacc_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmacc(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmacc_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmacc(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfmacc_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmacc(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmacc_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmacc(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfmacc_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmacc(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmacc_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmacc(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfmacc_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmacc(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmacc_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmacc(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfmacc_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmacc(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfmacc_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmacc(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfmacc_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmacc(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfmacc_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmacc(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfmacc_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmacc(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfmacc_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmacc(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfmacc_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmacc(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfmacc_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmacc(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfmacc_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmacc(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfmacc_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmacc(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfnmacc_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmacc(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfnmacc_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmacc(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfnmacc_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmacc(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfnmacc_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmacc(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfnmacc_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmacc(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfnmacc_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmacc(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfnmacc_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmacc(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfnmacc_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmacc(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfnmacc_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmacc(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfnmacc_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmacc(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfnmacc_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmacc(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfnmacc_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmacc(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfnmacc_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmacc(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfnmacc_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmacc(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfnmacc_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmacc(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfnmacc_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmacc(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfnmacc_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmacc(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfnmacc_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmacc(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfnmacc_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmacc(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfnmacc_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmsac(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfmsac_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmsac(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmsac_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmsac(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfmsac_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmsac(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmsac_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmsac(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfmsac_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmsac(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmsac_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmsac(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfmsac_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmsac(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmsac_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmsac(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfmsac_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmsac(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmsac_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmsac(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfmsac_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmsac(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfmsac_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmsac(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfmsac_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmsac(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfmsac_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmsac(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfmsac_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmsac(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfmsac_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmsac(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfmsac_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmsac(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfmsac_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmsac(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfmsac_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmsac(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfmsac_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmsac(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfnmsac_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmsac(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfnmsac_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmsac(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfnmsac_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmsac(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfnmsac_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmsac(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfnmsac_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmsac(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfnmsac_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmsac(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfnmsac_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmsac(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfnmsac_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmsac(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfnmsac_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmsac(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfnmsac_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmsac(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfnmsac_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmsac(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfnmsac_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmsac(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfnmsac_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmsac(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfnmsac_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmsac(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfnmsac_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmsac(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfnmsac_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmsac(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfnmsac_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmsac(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfnmsac_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmsac(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfnmsac_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmsac(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfnmsac_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmadd(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfmadd_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmadd_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmadd(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfmadd_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmadd_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmadd(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfmadd_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmadd_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmadd(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfmadd_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmadd_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmadd(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfmadd_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmadd_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmadd(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfmadd_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmadd(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfmadd_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmadd(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfmadd_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmadd(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfmadd_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmadd(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfmadd_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmadd(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfmadd_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmadd(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfmadd_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmadd(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfmadd_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmadd(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfmadd_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmadd(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfmadd_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmadd(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfnmadd_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmadd(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfnmadd_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmadd(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfnmadd_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmadd(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfnmadd_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmadd(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfnmadd_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmadd(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfnmadd_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmadd(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfnmadd_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmadd(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfnmadd_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmadd(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfnmadd_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmadd(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfnmadd_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmadd(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfnmadd_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmadd(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfnmadd_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmadd(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfnmadd_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmadd(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfnmadd_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmadd(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfnmadd_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmadd(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfnmadd_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmadd(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfnmadd_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmadd(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfnmadd_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmadd(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfnmadd_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmadd(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfnmadd_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmsub(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfmsub_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmsub(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmsub_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmsub(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfmsub_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmsub(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmsub_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmsub(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfmsub_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmsub(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmsub_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmsub(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfmsub_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmsub(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmsub_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmsub(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfmsub_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmsub(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmsub_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vlse32(vbool32_t op0, vfloat32m1_t op1, const float * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vlse32(vbool16_t op0, vfloat32m2_t op1, const float * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vlse32(vbool8_t op0, vfloat32m4_t op1, const float * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vlse32(vbool4_t op0, vfloat32m8_t op1, const float * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vlse32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, ptrdiff_t op3, size_t op4){
  return vlse32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmsub(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfmsub_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmsub(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfmsub_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmsub(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfmsub_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmsub(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfmsub_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmsub(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfmsub_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmsub(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfmsub_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmsub(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfmsub_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmsub(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfmsub_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmsub(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfmsub_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmsub(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfmsub_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmsub(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfnmsub_vv_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmsub(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfnmsub_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmsub(vfloat32m2_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfnmsub_vv_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmsub(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfnmsub_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmsub(vfloat32m4_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfnmsub_vv_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmsub(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfnmsub_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmsub(vfloat32m8_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfnmsub_vv_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmsub(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfnmsub_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmsub(vfloat32mf2_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfnmsub_vv_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmsub(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfnmsub_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfnmsub(vfloat32m1_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfnmsub_vf_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfnmsub(vbool32_t op0, vfloat32m1_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfnmsub_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfnmsub(vfloat32m2_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfnmsub_vf_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfnmsub(vbool16_t op0, vfloat32m2_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfnmsub_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfnmsub(vfloat32m4_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfnmsub_vf_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfnmsub(vbool8_t op0, vfloat32m4_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfnmsub_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfnmsub(vfloat32m8_t op0, float op1, vfloat32m8_t op2, size_t op3){
  return vfnmsub_vf_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfnmsub(vbool4_t op0, vfloat32m8_t op1, float op2, vfloat32m8_t op3, size_t op4){
  return vfnmsub_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfnmsub(vfloat32mf2_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfnmsub_vf_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfnmsub(vbool64_t op0, vfloat32mf2_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfnmsub_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmin(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfmin_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmin(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmin_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmin(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfmin_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmin(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmin_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmin(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfmin_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmin(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmin_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmin(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfmin_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmin(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmin_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmin(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfmin_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmin(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmin_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmin(vfloat32m1_t op0, float op1, size_t op2){
  return vfmin_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmin(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfmin_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmin(vfloat32m2_t op0, float op1, size_t op2){
  return vfmin_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmin(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfmin_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmin(vfloat32m4_t op0, float op1, size_t op2){
  return vfmin_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmin(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfmin_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmin(vfloat32m8_t op0, float op1, size_t op2){
  return vfmin_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmin(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfmin_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmin(vfloat32mf2_t op0, float op1, size_t op2){
  return vfmin_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmin(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfmin_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmax(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfmax_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmax(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfmax_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmax(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfmax_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmax(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfmax_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmax(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfmax_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmax(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfmax_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmax(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfmax_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmax(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfmax_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmax(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfmax_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmax(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfmax_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfmax(vfloat32m1_t op0, float op1, size_t op2){
  return vfmax_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfmax(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfmax_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfmax(vfloat32m2_t op0, float op1, size_t op2){
  return vfmax_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfmax(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfmax_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfmax(vfloat32m4_t op0, float op1, size_t op2){
  return vfmax_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfmax(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfmax_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfmax(vfloat32m8_t op0, float op1, size_t op2){
  return vfmax_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfmax(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfmax_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfmax(vfloat32mf2_t op0, float op1, size_t op2){
  return vfmax_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfmax(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfmax_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnj(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfsgnj_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnj(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfsgnj_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnj(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfsgnj_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnj(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfsgnj_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnj(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfsgnj_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnj(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfsgnj_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnj(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfsgnj_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnj(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfsgnj_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnj(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfsgnj_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnj(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfsgnj_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnj(vfloat32m1_t op0, float op1, size_t op2){
  return vfsgnj_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnj(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfsgnj_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnj(vfloat32m2_t op0, float op1, size_t op2){
  return vfsgnj_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnj(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfsgnj_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnj(vfloat32m4_t op0, float op1, size_t op2){
  return vfsgnj_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnj(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfsgnj_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnj(vfloat32m8_t op0, float op1, size_t op2){
  return vfsgnj_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnj(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfsgnj_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnj(vfloat32mf2_t op0, float op1, size_t op2){
  return vfsgnj_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnj(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfsgnj_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnjn(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfsgnjn_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnjn(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfsgnjn_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnjn(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfsgnjn_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnjn(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfsgnjn_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnjn(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfsgnjn_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnjn(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfsgnjn_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnjn(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfsgnjn_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnjn(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfsgnjn_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnjn(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfsgnjn_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnjn(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfsgnjn_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnjn(vfloat32m1_t op0, float op1, size_t op2){
  return vfsgnjn_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnjn(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfsgnjn_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnjn(vfloat32m2_t op0, float op1, size_t op2){
  return vfsgnjn_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnjn(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfsgnjn_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnjn(vfloat32m4_t op0, float op1, size_t op2){
  return vfsgnjn_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnjn(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfsgnjn_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnjn(vfloat32m8_t op0, float op1, size_t op2){
  return vfsgnjn_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnjn(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfsgnjn_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnjn(vfloat32mf2_t op0, float op1, size_t op2){
  return vfsgnjn_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnjn(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfsgnjn_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnjx(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfsgnjx_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnjx(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfsgnjx_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnjx(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfsgnjx_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnjx(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfsgnjx_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnjx(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfsgnjx_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnjx(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfsgnjx_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnjx(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vfsgnjx_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnjx(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vfsgnjx_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnjx(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfsgnjx_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnjx(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfsgnjx_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfsgnjx(vfloat32m1_t op0, float op1, size_t op2){
  return vfsgnjx_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfsgnjx(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfsgnjx_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfsgnjx(vfloat32m2_t op0, float op1, size_t op2){
  return vfsgnjx_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfsgnjx(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfsgnjx_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfsgnjx(vfloat32m4_t op0, float op1, size_t op2){
  return vfsgnjx_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfsgnjx(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfsgnjx_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfsgnjx(vfloat32m8_t op0, float op1, size_t op2){
  return vfsgnjx_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfsgnjx(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfsgnjx_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfsgnjx(vfloat32mf2_t op0, float op1, size_t op2){
  return vfsgnjx_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfsgnjx(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfsgnjx_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfeq(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vmfeq_vv_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfeq(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vmfeq_vv_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfeq(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vmfeq_vv_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfeq(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vmfeq_vv_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfeq(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vmfeq_vv_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfeq(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vmfeq_vv_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfeq(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vmfeq_vv_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfeq(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vmfeq_vv_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfeq(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vmfeq_vv_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfeq(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vmfeq_vv_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfeq(vfloat32m1_t op0, float op1, size_t op2){
  return vmfeq_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfeq(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmfeq_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfeq(vfloat32m2_t op0, float op1, size_t op2){
  return vmfeq_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfeq(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmfeq_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfeq(vfloat32m4_t op0, float op1, size_t op2){
  return vmfeq_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfeq(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmfeq_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfeq(vfloat32m8_t op0, float op1, size_t op2){
  return vmfeq_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfeq(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmfeq_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfeq(vfloat32mf2_t op0, float op1, size_t op2){
  return vmfeq_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfeq(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmfeq_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfne(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vmfne_vv_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfne(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vmfne_vv_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfne(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vmfne_vv_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfne(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vmfne_vv_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfne(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vmfne_vv_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfne(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vmfne_vv_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfne(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vmfne_vv_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfne(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vmfne_vv_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfne(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vmfne_vv_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfne(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vmfne_vv_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfne(vfloat32m1_t op0, float op1, size_t op2){
  return vmfne_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfne(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmfne_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfne(vfloat32m2_t op0, float op1, size_t op2){
  return vmfne_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfne(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmfne_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfne(vfloat32m4_t op0, float op1, size_t op2){
  return vmfne_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfne(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmfne_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfne(vfloat32m8_t op0, float op1, size_t op2){
  return vmfne_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfne(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmfne_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfne(vfloat32mf2_t op0, float op1, size_t op2){
  return vmfne_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfne(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmfne_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmflt(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vmflt_vv_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmflt(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vmflt_vv_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmflt(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vmflt_vv_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmflt(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vmflt_vv_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmflt(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vmflt_vv_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmflt(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vmflt_vv_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmflt(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vmflt_vv_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmflt(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vmflt_vv_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmflt(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vmflt_vv_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmflt(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vmflt_vv_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmflt(vfloat32m1_t op0, float op1, size_t op2){
  return vmflt_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmflt(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmflt_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmflt(vfloat32m2_t op0, float op1, size_t op2){
  return vmflt_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmflt(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmflt_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmflt(vfloat32m4_t op0, float op1, size_t op2){
  return vmflt_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmflt(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmflt_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmflt(vfloat32m8_t op0, float op1, size_t op2){
  return vmflt_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmflt(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmflt_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmflt(vfloat32mf2_t op0, float op1, size_t op2){
  return vmflt_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmflt(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmflt_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfle(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vmfle_vv_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfle(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vmfle_vv_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfle(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vmfle_vv_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfle(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vmfle_vv_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfle(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vmfle_vv_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfle(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vmfle_vv_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfle(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2){
  return vmfle_vv_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfle(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, vfloat32m8_t op3, size_t op4){
  return vmfle_vv_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfle(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vmfle_vv_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfle(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vmfle_vv_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfle(vfloat32m1_t op0, float op1, size_t op2){
  return vmfle_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfle(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmfle_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfle(vfloat32m2_t op0, float op1, size_t op2){
  return vmfle_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfle(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmfle_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfle(vfloat32m4_t op0, float op1, size_t op2){
  return vmfle_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfle(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmfle_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfle(vfloat32m8_t op0, float op1, size_t op2){
  return vmfle_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfle(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmfle_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfle(vfloat32mf2_t op0, float op1, size_t op2){
  return vmfle_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfle(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmfle_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfgt(vfloat32m1_t op0, float op1, size_t op2){
  return vmfgt_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfgt(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmfgt_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfgt(vfloat32m2_t op0, float op1, size_t op2){
  return vmfgt_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfgt(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmfgt_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfgt(vfloat32m4_t op0, float op1, size_t op2){
  return vmfgt_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfgt(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmfgt_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfgt(vfloat32m8_t op0, float op1, size_t op2){
  return vmfgt_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfgt(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmfgt_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfgt(vfloat32mf2_t op0, float op1, size_t op2){
  return vmfgt_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfgt(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmfgt_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfge(vfloat32m1_t op0, float op1, size_t op2){
  return vmfge_vf_f32m1_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfge(vbool32_t op0, vbool32_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vmfge_vf_f32m1_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfge(vfloat32m2_t op0, float op1, size_t op2){
  return vmfge_vf_f32m2_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfge(vbool16_t op0, vbool16_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vmfge_vf_f32m2_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfge(vfloat32m4_t op0, float op1, size_t op2){
  return vmfge_vf_f32m4_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfge(vbool8_t op0, vbool8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vmfge_vf_f32m4_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool4_t vmfge(vfloat32m8_t op0, float op1, size_t op2){
  return vmfge_vf_f32m8_b4(op0, op1, op2);
}

__rvv_overloaded vbool4_t vmfge(vbool4_t op0, vbool4_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vmfge_vf_f32m8_b4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfge(vfloat32mf2_t op0, float op1, size_t op2){
  return vmfge_vf_f32mf2_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfge(vbool64_t op0, vbool64_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vmfge_vf_f32mf2_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vmerge(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vmerge_vvm_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vmerge(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vmerge_vvm_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vmerge(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vmerge_vvm_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vmerge(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vmerge_vvm_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vmerge(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vmerge_vvm_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfmerge(vbool32_t op0, vfloat32m1_t op1, float op2, size_t op3){
  return vfmerge_vfm_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfmerge(vbool16_t op0, vfloat32m2_t op1, float op2, size_t op3){
  return vfmerge_vfm_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfmerge(vbool8_t op0, vfloat32m4_t op1, float op2, size_t op3){
  return vfmerge_vfm_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfmerge(vbool4_t op0, vfloat32m8_t op1, float op2, size_t op3){
  return vfmerge_vfm_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfmerge(vbool64_t op0, vfloat32mf2_t op1, float op2, size_t op3){
  return vfmerge_vfm_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmax_vs_f32m1_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmax_vs_f32m1_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmax(vfloat32m1_t op0, vfloat32m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmax_vs_f32m2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vbool16_t op0, vfloat32m1_t op1, vfloat32m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmax_vs_f32m2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmax(vfloat32m1_t op0, vfloat32m4_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmax_vs_f32m4_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vbool8_t op0, vfloat32m1_t op1, vfloat32m4_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmax_vs_f32m4_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmax(vfloat32m1_t op0, vfloat32m8_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmax_vs_f32m8_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vbool4_t op0, vfloat32m1_t op1, vfloat32m8_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmax_vs_f32m8_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmax(vfloat32m1_t op0, vfloat32mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmax_vs_f32mf2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmax(vbool64_t op0, vfloat32m1_t op1, vfloat32mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmax_vs_f32mf2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmin(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmin_vs_f32m1_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmin(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmin_vs_f32m1_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmin(vfloat32m1_t op0, vfloat32m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmin_vs_f32m2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmin(vbool16_t op0, vfloat32m1_t op1, vfloat32m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmin_vs_f32m2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmin(vfloat32m1_t op0, vfloat32m4_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmin_vs_f32m4_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmin(vbool8_t op0, vfloat32m1_t op1, vfloat32m4_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmin_vs_f32m4_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmin(vfloat32m1_t op0, vfloat32m8_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmin_vs_f32m8_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmin(vbool4_t op0, vfloat32m1_t op1, vfloat32m8_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmin_vs_f32m8_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredmin(vfloat32m1_t op0, vfloat32mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredmin_vs_f32mf2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredmin(vbool64_t op0, vfloat32m1_t op1, vfloat32mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredmin_vs_f32mf2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredsum(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfredsum_vs_f32m1_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredsum(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfredsum_vs_f32m1_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredsum(vfloat32m1_t op0, vfloat32m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredsum_vs_f32m2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredsum(vbool16_t op0, vfloat32m1_t op1, vfloat32m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredsum_vs_f32m2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredsum(vfloat32m1_t op0, vfloat32m4_t op1, vfloat32m1_t op2, size_t op3){
  return vfredsum_vs_f32m4_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredsum(vbool8_t op0, vfloat32m1_t op1, vfloat32m4_t op2, vfloat32m1_t op3, size_t op4){
  return vfredsum_vs_f32m4_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredsum(vfloat32m1_t op0, vfloat32m8_t op1, vfloat32m1_t op2, size_t op3){
  return vfredsum_vs_f32m8_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredsum(vbool4_t op0, vfloat32m1_t op1, vfloat32m8_t op2, vfloat32m1_t op3, size_t op4){
  return vfredsum_vs_f32m8_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredsum(vfloat32m1_t op0, vfloat32mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredsum_vs_f32mf2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredsum(vbool64_t op0, vfloat32m1_t op1, vfloat32mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredsum_vs_f32mf2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredosum(vfloat32m1_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfredosum_vs_f32m1_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredosum(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfredosum_vs_f32m1_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredosum(vfloat32m1_t op0, vfloat32m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredosum_vs_f32m2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredosum(vbool16_t op0, vfloat32m1_t op1, vfloat32m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredosum_vs_f32m2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredosum(vfloat32m1_t op0, vfloat32m4_t op1, vfloat32m1_t op2, size_t op3){
  return vfredosum_vs_f32m4_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredosum(vbool8_t op0, vfloat32m1_t op1, vfloat32m4_t op2, vfloat32m1_t op3, size_t op4){
  return vfredosum_vs_f32m4_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredosum(vfloat32m1_t op0, vfloat32m8_t op1, vfloat32m1_t op2, size_t op3){
  return vfredosum_vs_f32m8_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredosum(vbool4_t op0, vfloat32m1_t op1, vfloat32m8_t op2, vfloat32m1_t op3, size_t op4){
  return vfredosum_vs_f32m8_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfredosum(vfloat32m1_t op0, vfloat32mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfredosum_vs_f32mf2_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfredosum(vbool64_t op0, vfloat32m1_t op1, vfloat32mf2_t op2, vfloat32m1_t op3, size_t op4){
  return vfredosum_vs_f32mf2_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vslideup(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vslideup(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vslideup(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vslideup(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vslideup(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vslideup(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vslideup(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vslideup(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vslideup(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2, size_t op3){
  return vslideup_vx_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vslideup(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3, size_t op4){
  return vslideup_vx_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vslidedown(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vslidedown(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vslidedown(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vslidedown(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vslidedown(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vslidedown(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vslidedown(vfloat32m8_t op0, vfloat32m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vslidedown(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vslidedown(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vslidedown(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfslide1up(vfloat32m1_t op0, float op1, size_t op2){
  return vfslide1up_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfslide1up(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfslide1up_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfslide1up(vfloat32m2_t op0, float op1, size_t op2){
  return vfslide1up_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfslide1up(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfslide1up_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfslide1up(vfloat32m4_t op0, float op1, size_t op2){
  return vfslide1up_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfslide1up(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfslide1up_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfslide1up(vfloat32m8_t op0, float op1, size_t op2){
  return vfslide1up_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfslide1up(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfslide1up_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfslide1up(vfloat32mf2_t op0, float op1, size_t op2){
  return vfslide1up_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfslide1up(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfslide1up_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vfslide1down(vfloat32m1_t op0, float op1, size_t op2){
  return vfslide1down_vf_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vfslide1down(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfslide1down_vf_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vfslide1down(vfloat32m2_t op0, float op1, size_t op2){
  return vfslide1down_vf_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vfslide1down(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfslide1down_vf_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vfslide1down(vfloat32m4_t op0, float op1, size_t op2){
  return vfslide1down_vf_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vfslide1down(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfslide1down_vf_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vfslide1down(vfloat32m8_t op0, float op1, size_t op2){
  return vfslide1down_vf_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vfslide1down(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, float op3, size_t op4){
  return vfslide1down_vf_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfslide1down(vfloat32mf2_t op0, float op1, size_t op2){
  return vfslide1down_vf_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vfslide1down(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfslide1down_vf_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vrgather(vfloat32m1_t op0, vuint32m1_t op1, size_t op2){
  return vrgather_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vrgather(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vuint32m1_t op3, size_t op4){
  return vrgather_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vrgather(vfloat32m2_t op0, vuint32m2_t op1, size_t op2){
  return vrgather_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vrgather(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vuint32m2_t op3, size_t op4){
  return vrgather_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vrgather(vfloat32m4_t op0, vuint32m4_t op1, size_t op2){
  return vrgather_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vrgather(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vuint32m4_t op3, size_t op4){
  return vrgather_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vrgather(vfloat32m8_t op0, vuint32m8_t op1, size_t op2){
  return vrgather_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vrgather(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vuint32m8_t op3, size_t op4){
  return vrgather_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vrgather(vfloat32mf2_t op0, vuint32mf2_t op1, size_t op2){
  return vrgather_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vrgather(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vuint32mf2_t op3, size_t op4){
  return vrgather_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vrgather(vfloat32m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vrgather(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vrgather(vfloat32m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vrgather(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vrgather(vfloat32m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vrgather(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vrgather(vfloat32m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vrgather(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vrgather(vfloat32mf2_t op0, size_t op1, size_t op2){
  return vrgather_vx_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vrgather(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3, size_t op4){
  return vrgather_vx_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vrgatherei16(vfloat32m1_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vrgatherei16(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vrgatherei16(vfloat32m2_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vrgatherei16(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vrgatherei16(vfloat32m4_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vrgatherei16(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vrgatherei16(vfloat32m8_t op0, vuint16m4_t op1, size_t op2){
  return vrgatherei16_vv_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vrgatherei16(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, vuint16m4_t op3, size_t op4){
  return vrgatherei16_vv_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vrgatherei16(vfloat32mf2_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vrgatherei16(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vcompress(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vcompress_vm_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vcompress(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vcompress_vm_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vcompress(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vcompress_vm_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vcompress(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vcompress_vm_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vcompress(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vcompress_vm_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(float * op0, ptrdiff_t op1, vfloat32m1_t op2, size_t op3){
  return vsse32_v_f32m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool32_t op0, float * op1, ptrdiff_t op2, vfloat32m1_t op3, size_t op4){
  return vsse32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(float * op0, ptrdiff_t op1, vfloat32m2_t op2, size_t op3){
  return vsse32_v_f32m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool16_t op0, float * op1, ptrdiff_t op2, vfloat32m2_t op3, size_t op4){
  return vsse32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(float * op0, ptrdiff_t op1, vfloat32m4_t op2, size_t op3){
  return vsse32_v_f32m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool8_t op0, float * op1, ptrdiff_t op2, vfloat32m4_t op3, size_t op4){
  return vsse32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(float * op0, ptrdiff_t op1, vfloat32m8_t op2, size_t op3){
  return vsse32_v_f32m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool4_t op0, float * op1, ptrdiff_t op2, vfloat32m8_t op3, size_t op4){
  return vsse32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse32(float * op0, ptrdiff_t op1, vfloat32mf2_t op2, size_t op3){
  return vsse32_v_f32mf2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse32(vbool64_t op0, float * op1, ptrdiff_t op2, vfloat32mf2_t op3, size_t op4){
  return vsse32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei8(const float * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei8(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei8(const float * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei8(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei8(const float * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei8(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei8(const float * op0, vuint8m2_t op1, size_t op2){
  return vluxei8_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei8(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint8m2_t op3, size_t op4){
  return vluxei8_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei8(const float * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei8(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei16(const float * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei16(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei16(const float * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei16(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei16(const float * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei16(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei16(const float * op0, vuint16m4_t op1, size_t op2){
  return vluxei16_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei16(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint16m4_t op3, size_t op4){
  return vluxei16_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei16(const float * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei16(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei32(const float * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei32(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei32(const float * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei32(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei32(const float * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei32(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m8_t vluxei32(const float * op0, vuint32m8_t op1, size_t op2){
  return vluxei32_v_f32m8(op0, op1, op2);
}

__rvv_overloaded vfloat32m8_t vluxei32(vbool4_t op0, vfloat32m8_t op1, const float * op2, vuint32m8_t op3, size_t op4){
  return vluxei32_v_f32m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei32(const float * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei32(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m1_t vluxei64(const float * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_f32m1(op0, op1, op2);
}

__rvv_overloaded vfloat32m1_t vluxei64(vbool32_t op0, vfloat32m1_t op1, const float * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_f32m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m2_t vluxei64(const float * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_f32m2(op0, op1, op2);
}

__rvv_overloaded vfloat32m2_t vluxei64(vbool16_t op0, vfloat32m2_t op1, const float * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_f32m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32m4_t vluxei64(const float * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_f32m4(op0, op1, op2);
}

__rvv_overloaded vfloat32m4_t vluxei64(vbool8_t op0, vfloat32m4_t op1, const float * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_f32m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vluxei64(const float * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_f32mf2(op0, op1, op2);
}

__rvv_overloaded vfloat32mf2_t vluxei64(vbool64_t op0, vfloat32mf2_t op1, const float * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_f32mf2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint32m1_t vfclass(vfloat32m1_t op0, size_t op1){
  return vfclass_v_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vfclass(vbool32_t op0, vuint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfclass_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vfclass(vfloat32m2_t op0, size_t op1){
  return vfclass_v_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vfclass(vbool16_t op0, vuint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfclass_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vfclass(vfloat32m4_t op0, size_t op1){
  return vfclass_v_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vfclass(vbool8_t op0, vuint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfclass_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vfclass(vfloat32m8_t op0, size_t op1){
  return vfclass_v_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vfclass(vbool4_t op0, vuint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfclass_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vfclass(vfloat32mf2_t op0, size_t op1){
  return vfclass_v_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vfclass(vbool64_t op0, vuint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfclass_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfcvt_f(vint32m1_t op0, size_t op1){
  return vfcvt_f_x_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfcvt_f(vbool32_t op0, vfloat32m1_t op1, vint32m1_t op2, size_t op3){
  return vfcvt_f_x_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfcvt_f(vint32m2_t op0, size_t op1){
  return vfcvt_f_x_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfcvt_f(vbool16_t op0, vfloat32m2_t op1, vint32m2_t op2, size_t op3){
  return vfcvt_f_x_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfcvt_f(vint32m4_t op0, size_t op1){
  return vfcvt_f_x_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfcvt_f(vbool8_t op0, vfloat32m4_t op1, vint32m4_t op2, size_t op3){
  return vfcvt_f_x_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfcvt_f(vint32m8_t op0, size_t op1){
  return vfcvt_f_x_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfcvt_f(vbool4_t op0, vfloat32m8_t op1, vint32m8_t op2, size_t op3){
  return vfcvt_f_x_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfcvt_f(vint32mf2_t op0, size_t op1){
  return vfcvt_f_x_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfcvt_f(vbool64_t op0, vfloat32mf2_t op1, vint32mf2_t op2, size_t op3){
  return vfcvt_f_x_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfcvt_f(vuint32m1_t op0, size_t op1){
  return vfcvt_f_xu_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfcvt_f(vbool32_t op0, vfloat32m1_t op1, vuint32m1_t op2, size_t op3){
  return vfcvt_f_xu_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfcvt_f(vuint32m2_t op0, size_t op1){
  return vfcvt_f_xu_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfcvt_f(vbool16_t op0, vfloat32m2_t op1, vuint32m2_t op2, size_t op3){
  return vfcvt_f_xu_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfcvt_f(vuint32m4_t op0, size_t op1){
  return vfcvt_f_xu_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfcvt_f(vbool8_t op0, vfloat32m4_t op1, vuint32m4_t op2, size_t op3){
  return vfcvt_f_xu_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfcvt_f(vuint32m8_t op0, size_t op1){
  return vfcvt_f_xu_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfcvt_f(vbool4_t op0, vfloat32m8_t op1, vuint32m8_t op2, size_t op3){
  return vfcvt_f_xu_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfcvt_f(vuint32mf2_t op0, size_t op1){
  return vfcvt_f_xu_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfcvt_f(vbool64_t op0, vfloat32mf2_t op1, vuint32mf2_t op2, size_t op3){
  return vfcvt_f_xu_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vfcvt_rtz_x(vfloat32m1_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vfcvt_rtz_x(vbool32_t op0, vint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vfcvt_rtz_x(vfloat32m2_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vfcvt_rtz_x(vbool16_t op0, vint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vfcvt_rtz_x(vfloat32m4_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vfcvt_rtz_x(vbool8_t op0, vint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vfcvt_rtz_x(vfloat32m8_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vfcvt_rtz_x(vbool4_t op0, vint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vfcvt_rtz_x(vfloat32mf2_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vfcvt_rtz_x(vbool64_t op0, vint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vfcvt_rtz_xu(vfloat32m1_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vfcvt_rtz_xu(vbool32_t op0, vuint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vfcvt_rtz_xu(vfloat32m2_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vfcvt_rtz_xu(vbool16_t op0, vuint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vfcvt_rtz_xu(vfloat32m4_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vfcvt_rtz_xu(vbool8_t op0, vuint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vfcvt_rtz_xu(vfloat32m8_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vfcvt_rtz_xu(vbool4_t op0, vuint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vfcvt_rtz_xu(vfloat32mf2_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vfcvt_rtz_xu(vbool64_t op0, vuint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vfcvt_x(vfloat32m1_t op0, size_t op1){
  return vfcvt_x_f_v_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vfcvt_x(vbool32_t op0, vint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfcvt_x_f_v_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vfcvt_x(vfloat32m2_t op0, size_t op1){
  return vfcvt_x_f_v_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vfcvt_x(vbool16_t op0, vint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfcvt_x_f_v_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vfcvt_x(vfloat32m4_t op0, size_t op1){
  return vfcvt_x_f_v_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vfcvt_x(vbool8_t op0, vint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfcvt_x_f_v_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m8_t vfcvt_x(vfloat32m8_t op0, size_t op1){
  return vfcvt_x_f_v_i32m8(op0, op1);
}

__rvv_overloaded vint32m8_t vfcvt_x(vbool4_t op0, vint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfcvt_x_f_v_i32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vfcvt_x(vfloat32mf2_t op0, size_t op1){
  return vfcvt_x_f_v_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vfcvt_x(vbool64_t op0, vint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfcvt_x_f_v_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vfcvt_xu(vfloat32m1_t op0, size_t op1){
  return vfcvt_xu_f_v_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vfcvt_xu(vbool32_t op0, vuint32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfcvt_xu_f_v_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vfcvt_xu(vfloat32m2_t op0, size_t op1){
  return vfcvt_xu_f_v_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vfcvt_xu(vbool16_t op0, vuint32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfcvt_xu_f_v_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vfcvt_xu(vfloat32m4_t op0, size_t op1){
  return vfcvt_xu_f_v_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vfcvt_xu(vbool8_t op0, vuint32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfcvt_xu_f_v_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m8_t vfcvt_xu(vfloat32m8_t op0, size_t op1){
  return vfcvt_xu_f_v_u32m8(op0, op1);
}

__rvv_overloaded vuint32m8_t vfcvt_xu(vbool4_t op0, vuint32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfcvt_xu_f_v_u32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vfcvt_xu(vfloat32mf2_t op0, size_t op1){
  return vfcvt_xu_f_v_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vfcvt_xu(vbool64_t op0, vuint32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfcvt_xu_f_v_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vint64m1_t op0, size_t op1){
  return vfncvt_f_x_w_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vbool64_t op0, vfloat32mf2_t op1, vint64m1_t op2, size_t op3){
  return vfncvt_f_x_w_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vint64m2_t op0, size_t op1){
  return vfncvt_f_x_w_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vbool32_t op0, vfloat32m1_t op1, vint64m2_t op2, size_t op3){
  return vfncvt_f_x_w_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vint64m4_t op0, size_t op1){
  return vfncvt_f_x_w_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vbool16_t op0, vfloat32m2_t op1, vint64m4_t op2, size_t op3){
  return vfncvt_f_x_w_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vint64m8_t op0, size_t op1){
  return vfncvt_f_x_w_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vbool8_t op0, vfloat32m4_t op1, vint64m8_t op2, size_t op3){
  return vfncvt_f_x_w_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vuint64m1_t op0, size_t op1){
  return vfncvt_f_xu_w_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vbool64_t op0, vfloat32mf2_t op1, vuint64m1_t op2, size_t op3){
  return vfncvt_f_xu_w_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vuint64m2_t op0, size_t op1){
  return vfncvt_f_xu_w_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vbool32_t op0, vfloat32m1_t op1, vuint64m2_t op2, size_t op3){
  return vfncvt_f_xu_w_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vuint64m4_t op0, size_t op1){
  return vfncvt_f_xu_w_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vbool16_t op0, vfloat32m2_t op1, vuint64m4_t op2, size_t op3){
  return vfncvt_f_xu_w_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vuint64m8_t op0, size_t op1){
  return vfncvt_f_xu_w_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vbool8_t op0, vfloat32m4_t op1, vuint64m8_t op2, size_t op3){
  return vfncvt_f_xu_w_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vfncvt_rtz_x(vfloat32mf2_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i16mf4(op0, op1);
}

__rvv_overloaded vint16mf4_t vfncvt_rtz_x(vbool64_t op0, vint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vfncvt_rtz_x(vfloat32m1_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i16mf2(op0, op1);
}

__rvv_overloaded vint16mf2_t vfncvt_rtz_x(vbool32_t op0, vint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vfncvt_rtz_x(vfloat32m2_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i16m1(op0, op1);
}

__rvv_overloaded vint16m1_t vfncvt_rtz_x(vbool16_t op0, vint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vfncvt_rtz_x(vfloat32m4_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i16m2(op0, op1);
}

__rvv_overloaded vint16m2_t vfncvt_rtz_x(vbool8_t op0, vint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vfncvt_rtz_x(vfloat32m8_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i16m4(op0, op1);
}

__rvv_overloaded vint16m4_t vfncvt_rtz_x(vbool4_t op0, vint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vfncvt_rtz_xu(vfloat32mf2_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u16mf4(op0, op1);
}

__rvv_overloaded vuint16mf4_t vfncvt_rtz_xu(vbool64_t op0, vuint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vfncvt_rtz_xu(vfloat32m1_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u16mf2(op0, op1);
}

__rvv_overloaded vuint16mf2_t vfncvt_rtz_xu(vbool32_t op0, vuint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vfncvt_rtz_xu(vfloat32m2_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u16m1(op0, op1);
}

__rvv_overloaded vuint16m1_t vfncvt_rtz_xu(vbool16_t op0, vuint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vfncvt_rtz_xu(vfloat32m4_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u16m2(op0, op1);
}

__rvv_overloaded vuint16m2_t vfncvt_rtz_xu(vbool8_t op0, vuint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vfncvt_rtz_xu(vfloat32m8_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u16m4(op0, op1);
}

__rvv_overloaded vuint16m4_t vfncvt_rtz_xu(vbool4_t op0, vuint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf4_t vfncvt_x(vfloat32mf2_t op0, size_t op1){
  return vfncvt_x_f_w_i16mf4(op0, op1);
}

__rvv_overloaded vint16mf4_t vfncvt_x(vbool64_t op0, vint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vfncvt_x_f_w_i16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16mf2_t vfncvt_x(vfloat32m1_t op0, size_t op1){
  return vfncvt_x_f_w_i16mf2(op0, op1);
}

__rvv_overloaded vint16mf2_t vfncvt_x(vbool32_t op0, vint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfncvt_x_f_w_i16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m1_t vfncvt_x(vfloat32m2_t op0, size_t op1){
  return vfncvt_x_f_w_i16m1(op0, op1);
}

__rvv_overloaded vint16m1_t vfncvt_x(vbool16_t op0, vint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vfncvt_x_f_w_i16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m2_t vfncvt_x(vfloat32m4_t op0, size_t op1){
  return vfncvt_x_f_w_i16m2(op0, op1);
}

__rvv_overloaded vint16m2_t vfncvt_x(vbool8_t op0, vint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vfncvt_x_f_w_i16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint16m4_t vfncvt_x(vfloat32m8_t op0, size_t op1){
  return vfncvt_x_f_w_i16m4(op0, op1);
}

__rvv_overloaded vint16m4_t vfncvt_x(vbool4_t op0, vint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vfncvt_x_f_w_i16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf4_t vfncvt_xu(vfloat32mf2_t op0, size_t op1){
  return vfncvt_xu_f_w_u16mf4(op0, op1);
}

__rvv_overloaded vuint16mf4_t vfncvt_xu(vbool64_t op0, vuint16mf4_t op1, vfloat32mf2_t op2, size_t op3){
  return vfncvt_xu_f_w_u16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16mf2_t vfncvt_xu(vfloat32m1_t op0, size_t op1){
  return vfncvt_xu_f_w_u16mf2(op0, op1);
}

__rvv_overloaded vuint16mf2_t vfncvt_xu(vbool32_t op0, vuint16mf2_t op1, vfloat32m1_t op2, size_t op3){
  return vfncvt_xu_f_w_u16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m1_t vfncvt_xu(vfloat32m2_t op0, size_t op1){
  return vfncvt_xu_f_w_u16m1(op0, op1);
}

__rvv_overloaded vuint16m1_t vfncvt_xu(vbool16_t op0, vuint16m1_t op1, vfloat32m2_t op2, size_t op3){
  return vfncvt_xu_f_w_u16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m2_t vfncvt_xu(vfloat32m4_t op0, size_t op1){
  return vfncvt_xu_f_w_u16m2(op0, op1);
}

__rvv_overloaded vuint16m2_t vfncvt_xu(vbool8_t op0, vuint16m2_t op1, vfloat32m4_t op2, size_t op3){
  return vfncvt_xu_f_w_u16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint16m4_t vfncvt_xu(vfloat32m8_t op0, size_t op1){
  return vfncvt_xu_f_w_u16m4(op0, op1);
}

__rvv_overloaded vuint16m4_t vfncvt_xu(vbool4_t op0, vuint16m4_t op1, vfloat32m8_t op2, size_t op3){
  return vfncvt_xu_f_w_u16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfrec7(vfloat32m1_t op0, size_t op1){
  return vfrec7_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfrec7(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfrec7_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfrec7(vfloat32m2_t op0, size_t op1){
  return vfrec7_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfrec7(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfrec7_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfrec7(vfloat32m4_t op0, size_t op1){
  return vfrec7_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfrec7(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfrec7_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfrec7(vfloat32m8_t op0, size_t op1){
  return vfrec7_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfrec7(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfrec7_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfrec7(vfloat32mf2_t op0, size_t op1){
  return vfrec7_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfrec7(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfrec7_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfrsqrt7(vfloat32m1_t op0, size_t op1){
  return vfrsqrt7_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfrsqrt7(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfrsqrt7_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfrsqrt7(vfloat32m2_t op0, size_t op1){
  return vfrsqrt7_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfrsqrt7(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfrsqrt7_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfrsqrt7(vfloat32m4_t op0, size_t op1){
  return vfrsqrt7_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfrsqrt7(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfrsqrt7_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfrsqrt7(vfloat32m8_t op0, size_t op1){
  return vfrsqrt7_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfrsqrt7(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfrsqrt7_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfrsqrt7(vfloat32mf2_t op0, size_t op1){
  return vfrsqrt7_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfrsqrt7(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfrsqrt7_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfsqrt(vfloat32m1_t op0, size_t op1){
  return vfsqrt_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfsqrt(vbool32_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfsqrt_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfsqrt(vfloat32m2_t op0, size_t op1){
  return vfsqrt_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfsqrt(vbool16_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfsqrt_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfsqrt(vfloat32m4_t op0, size_t op1){
  return vfsqrt_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfsqrt(vbool8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfsqrt_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfsqrt(vfloat32m8_t op0, size_t op1){
  return vfsqrt_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfsqrt(vbool4_t op0, vfloat32m8_t op1, vfloat32m8_t op2, size_t op3){
  return vfsqrt_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfsqrt(vfloat32mf2_t op0, size_t op1){
  return vfsqrt_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfsqrt(vbool64_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfsqrt_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfwcvt_f(vint16mf4_t op0, size_t op1){
  return vfwcvt_f_x_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfwcvt_f(vbool64_t op0, vfloat32mf2_t op1, vint16mf4_t op2, size_t op3){
  return vfwcvt_f_x_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vint16mf2_t op0, size_t op1){
  return vfwcvt_f_x_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vbool32_t op0, vfloat32m1_t op1, vint16mf2_t op2, size_t op3){
  return vfwcvt_f_x_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vint16m1_t op0, size_t op1){
  return vfwcvt_f_x_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vbool16_t op0, vfloat32m2_t op1, vint16m1_t op2, size_t op3){
  return vfwcvt_f_x_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vint16m2_t op0, size_t op1){
  return vfwcvt_f_x_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vbool8_t op0, vfloat32m4_t op1, vint16m2_t op2, size_t op3){
  return vfwcvt_f_x_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vint16m4_t op0, size_t op1){
  return vfwcvt_f_x_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vbool4_t op0, vfloat32m8_t op1, vint16m4_t op2, size_t op3){
  return vfwcvt_f_x_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfwcvt_f(vuint16mf4_t op0, size_t op1){
  return vfwcvt_f_xu_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfwcvt_f(vbool64_t op0, vfloat32mf2_t op1, vuint16mf4_t op2, size_t op3){
  return vfwcvt_f_xu_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vuint16mf2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vbool32_t op0, vfloat32m1_t op1, vuint16mf2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vuint16m1_t op0, size_t op1){
  return vfwcvt_f_xu_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vbool16_t op0, vfloat32m2_t op1, vuint16m1_t op2, size_t op3){
  return vfwcvt_f_xu_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vuint16m2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vbool8_t op0, vfloat32m4_t op1, vuint16m2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vuint16m4_t op0, size_t op1){
  return vfwcvt_f_xu_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vbool4_t op0, vfloat32m8_t op1, vuint16m4_t op2, size_t op3){
  return vfwcvt_f_xu_v_f32m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vfwcvt_rtz_x(vfloat32mf2_t op0, size_t op1){
  return vfwcvt_rtz_x_f_v_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vfwcvt_rtz_x(vbool64_t op0, vint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwcvt_rtz_x_f_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vfwcvt_rtz_x(vfloat32m1_t op0, size_t op1){
  return vfwcvt_rtz_x_f_v_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vfwcvt_rtz_x(vbool32_t op0, vint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfwcvt_rtz_x_f_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vfwcvt_rtz_x(vfloat32m2_t op0, size_t op1){
  return vfwcvt_rtz_x_f_v_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vfwcvt_rtz_x(vbool16_t op0, vint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vfwcvt_rtz_x_f_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vfwcvt_rtz_x(vfloat32m4_t op0, size_t op1){
  return vfwcvt_rtz_x_f_v_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vfwcvt_rtz_x(vbool8_t op0, vint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vfwcvt_rtz_x_f_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vfwcvt_rtz_xu(vfloat32mf2_t op0, size_t op1){
  return vfwcvt_rtz_xu_f_v_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vfwcvt_rtz_xu(vbool64_t op0, vuint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwcvt_rtz_xu_f_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vfwcvt_rtz_xu(vfloat32m1_t op0, size_t op1){
  return vfwcvt_rtz_xu_f_v_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vfwcvt_rtz_xu(vbool32_t op0, vuint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfwcvt_rtz_xu_f_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vfwcvt_rtz_xu(vfloat32m2_t op0, size_t op1){
  return vfwcvt_rtz_xu_f_v_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vfwcvt_rtz_xu(vbool16_t op0, vuint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vfwcvt_rtz_xu_f_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vfwcvt_rtz_xu(vfloat32m4_t op0, size_t op1){
  return vfwcvt_rtz_xu_f_v_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vfwcvt_rtz_xu(vbool8_t op0, vuint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vfwcvt_rtz_xu_f_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vfwcvt_x(vfloat32mf2_t op0, size_t op1){
  return vfwcvt_x_f_v_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vfwcvt_x(vbool64_t op0, vint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwcvt_x_f_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vfwcvt_x(vfloat32m1_t op0, size_t op1){
  return vfwcvt_x_f_v_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vfwcvt_x(vbool32_t op0, vint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfwcvt_x_f_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vfwcvt_x(vfloat32m2_t op0, size_t op1){
  return vfwcvt_x_f_v_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vfwcvt_x(vbool16_t op0, vint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vfwcvt_x_f_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vfwcvt_x(vfloat32m4_t op0, size_t op1){
  return vfwcvt_x_f_v_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vfwcvt_x(vbool8_t op0, vint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vfwcvt_x_f_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vfwcvt_xu(vfloat32mf2_t op0, size_t op1){
  return vfwcvt_xu_f_v_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vfwcvt_xu(vbool64_t op0, vuint64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwcvt_xu_f_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vfwcvt_xu(vfloat32m1_t op0, size_t op1){
  return vfwcvt_xu_f_v_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vfwcvt_xu(vbool32_t op0, vuint64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfwcvt_xu_f_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vfwcvt_xu(vfloat32m2_t op0, size_t op1){
  return vfwcvt_xu_f_v_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vfwcvt_xu(vbool16_t op0, vuint64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vfwcvt_xu_f_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vfwcvt_xu(vfloat32m4_t op0, size_t op1){
  return vfwcvt_xu_f_v_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vfwcvt_xu(vbool8_t op0, vuint64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vfwcvt_xu_f_v_u64m8_m(op0, op1, op2, op3);
}

#endif

#if defined(__riscv_d)
__rvv_overloaded vfloat64m1_t vloxei8(const double * op0, vuint8mf8_t op1, size_t op2){
  return vloxei8_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei8(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint8mf8_t op3, size_t op4){
  return vloxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei8(const double * op0, vuint8mf4_t op1, size_t op2){
  return vloxei8_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei8(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint8mf4_t op3, size_t op4){
  return vloxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei8(const double * op0, vuint8mf2_t op1, size_t op2){
  return vloxei8_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei8(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint8mf2_t op3, size_t op4){
  return vloxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei8(const double * op0, vuint8m1_t op1, size_t op2){
  return vloxei8_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei8(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint8m1_t op3, size_t op4){
  return vloxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei16(const double * op0, vuint16mf4_t op1, size_t op2){
  return vloxei16_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei16(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint16mf4_t op3, size_t op4){
  return vloxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei16(const double * op0, vuint16mf2_t op1, size_t op2){
  return vloxei16_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei16(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint16mf2_t op3, size_t op4){
  return vloxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei16(const double * op0, vuint16m1_t op1, size_t op2){
  return vloxei16_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei16(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint16m1_t op3, size_t op4){
  return vloxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei16(const double * op0, vuint16m2_t op1, size_t op2){
  return vloxei16_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei16(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint16m2_t op3, size_t op4){
  return vloxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei32(const double * op0, vuint32mf2_t op1, size_t op2){
  return vloxei32_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei32(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint32mf2_t op3, size_t op4){
  return vloxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei32(const double * op0, vuint32m1_t op1, size_t op2){
  return vloxei32_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei32(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint32m1_t op3, size_t op4){
  return vloxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei32(const double * op0, vuint32m2_t op1, size_t op2){
  return vloxei32_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei32(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint32m2_t op3, size_t op4){
  return vloxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei32(const double * op0, vuint32m4_t op1, size_t op2){
  return vloxei32_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei32(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint32m4_t op3, size_t op4){
  return vloxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vloxei64(const double * op0, vuint64m1_t op1, size_t op2){
  return vloxei64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vloxei64(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint64m1_t op3, size_t op4){
  return vloxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vloxei64(const double * op0, vuint64m2_t op1, size_t op2){
  return vloxei64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vloxei64(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint64m2_t op3, size_t op4){
  return vloxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vloxei64(const double * op0, vuint64m4_t op1, size_t op2){
  return vloxei64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vloxei64(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint64m4_t op3, size_t op4){
  return vloxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vloxei64(const double * op0, vuint64m8_t op1, size_t op2){
  return vloxei64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vloxei64(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint64m8_t op3, size_t op4){
  return vloxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(double * op0, vuint8mf8_t op1, vfloat64m1_t op2, size_t op3){
  return vsuxei8_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool64_t op0, double * op1, vuint8mf8_t op2, vfloat64m1_t op3, size_t op4){
  return vsuxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(double * op0, vuint8mf4_t op1, vfloat64m2_t op2, size_t op3){
  return vsuxei8_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool32_t op0, double * op1, vuint8mf4_t op2, vfloat64m2_t op3, size_t op4){
  return vsuxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(double * op0, vuint8mf2_t op1, vfloat64m4_t op2, size_t op3){
  return vsuxei8_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool16_t op0, double * op1, vuint8mf2_t op2, vfloat64m4_t op3, size_t op4){
  return vsuxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei8(double * op0, vuint8m1_t op1, vfloat64m8_t op2, size_t op3){
  return vsuxei8_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei8(vbool8_t op0, double * op1, vuint8m1_t op2, vfloat64m8_t op3, size_t op4){
  return vsuxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(double * op0, vuint16mf4_t op1, vfloat64m1_t op2, size_t op3){
  return vsuxei16_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool64_t op0, double * op1, vuint16mf4_t op2, vfloat64m1_t op3, size_t op4){
  return vsuxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(double * op0, vuint16mf2_t op1, vfloat64m2_t op2, size_t op3){
  return vsuxei16_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool32_t op0, double * op1, vuint16mf2_t op2, vfloat64m2_t op3, size_t op4){
  return vsuxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(double * op0, vuint16m1_t op1, vfloat64m4_t op2, size_t op3){
  return vsuxei16_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool16_t op0, double * op1, vuint16m1_t op2, vfloat64m4_t op3, size_t op4){
  return vsuxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei16(double * op0, vuint16m2_t op1, vfloat64m8_t op2, size_t op3){
  return vsuxei16_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei16(vbool8_t op0, double * op1, vuint16m2_t op2, vfloat64m8_t op3, size_t op4){
  return vsuxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(double * op0, vuint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vsuxei32_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool64_t op0, double * op1, vuint32mf2_t op2, vfloat64m1_t op3, size_t op4){
  return vsuxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(double * op0, vuint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vsuxei32_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool32_t op0, double * op1, vuint32m1_t op2, vfloat64m2_t op3, size_t op4){
  return vsuxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(double * op0, vuint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vsuxei32_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool16_t op0, double * op1, vuint32m2_t op2, vfloat64m4_t op3, size_t op4){
  return vsuxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei32(double * op0, vuint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vsuxei32_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei32(vbool8_t op0, double * op1, vuint32m4_t op2, vfloat64m8_t op3, size_t op4){
  return vsuxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(double * op0, vuint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vsuxei64_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool64_t op0, double * op1, vuint64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vsuxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(double * op0, vuint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vsuxei64_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool32_t op0, double * op1, vuint64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vsuxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(double * op0, vuint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vsuxei64_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool16_t op0, double * op1, vuint64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vsuxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsuxei64(double * op0, vuint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vsuxei64_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsuxei64(vbool8_t op0, double * op1, vuint64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vsuxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(double * op0, vuint8mf8_t op1, vfloat64m1_t op2, size_t op3){
  return vsoxei8_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool64_t op0, double * op1, vuint8mf8_t op2, vfloat64m1_t op3, size_t op4){
  return vsoxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(double * op0, vuint8mf4_t op1, vfloat64m2_t op2, size_t op3){
  return vsoxei8_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool32_t op0, double * op1, vuint8mf4_t op2, vfloat64m2_t op3, size_t op4){
  return vsoxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(double * op0, vuint8mf2_t op1, vfloat64m4_t op2, size_t op3){
  return vsoxei8_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool16_t op0, double * op1, vuint8mf2_t op2, vfloat64m4_t op3, size_t op4){
  return vsoxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei8(double * op0, vuint8m1_t op1, vfloat64m8_t op2, size_t op3){
  return vsoxei8_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei8(vbool8_t op0, double * op1, vuint8m1_t op2, vfloat64m8_t op3, size_t op4){
  return vsoxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(double * op0, vuint16mf4_t op1, vfloat64m1_t op2, size_t op3){
  return vsoxei16_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool64_t op0, double * op1, vuint16mf4_t op2, vfloat64m1_t op3, size_t op4){
  return vsoxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(double * op0, vuint16mf2_t op1, vfloat64m2_t op2, size_t op3){
  return vsoxei16_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool32_t op0, double * op1, vuint16mf2_t op2, vfloat64m2_t op3, size_t op4){
  return vsoxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(double * op0, vuint16m1_t op1, vfloat64m4_t op2, size_t op3){
  return vsoxei16_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool16_t op0, double * op1, vuint16m1_t op2, vfloat64m4_t op3, size_t op4){
  return vsoxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei16(double * op0, vuint16m2_t op1, vfloat64m8_t op2, size_t op3){
  return vsoxei16_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei16(vbool8_t op0, double * op1, vuint16m2_t op2, vfloat64m8_t op3, size_t op4){
  return vsoxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(double * op0, vuint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vsoxei32_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool64_t op0, double * op1, vuint32mf2_t op2, vfloat64m1_t op3, size_t op4){
  return vsoxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(double * op0, vuint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vsoxei32_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool32_t op0, double * op1, vuint32m1_t op2, vfloat64m2_t op3, size_t op4){
  return vsoxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(double * op0, vuint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vsoxei32_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool16_t op0, double * op1, vuint32m2_t op2, vfloat64m4_t op3, size_t op4){
  return vsoxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei32(double * op0, vuint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vsoxei32_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei32(vbool8_t op0, double * op1, vuint32m4_t op2, vfloat64m8_t op3, size_t op4){
  return vsoxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(double * op0, vuint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vsoxei64_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool64_t op0, double * op1, vuint64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vsoxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(double * op0, vuint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vsoxei64_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool32_t op0, double * op1, vuint64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vsoxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(double * op0, vuint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vsoxei64_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool16_t op0, double * op1, vuint64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vsoxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsoxei64(double * op0, vuint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vsoxei64_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsoxei64(vbool8_t op0, double * op1, vuint64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vsoxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vle64ff(vbool64_t op0, vfloat64m1_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vle64ff(vbool32_t op0, vfloat64m2_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vle64ff(vbool16_t op0, vfloat64m4_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vle64ff(vbool8_t op0, vfloat64m8_t op1, const double * op2, size_t * op3, size_t op4){
  return vle64ff_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vle64(vbool64_t op0, vfloat64m1_t op1, const double * op2, size_t op3){
  return vle64_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vle64(vbool32_t op0, vfloat64m2_t op1, const double * op2, size_t op3){
  return vle64_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vle64(vbool16_t op0, vfloat64m4_t op1, const double * op2, size_t op3){
  return vle64_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vle64(vbool8_t op0, vfloat64m8_t op1, const double * op2, size_t op3){
  return vle64_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m1_t op1, size_t op2){
  return vse64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool64_t op0, double * op1, vfloat64m1_t op2, size_t op3){
  return vse64_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m2_t op1, size_t op2){
  return vse64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool32_t op0, double * op1, vfloat64m2_t op2, size_t op3){
  return vse64_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m4_t op1, size_t op2){
  return vse64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool16_t op0, double * op1, vfloat64m4_t op2, size_t op3){
  return vse64_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded void vse64(double * op0, vfloat64m8_t op1, size_t op2){
  return vse64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded void vse64(vbool8_t op0, double * op1, vfloat64m8_t op2, size_t op3){
  return vse64_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfadd(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfadd_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfadd_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfadd(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfadd_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfadd_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfadd(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfadd_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfadd_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfadd(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfadd_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfadd_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfadd(vfloat64m1_t op0, double op1, size_t op2){
  return vfadd_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfadd_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfadd(vfloat64m2_t op0, double op1, size_t op2){
  return vfadd_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfadd_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfadd(vfloat64m4_t op0, double op1, size_t op2){
  return vfadd_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfadd_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfadd(vfloat64m8_t op0, double op1, size_t op2){
  return vfadd_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfadd_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsub(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfsub_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsub(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfsub_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsub(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfsub_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsub(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfsub_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsub(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfsub_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsub(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfsub_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsub(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfsub_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsub(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfsub_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsub(vfloat64m1_t op0, double op1, size_t op2){
  return vfsub_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsub(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfsub_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsub(vfloat64m2_t op0, double op1, size_t op2){
  return vfsub_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsub(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfsub_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsub(vfloat64m4_t op0, double op1, size_t op2){
  return vfsub_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsub(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfsub_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsub(vfloat64m8_t op0, double op1, size_t op2){
  return vfsub_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsub(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfsub_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfrsub(vfloat64m1_t op0, double op1, size_t op2){
  return vfrsub_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfrsub(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfrsub_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfrsub(vfloat64m2_t op0, double op1, size_t op2){
  return vfrsub_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfrsub(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfrsub_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfrsub(vfloat64m4_t op0, double op1, size_t op2){
  return vfrsub_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfrsub(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfrsub_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfrsub(vfloat64m8_t op0, double op1, size_t op2){
  return vfrsub_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfrsub(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfrsub_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwadd_wf(vfloat64m1_t op0, float op1, size_t op2){
  return vfwadd_wf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwadd_wf(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, float op3, size_t op4){
  return vfwadd_wf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwadd_wf(vfloat64m2_t op0, float op1, size_t op2){
  return vfwadd_wf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwadd_wf(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, float op3, size_t op4){
  return vfwadd_wf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwadd_wf(vfloat64m4_t op0, float op1, size_t op2){
  return vfwadd_wf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwadd_wf(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, float op3, size_t op4){
  return vfwadd_wf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwadd_wf(vfloat64m8_t op0, float op1, size_t op2){
  return vfwadd_wf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwadd_wf(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, float op3, size_t op4){
  return vfwadd_wf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwsub_wf(vfloat64m1_t op0, float op1, size_t op2){
  return vfwsub_wf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwsub_wf(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, float op3, size_t op4){
  return vfwsub_wf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwsub_wf(vfloat64m2_t op0, float op1, size_t op2){
  return vfwsub_wf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwsub_wf(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, float op3, size_t op4){
  return vfwsub_wf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwsub_wf(vfloat64m4_t op0, float op1, size_t op2){
  return vfwsub_wf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwsub_wf(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, float op3, size_t op4){
  return vfwsub_wf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwsub_wf(vfloat64m8_t op0, float op1, size_t op2){
  return vfwsub_wf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwsub_wf(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, float op3, size_t op4){
  return vfwsub_wf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmul(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfmul_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmul(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmul_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmul(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfmul_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmul(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmul_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmul(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfmul_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmul(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmul_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmul(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfmul_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmul(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmul_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmul(vfloat64m1_t op0, double op1, size_t op2){
  return vfmul_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmul(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfmul_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmul(vfloat64m2_t op0, double op1, size_t op2){
  return vfmul_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmul(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfmul_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmul(vfloat64m4_t op0, double op1, size_t op2){
  return vfmul_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmul(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfmul_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmul(vfloat64m8_t op0, double op1, size_t op2){
  return vfmul_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmul(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfmul_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfdiv(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfdiv_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfdiv(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfdiv_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfdiv(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfdiv_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfdiv(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfdiv_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfdiv(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfdiv_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfdiv(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfdiv_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfdiv(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfdiv_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfdiv(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfdiv_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfdiv(vfloat64m1_t op0, double op1, size_t op2){
  return vfdiv_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfdiv(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfdiv_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfdiv(vfloat64m2_t op0, double op1, size_t op2){
  return vfdiv_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfdiv(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfdiv_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfdiv(vfloat64m4_t op0, double op1, size_t op2){
  return vfdiv_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfdiv(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfdiv_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfdiv(vfloat64m8_t op0, double op1, size_t op2){
  return vfdiv_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfdiv(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfdiv_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfrdiv(vfloat64m1_t op0, double op1, size_t op2){
  return vfrdiv_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfrdiv(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfrdiv_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfrdiv(vfloat64m2_t op0, double op1, size_t op2){
  return vfrdiv_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfrdiv(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfrdiv_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfrdiv(vfloat64m4_t op0, double op1, size_t op2){
  return vfrdiv_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfrdiv(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfrdiv_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfrdiv(vfloat64m8_t op0, double op1, size_t op2){
  return vfrdiv_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfrdiv(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfrdiv_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmacc(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfmacc_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmacc(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmacc_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmacc(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfmacc_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmacc(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmacc_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmacc(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfmacc_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmacc(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmacc_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmacc(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfmacc_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmacc(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmacc_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmacc(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfmacc_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmacc(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfmacc_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmacc(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfmacc_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmacc(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfmacc_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmacc(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfmacc_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmacc(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfmacc_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmacc(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfmacc_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmacc(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfmacc_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmacc(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfnmacc_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmacc(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfnmacc_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmacc(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfnmacc_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmacc(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfnmacc_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmacc(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfnmacc_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmacc(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfnmacc_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmacc(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfnmacc_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmacc(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfnmacc_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmacc(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfnmacc_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmacc(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfnmacc_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmacc(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfnmacc_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmacc(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfnmacc_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmacc(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfnmacc_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmacc(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfnmacc_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmacc(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfnmacc_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmacc(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfnmacc_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmsac(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfmsac_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmsac(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmsac_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmsac(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfmsac_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmsac(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmsac_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmsac(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfmsac_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmsac(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmsac_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmsac(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfmsac_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmsac(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmsac_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmsac(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfmsac_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmsac(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfmsac_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmsac(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfmsac_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmsac(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfmsac_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmsac(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfmsac_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmsac(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfmsac_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmsac(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfmsac_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmsac(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfmsac_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmsac(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfnmsac_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmsac(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfnmsac_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmsac(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfnmsac_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmsac(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfnmsac_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmsac(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfnmsac_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmsac(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfnmsac_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmsac(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfnmsac_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmsac(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfnmsac_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmsac(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfnmsac_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmsac(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfnmsac_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmsac(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfnmsac_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmsac(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfnmsac_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmsac(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfnmsac_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmsac(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfnmsac_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmsac(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfnmsac_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmsac(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfnmsac_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmadd(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfmadd_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmadd_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmadd(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfmadd_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmadd_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmadd(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfmadd_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmadd_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmadd(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfmadd_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmadd_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmadd(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfmadd_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmadd(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfmadd_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmadd(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfmadd_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmadd(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfmadd_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmadd(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfmadd_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmadd(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfmadd_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmadd(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfmadd_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmadd(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfmadd_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmadd(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfnmadd_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmadd(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfnmadd_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmadd(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfnmadd_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmadd(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfnmadd_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmadd(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfnmadd_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmadd(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfnmadd_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmadd(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfnmadd_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmadd(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfnmadd_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmadd(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfnmadd_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmadd(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfnmadd_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmadd(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfnmadd_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmadd(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfnmadd_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmadd(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfnmadd_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmadd(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfnmadd_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmadd(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfnmadd_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmadd(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfnmadd_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmsub(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfmsub_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmsub(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmsub_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmsub(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfmsub_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmsub(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmsub_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmsub(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfmsub_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmsub(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmsub_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmsub(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfmsub_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmsub(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmsub_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmsub(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfmsub_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmsub(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfmsub_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmsub(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfmsub_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmsub(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfmsub_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmsub(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfmsub_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmsub(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfmsub_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmsub(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfmsub_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmsub(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfmsub_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmsub(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfnmsub_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmsub(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfnmsub_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmsub(vfloat64m2_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfnmsub_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmsub(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfnmsub_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmsub(vfloat64m4_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfnmsub_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmsub(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfnmsub_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmsub(vfloat64m8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfnmsub_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmsub(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfnmsub_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfnmsub(vfloat64m1_t op0, double op1, vfloat64m1_t op2, size_t op3){
  return vfnmsub_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfnmsub(vbool64_t op0, vfloat64m1_t op1, double op2, vfloat64m1_t op3, size_t op4){
  return vfnmsub_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfnmsub(vfloat64m2_t op0, double op1, vfloat64m2_t op2, size_t op3){
  return vfnmsub_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfnmsub(vbool32_t op0, vfloat64m2_t op1, double op2, vfloat64m2_t op3, size_t op4){
  return vfnmsub_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfnmsub(vfloat64m4_t op0, double op1, vfloat64m4_t op2, size_t op3){
  return vfnmsub_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfnmsub(vbool16_t op0, vfloat64m4_t op1, double op2, vfloat64m4_t op3, size_t op4){
  return vfnmsub_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfnmsub(vfloat64m8_t op0, double op1, vfloat64m8_t op2, size_t op3){
  return vfnmsub_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfnmsub(vbool8_t op0, vfloat64m8_t op1, double op2, vfloat64m8_t op3, size_t op4){
  return vfnmsub_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmin(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfmin_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmin(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmin_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmin(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfmin_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmin(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmin_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmin(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfmin_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmin(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmin_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmin(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfmin_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmin(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmin_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmin(vfloat64m1_t op0, double op1, size_t op2){
  return vfmin_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmin(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfmin_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmin(vfloat64m2_t op0, double op1, size_t op2){
  return vfmin_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmin(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfmin_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmin(vfloat64m4_t op0, double op1, size_t op2){
  return vfmin_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmin(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfmin_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmin(vfloat64m8_t op0, double op1, size_t op2){
  return vfmin_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmin(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfmin_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmax(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfmax_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmax(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfmax_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmax(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfmax_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmax(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfmax_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmax(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfmax_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmax(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfmax_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmax(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfmax_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmax(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfmax_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfmax(vfloat64m1_t op0, double op1, size_t op2){
  return vfmax_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfmax(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfmax_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfmax(vfloat64m2_t op0, double op1, size_t op2){
  return vfmax_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfmax(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfmax_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfmax(vfloat64m4_t op0, double op1, size_t op2){
  return vfmax_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfmax(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfmax_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfmax(vfloat64m8_t op0, double op1, size_t op2){
  return vfmax_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfmax(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfmax_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnj(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfsgnj_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnj(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfsgnj_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnj(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfsgnj_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnj(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfsgnj_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnj(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfsgnj_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnj(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfsgnj_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnj(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfsgnj_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnj(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfsgnj_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnj(vfloat64m1_t op0, double op1, size_t op2){
  return vfsgnj_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnj(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfsgnj_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnj(vfloat64m2_t op0, double op1, size_t op2){
  return vfsgnj_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnj(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfsgnj_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnj(vfloat64m4_t op0, double op1, size_t op2){
  return vfsgnj_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnj(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfsgnj_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnj(vfloat64m8_t op0, double op1, size_t op2){
  return vfsgnj_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnj(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfsgnj_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnjn(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfsgnjn_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnjn(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfsgnjn_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnjn(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfsgnjn_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnjn(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfsgnjn_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnjn(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfsgnjn_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnjn(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfsgnjn_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnjn(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfsgnjn_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnjn(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfsgnjn_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnjn(vfloat64m1_t op0, double op1, size_t op2){
  return vfsgnjn_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnjn(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfsgnjn_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnjn(vfloat64m2_t op0, double op1, size_t op2){
  return vfsgnjn_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnjn(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfsgnjn_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnjn(vfloat64m4_t op0, double op1, size_t op2){
  return vfsgnjn_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnjn(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfsgnjn_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnjn(vfloat64m8_t op0, double op1, size_t op2){
  return vfsgnjn_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnjn(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfsgnjn_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnjx(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vfsgnjx_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnjx(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfsgnjx_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnjx(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vfsgnjx_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnjx(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vfsgnjx_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnjx(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vfsgnjx_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnjx(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vfsgnjx_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnjx(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vfsgnjx_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnjx(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vfsgnjx_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfsgnjx(vfloat64m1_t op0, double op1, size_t op2){
  return vfsgnjx_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfsgnjx(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfsgnjx_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfsgnjx(vfloat64m2_t op0, double op1, size_t op2){
  return vfsgnjx_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfsgnjx(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfsgnjx_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfsgnjx(vfloat64m4_t op0, double op1, size_t op2){
  return vfsgnjx_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfsgnjx(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfsgnjx_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfsgnjx(vfloat64m8_t op0, double op1, size_t op2){
  return vfsgnjx_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfsgnjx(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfsgnjx_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfeq(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vmfeq_vv_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfeq(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vmfeq_vv_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfeq(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vmfeq_vv_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfeq(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vmfeq_vv_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfeq(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vmfeq_vv_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfeq(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vmfeq_vv_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfeq(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vmfeq_vv_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfeq(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vmfeq_vv_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfeq(vfloat64m1_t op0, double op1, size_t op2){
  return vmfeq_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfeq(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmfeq_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfeq(vfloat64m2_t op0, double op1, size_t op2){
  return vmfeq_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfeq(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmfeq_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfeq(vfloat64m4_t op0, double op1, size_t op2){
  return vmfeq_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfeq(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmfeq_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfeq(vfloat64m8_t op0, double op1, size_t op2){
  return vmfeq_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfeq(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmfeq_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfne(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vmfne_vv_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfne(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vmfne_vv_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfne(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vmfne_vv_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfne(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vmfne_vv_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfne(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vmfne_vv_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfne(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vmfne_vv_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfne(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vmfne_vv_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfne(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vmfne_vv_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfne(vfloat64m1_t op0, double op1, size_t op2){
  return vmfne_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfne(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmfne_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfne(vfloat64m2_t op0, double op1, size_t op2){
  return vmfne_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfne(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmfne_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfne(vfloat64m4_t op0, double op1, size_t op2){
  return vmfne_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfne(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmfne_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfne(vfloat64m8_t op0, double op1, size_t op2){
  return vmfne_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfne(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmfne_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmflt(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vmflt_vv_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmflt(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vmflt_vv_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmflt(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vmflt_vv_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmflt(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vmflt_vv_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmflt(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vmflt_vv_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmflt(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vmflt_vv_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmflt(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vmflt_vv_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmflt(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vmflt_vv_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmflt(vfloat64m1_t op0, double op1, size_t op2){
  return vmflt_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmflt(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmflt_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmflt(vfloat64m2_t op0, double op1, size_t op2){
  return vmflt_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmflt(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmflt_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmflt(vfloat64m4_t op0, double op1, size_t op2){
  return vmflt_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmflt(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmflt_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmflt(vfloat64m8_t op0, double op1, size_t op2){
  return vmflt_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmflt(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmflt_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfle(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2){
  return vmfle_vv_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfle(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vmfle_vv_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfle(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2){
  return vmfle_vv_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfle(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, vfloat64m2_t op3, size_t op4){
  return vmfle_vv_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfle(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2){
  return vmfle_vv_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfle(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, vfloat64m4_t op3, size_t op4){
  return vmfle_vv_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfle(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2){
  return vmfle_vv_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfle(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, vfloat64m8_t op3, size_t op4){
  return vmfle_vv_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfle(vfloat64m1_t op0, double op1, size_t op2){
  return vmfle_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfle(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmfle_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfle(vfloat64m2_t op0, double op1, size_t op2){
  return vmfle_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfle(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmfle_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfle(vfloat64m4_t op0, double op1, size_t op2){
  return vmfle_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfle(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmfle_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfle(vfloat64m8_t op0, double op1, size_t op2){
  return vmfle_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfle(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmfle_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfgt(vfloat64m1_t op0, double op1, size_t op2){
  return vmfgt_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfgt(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmfgt_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfgt(vfloat64m2_t op0, double op1, size_t op2){
  return vmfgt_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfgt(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmfgt_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfgt(vfloat64m4_t op0, double op1, size_t op2){
  return vmfgt_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfgt(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmfgt_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfgt(vfloat64m8_t op0, double op1, size_t op2){
  return vmfgt_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfgt(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmfgt_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vlse64(vbool64_t op0, vfloat64m1_t op1, const double * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vlse64(vbool32_t op0, vfloat64m2_t op1, const double * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vlse64(vbool16_t op0, vfloat64m4_t op1, const double * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vlse64(vbool8_t op0, vfloat64m8_t op1, const double * op2, ptrdiff_t op3, size_t op4){
  return vlse64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool64_t vmfge(vfloat64m1_t op0, double op1, size_t op2){
  return vmfge_vf_f64m1_b64(op0, op1, op2);
}

__rvv_overloaded vbool64_t vmfge(vbool64_t op0, vbool64_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vmfge_vf_f64m1_b64_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool32_t vmfge(vfloat64m2_t op0, double op1, size_t op2){
  return vmfge_vf_f64m2_b32(op0, op1, op2);
}

__rvv_overloaded vbool32_t vmfge(vbool32_t op0, vbool32_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vmfge_vf_f64m2_b32_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool16_t vmfge(vfloat64m4_t op0, double op1, size_t op2){
  return vmfge_vf_f64m4_b16(op0, op1, op2);
}

__rvv_overloaded vbool16_t vmfge(vbool16_t op0, vbool16_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vmfge_vf_f64m4_b16_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vbool8_t vmfge(vfloat64m8_t op0, double op1, size_t op2){
  return vmfge_vf_f64m8_b8(op0, op1, op2);
}

__rvv_overloaded vbool8_t vmfge(vbool8_t op0, vbool8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vmfge_vf_f64m8_b8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vmerge(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vmerge_vvm_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vmerge(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vmerge_vvm_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vmerge(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vmerge_vvm_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vmerge(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vmerge_vvm_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfmerge(vbool64_t op0, vfloat64m1_t op1, double op2, size_t op3){
  return vfmerge_vfm_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfmerge(vbool32_t op0, vfloat64m2_t op1, double op2, size_t op3){
  return vfmerge_vfm_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfmerge(vbool16_t op0, vfloat64m4_t op1, double op2, size_t op3){
  return vfmerge_vfm_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfmerge(vbool8_t op0, vfloat64m8_t op1, double op2, size_t op3){
  return vfmerge_vfm_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmax(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmax_vs_f64m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmax(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmax_vs_f64m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmax(vfloat64m1_t op0, vfloat64m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmax_vs_f64m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmax(vbool32_t op0, vfloat64m1_t op1, vfloat64m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmax_vs_f64m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmax(vfloat64m1_t op0, vfloat64m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmax_vs_f64m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmax(vbool16_t op0, vfloat64m1_t op1, vfloat64m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmax_vs_f64m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmax(vfloat64m1_t op0, vfloat64m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmax_vs_f64m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmax(vbool8_t op0, vfloat64m1_t op1, vfloat64m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmax_vs_f64m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmin(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmin_vs_f64m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmin(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmin_vs_f64m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmin(vfloat64m1_t op0, vfloat64m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmin_vs_f64m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmin(vbool32_t op0, vfloat64m1_t op1, vfloat64m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmin_vs_f64m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmin(vfloat64m1_t op0, vfloat64m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmin_vs_f64m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmin(vbool16_t op0, vfloat64m1_t op1, vfloat64m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmin_vs_f64m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredmin(vfloat64m1_t op0, vfloat64m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfredmin_vs_f64m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredmin(vbool8_t op0, vfloat64m1_t op1, vfloat64m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfredmin_vs_f64m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredsum(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfredsum_vs_f64m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredsum(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfredsum_vs_f64m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredsum(vfloat64m1_t op0, vfloat64m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfredsum_vs_f64m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredsum(vbool32_t op0, vfloat64m1_t op1, vfloat64m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfredsum_vs_f64m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredsum(vfloat64m1_t op0, vfloat64m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfredsum_vs_f64m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredsum(vbool16_t op0, vfloat64m1_t op1, vfloat64m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfredsum_vs_f64m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredsum(vfloat64m1_t op0, vfloat64m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfredsum_vs_f64m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredsum(vbool8_t op0, vfloat64m1_t op1, vfloat64m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfredsum_vs_f64m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredosum(vfloat64m1_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfredosum_vs_f64m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredosum(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfredosum_vs_f64m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredosum(vfloat64m1_t op0, vfloat64m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfredosum_vs_f64m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredosum(vbool32_t op0, vfloat64m1_t op1, vfloat64m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfredosum_vs_f64m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredosum(vfloat64m1_t op0, vfloat64m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfredosum_vs_f64m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredosum(vbool16_t op0, vfloat64m1_t op1, vfloat64m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfredosum_vs_f64m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfredosum(vfloat64m1_t op0, vfloat64m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfredosum_vs_f64m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfredosum(vbool8_t op0, vfloat64m1_t op1, vfloat64m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfredosum_vs_f64m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vslideup(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2, size_t op3){
  return vslideup_vx_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vslideup(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3, size_t op4){
  return vslideup_vx_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vslideup(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2, size_t op3){
  return vslideup_vx_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vslideup(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3, size_t op4){
  return vslideup_vx_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vslideup(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2, size_t op3){
  return vslideup_vx_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vslideup(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3, size_t op4){
  return vslideup_vx_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vslideup(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2, size_t op3){
  return vslideup_vx_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vslideup(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3, size_t op4){
  return vslideup_vx_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vslidedown(vfloat64m1_t op0, vfloat64m1_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vslidedown(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vslidedown(vfloat64m2_t op0, vfloat64m2_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vslidedown(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vslidedown(vfloat64m4_t op0, vfloat64m4_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vslidedown(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vslidedown(vfloat64m8_t op0, vfloat64m8_t op1, size_t op2, size_t op3){
  return vslidedown_vx_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vslidedown(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3, size_t op4){
  return vslidedown_vx_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfslide1up(vfloat64m1_t op0, double op1, size_t op2){
  return vfslide1up_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfslide1up(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfslide1up_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfslide1up(vfloat64m2_t op0, double op1, size_t op2){
  return vfslide1up_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfslide1up(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfslide1up_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfslide1up(vfloat64m4_t op0, double op1, size_t op2){
  return vfslide1up_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfslide1up(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfslide1up_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfslide1up(vfloat64m8_t op0, double op1, size_t op2){
  return vfslide1up_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfslide1up(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfslide1up_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfslide1down(vfloat64m1_t op0, double op1, size_t op2){
  return vfslide1down_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfslide1down(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, double op3, size_t op4){
  return vfslide1down_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfslide1down(vfloat64m2_t op0, double op1, size_t op2){
  return vfslide1down_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfslide1down(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, double op3, size_t op4){
  return vfslide1down_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfslide1down(vfloat64m4_t op0, double op1, size_t op2){
  return vfslide1down_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfslide1down(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, double op3, size_t op4){
  return vfslide1down_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfslide1down(vfloat64m8_t op0, double op1, size_t op2){
  return vfslide1down_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfslide1down(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, double op3, size_t op4){
  return vfslide1down_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vrgather(vfloat64m1_t op0, vuint64m1_t op1, size_t op2){
  return vrgather_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vrgather(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vuint64m1_t op3, size_t op4){
  return vrgather_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vrgather(vfloat64m2_t op0, vuint64m2_t op1, size_t op2){
  return vrgather_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vrgather(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vuint64m2_t op3, size_t op4){
  return vrgather_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vrgather(vfloat64m4_t op0, vuint64m4_t op1, size_t op2){
  return vrgather_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vrgather(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vuint64m4_t op3, size_t op4){
  return vrgather_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vrgather(vfloat64m8_t op0, vuint64m8_t op1, size_t op2){
  return vrgather_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vrgather(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vuint64m8_t op3, size_t op4){
  return vrgather_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vrgather(vfloat64m1_t op0, size_t op1, size_t op2){
  return vrgather_vx_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vrgather(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3, size_t op4){
  return vrgather_vx_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vrgather(vfloat64m2_t op0, size_t op1, size_t op2){
  return vrgather_vx_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vrgather(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3, size_t op4){
  return vrgather_vx_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vrgather(vfloat64m4_t op0, size_t op1, size_t op2){
  return vrgather_vx_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vrgather(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3, size_t op4){
  return vrgather_vx_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vrgather(vfloat64m8_t op0, size_t op1, size_t op2){
  return vrgather_vx_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vrgather(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3, size_t op4){
  return vrgather_vx_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vrgatherei16(vfloat64m1_t op0, vuint16mf4_t op1, size_t op2){
  return vrgatherei16_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vrgatherei16(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vuint16mf4_t op3, size_t op4){
  return vrgatherei16_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vrgatherei16(vfloat64m2_t op0, vuint16mf2_t op1, size_t op2){
  return vrgatherei16_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vrgatherei16(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vuint16mf2_t op3, size_t op4){
  return vrgatherei16_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vrgatherei16(vfloat64m4_t op0, vuint16m1_t op1, size_t op2){
  return vrgatherei16_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vrgatherei16(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vuint16m1_t op3, size_t op4){
  return vrgatherei16_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vrgatherei16(vfloat64m8_t op0, vuint16m2_t op1, size_t op2){
  return vrgatherei16_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vrgatherei16(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vuint16m2_t op3, size_t op4){
  return vrgatherei16_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vcompress(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vcompress_vm_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vcompress(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vcompress_vm_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vcompress(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vcompress_vm_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vcompress(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vcompress_vm_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(double * op0, ptrdiff_t op1, vfloat64m1_t op2, size_t op3){
  return vsse64_v_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool64_t op0, double * op1, ptrdiff_t op2, vfloat64m1_t op3, size_t op4){
  return vsse64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(double * op0, ptrdiff_t op1, vfloat64m2_t op2, size_t op3){
  return vsse64_v_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool32_t op0, double * op1, ptrdiff_t op2, vfloat64m2_t op3, size_t op4){
  return vsse64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(double * op0, ptrdiff_t op1, vfloat64m4_t op2, size_t op3){
  return vsse64_v_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool16_t op0, double * op1, ptrdiff_t op2, vfloat64m4_t op3, size_t op4){
  return vsse64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded void vsse64(double * op0, ptrdiff_t op1, vfloat64m8_t op2, size_t op3){
  return vsse64_v_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded void vsse64(vbool8_t op0, double * op1, ptrdiff_t op2, vfloat64m8_t op3, size_t op4){
  return vsse64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei8(const double * op0, vuint8mf8_t op1, size_t op2){
  return vluxei8_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei8(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint8mf8_t op3, size_t op4){
  return vluxei8_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei8(const double * op0, vuint8mf4_t op1, size_t op2){
  return vluxei8_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei8(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint8mf4_t op3, size_t op4){
  return vluxei8_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei8(const double * op0, vuint8mf2_t op1, size_t op2){
  return vluxei8_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei8(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint8mf2_t op3, size_t op4){
  return vluxei8_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei8(const double * op0, vuint8m1_t op1, size_t op2){
  return vluxei8_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei8(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint8m1_t op3, size_t op4){
  return vluxei8_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei16(const double * op0, vuint16mf4_t op1, size_t op2){
  return vluxei16_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei16(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint16mf4_t op3, size_t op4){
  return vluxei16_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei16(const double * op0, vuint16mf2_t op1, size_t op2){
  return vluxei16_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei16(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint16mf2_t op3, size_t op4){
  return vluxei16_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei16(const double * op0, vuint16m1_t op1, size_t op2){
  return vluxei16_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei16(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint16m1_t op3, size_t op4){
  return vluxei16_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei16(const double * op0, vuint16m2_t op1, size_t op2){
  return vluxei16_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei16(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint16m2_t op3, size_t op4){
  return vluxei16_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei32(const double * op0, vuint32mf2_t op1, size_t op2){
  return vluxei32_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei32(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint32mf2_t op3, size_t op4){
  return vluxei32_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei32(const double * op0, vuint32m1_t op1, size_t op2){
  return vluxei32_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei32(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint32m1_t op3, size_t op4){
  return vluxei32_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei32(const double * op0, vuint32m2_t op1, size_t op2){
  return vluxei32_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei32(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint32m2_t op3, size_t op4){
  return vluxei32_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei32(const double * op0, vuint32m4_t op1, size_t op2){
  return vluxei32_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei32(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint32m4_t op3, size_t op4){
  return vluxei32_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vluxei64(const double * op0, vuint64m1_t op1, size_t op2){
  return vluxei64_v_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vluxei64(vbool64_t op0, vfloat64m1_t op1, const double * op2, vuint64m1_t op3, size_t op4){
  return vluxei64_v_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vluxei64(const double * op0, vuint64m2_t op1, size_t op2){
  return vluxei64_v_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vluxei64(vbool32_t op0, vfloat64m2_t op1, const double * op2, vuint64m2_t op3, size_t op4){
  return vluxei64_v_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vluxei64(const double * op0, vuint64m4_t op1, size_t op2){
  return vluxei64_v_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vluxei64(vbool16_t op0, vfloat64m4_t op1, const double * op2, vuint64m4_t op3, size_t op4){
  return vluxei64_v_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vluxei64(const double * op0, vuint64m8_t op1, size_t op2){
  return vluxei64_v_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vluxei64(vbool8_t op0, vfloat64m8_t op1, const double * op2, vuint64m8_t op3, size_t op4){
  return vluxei64_v_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vuint64m1_t vfclass(vfloat64m1_t op0, size_t op1){
  return vfclass_v_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vfclass(vbool64_t op0, vuint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfclass_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vfclass(vfloat64m2_t op0, size_t op1){
  return vfclass_v_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vfclass(vbool32_t op0, vuint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfclass_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vfclass(vfloat64m4_t op0, size_t op1){
  return vfclass_v_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vfclass(vbool16_t op0, vuint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfclass_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vfclass(vfloat64m8_t op0, size_t op1){
  return vfclass_v_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vfclass(vbool8_t op0, vuint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfclass_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfcvt_f(vint64m1_t op0, size_t op1){
  return vfcvt_f_x_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfcvt_f(vbool64_t op0, vfloat64m1_t op1, vint64m1_t op2, size_t op3){
  return vfcvt_f_x_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfcvt_f(vint64m2_t op0, size_t op1){
  return vfcvt_f_x_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfcvt_f(vbool32_t op0, vfloat64m2_t op1, vint64m2_t op2, size_t op3){
  return vfcvt_f_x_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfcvt_f(vint64m4_t op0, size_t op1){
  return vfcvt_f_x_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfcvt_f(vbool16_t op0, vfloat64m4_t op1, vint64m4_t op2, size_t op3){
  return vfcvt_f_x_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfcvt_f(vint64m8_t op0, size_t op1){
  return vfcvt_f_x_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfcvt_f(vbool8_t op0, vfloat64m8_t op1, vint64m8_t op2, size_t op3){
  return vfcvt_f_x_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfcvt_f(vuint64m1_t op0, size_t op1){
  return vfcvt_f_xu_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfcvt_f(vbool64_t op0, vfloat64m1_t op1, vuint64m1_t op2, size_t op3){
  return vfcvt_f_xu_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfcvt_f(vuint64m2_t op0, size_t op1){
  return vfcvt_f_xu_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfcvt_f(vbool32_t op0, vfloat64m2_t op1, vuint64m2_t op2, size_t op3){
  return vfcvt_f_xu_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfcvt_f(vuint64m4_t op0, size_t op1){
  return vfcvt_f_xu_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfcvt_f(vbool16_t op0, vfloat64m4_t op1, vuint64m4_t op2, size_t op3){
  return vfcvt_f_xu_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfcvt_f(vuint64m8_t op0, size_t op1){
  return vfcvt_f_xu_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfcvt_f(vbool8_t op0, vfloat64m8_t op1, vuint64m8_t op2, size_t op3){
  return vfcvt_f_xu_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vfcvt_rtz_x(vfloat64m1_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vfcvt_rtz_x(vbool64_t op0, vint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vfcvt_rtz_x(vfloat64m2_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vfcvt_rtz_x(vbool32_t op0, vint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vfcvt_rtz_x(vfloat64m4_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vfcvt_rtz_x(vbool16_t op0, vint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vfcvt_rtz_x(vfloat64m8_t op0, size_t op1){
  return vfcvt_rtz_x_f_v_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vfcvt_rtz_x(vbool8_t op0, vint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfcvt_rtz_x_f_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vfcvt_rtz_xu(vfloat64m1_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vfcvt_rtz_xu(vbool64_t op0, vuint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vfcvt_rtz_xu(vfloat64m2_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vfcvt_rtz_xu(vbool32_t op0, vuint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vfcvt_rtz_xu(vfloat64m4_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vfcvt_rtz_xu(vbool16_t op0, vuint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vfcvt_rtz_xu(vfloat64m8_t op0, size_t op1){
  return vfcvt_rtz_xu_f_v_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vfcvt_rtz_xu(vbool8_t op0, vuint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfcvt_rtz_xu_f_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m1_t vfcvt_x(vfloat64m1_t op0, size_t op1){
  return vfcvt_x_f_v_i64m1(op0, op1);
}

__rvv_overloaded vint64m1_t vfcvt_x(vbool64_t op0, vint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfcvt_x_f_v_i64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m2_t vfcvt_x(vfloat64m2_t op0, size_t op1){
  return vfcvt_x_f_v_i64m2(op0, op1);
}

__rvv_overloaded vint64m2_t vfcvt_x(vbool32_t op0, vint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfcvt_x_f_v_i64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m4_t vfcvt_x(vfloat64m4_t op0, size_t op1){
  return vfcvt_x_f_v_i64m4(op0, op1);
}

__rvv_overloaded vint64m4_t vfcvt_x(vbool16_t op0, vint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfcvt_x_f_v_i64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint64m8_t vfcvt_x(vfloat64m8_t op0, size_t op1){
  return vfcvt_x_f_v_i64m8(op0, op1);
}

__rvv_overloaded vint64m8_t vfcvt_x(vbool8_t op0, vint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfcvt_x_f_v_i64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m1_t vfcvt_xu(vfloat64m1_t op0, size_t op1){
  return vfcvt_xu_f_v_u64m1(op0, op1);
}

__rvv_overloaded vuint64m1_t vfcvt_xu(vbool64_t op0, vuint64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfcvt_xu_f_v_u64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m2_t vfcvt_xu(vfloat64m2_t op0, size_t op1){
  return vfcvt_xu_f_v_u64m2(op0, op1);
}

__rvv_overloaded vuint64m2_t vfcvt_xu(vbool32_t op0, vuint64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfcvt_xu_f_v_u64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m4_t vfcvt_xu(vfloat64m4_t op0, size_t op1){
  return vfcvt_xu_f_v_u64m4(op0, op1);
}

__rvv_overloaded vuint64m4_t vfcvt_xu(vbool16_t op0, vuint64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfcvt_xu_f_v_u64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint64m8_t vfcvt_xu(vfloat64m8_t op0, size_t op1){
  return vfcvt_xu_f_v_u64m8(op0, op1);
}

__rvv_overloaded vuint64m8_t vfcvt_xu(vbool8_t op0, vuint64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfcvt_xu_f_v_u64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vfncvt_rtz_x(vfloat64m1_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vfncvt_rtz_x(vbool64_t op0, vint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vfncvt_rtz_x(vfloat64m2_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vfncvt_rtz_x(vbool32_t op0, vint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vfncvt_rtz_x(vfloat64m4_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vfncvt_rtz_x(vbool16_t op0, vint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vfncvt_rtz_x(vfloat64m8_t op0, size_t op1){
  return vfncvt_rtz_x_f_w_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vfncvt_rtz_x(vbool8_t op0, vint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_rtz_x_f_w_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vfncvt_rtz_xu(vfloat64m1_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vfncvt_rtz_xu(vbool64_t op0, vuint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vfncvt_rtz_xu(vfloat64m2_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vfncvt_rtz_xu(vbool32_t op0, vuint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vfncvt_rtz_xu(vfloat64m4_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vfncvt_rtz_xu(vbool16_t op0, vuint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vfncvt_rtz_xu(vfloat64m8_t op0, size_t op1){
  return vfncvt_rtz_xu_f_w_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vfncvt_rtz_xu(vbool8_t op0, vuint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_rtz_xu_f_w_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32mf2_t vfncvt_x(vfloat64m1_t op0, size_t op1){
  return vfncvt_x_f_w_i32mf2(op0, op1);
}

__rvv_overloaded vint32mf2_t vfncvt_x(vbool64_t op0, vint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_x_f_w_i32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m1_t vfncvt_x(vfloat64m2_t op0, size_t op1){
  return vfncvt_x_f_w_i32m1(op0, op1);
}

__rvv_overloaded vint32m1_t vfncvt_x(vbool32_t op0, vint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_x_f_w_i32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m2_t vfncvt_x(vfloat64m4_t op0, size_t op1){
  return vfncvt_x_f_w_i32m2(op0, op1);
}

__rvv_overloaded vint32m2_t vfncvt_x(vbool16_t op0, vint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_x_f_w_i32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vint32m4_t vfncvt_x(vfloat64m8_t op0, size_t op1){
  return vfncvt_x_f_w_i32m4(op0, op1);
}

__rvv_overloaded vint32m4_t vfncvt_x(vbool8_t op0, vint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_x_f_w_i32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32mf2_t vfncvt_xu(vfloat64m1_t op0, size_t op1){
  return vfncvt_xu_f_w_u32mf2(op0, op1);
}

__rvv_overloaded vuint32mf2_t vfncvt_xu(vbool64_t op0, vuint32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_xu_f_w_u32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m1_t vfncvt_xu(vfloat64m2_t op0, size_t op1){
  return vfncvt_xu_f_w_u32m1(op0, op1);
}

__rvv_overloaded vuint32m1_t vfncvt_xu(vbool32_t op0, vuint32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_xu_f_w_u32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m2_t vfncvt_xu(vfloat64m4_t op0, size_t op1){
  return vfncvt_xu_f_w_u32m2(op0, op1);
}

__rvv_overloaded vuint32m2_t vfncvt_xu(vbool16_t op0, vuint32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_xu_f_w_u32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vuint32m4_t vfncvt_xu(vfloat64m8_t op0, size_t op1){
  return vfncvt_xu_f_w_u32m4(op0, op1);
}

__rvv_overloaded vuint32m4_t vfncvt_xu(vbool8_t op0, vuint32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_xu_f_w_u32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfrec7(vfloat64m1_t op0, size_t op1){
  return vfrec7_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfrec7(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfrec7_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfrec7(vfloat64m2_t op0, size_t op1){
  return vfrec7_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfrec7(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfrec7_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfrec7(vfloat64m4_t op0, size_t op1){
  return vfrec7_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfrec7(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfrec7_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfrec7(vfloat64m8_t op0, size_t op1){
  return vfrec7_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfrec7(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfrec7_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfrsqrt7(vfloat64m1_t op0, size_t op1){
  return vfrsqrt7_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfrsqrt7(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfrsqrt7_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfrsqrt7(vfloat64m2_t op0, size_t op1){
  return vfrsqrt7_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfrsqrt7(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfrsqrt7_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfrsqrt7(vfloat64m4_t op0, size_t op1){
  return vfrsqrt7_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfrsqrt7(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfrsqrt7_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfrsqrt7(vfloat64m8_t op0, size_t op1){
  return vfrsqrt7_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfrsqrt7(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfrsqrt7_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfsqrt(vfloat64m1_t op0, size_t op1){
  return vfsqrt_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfsqrt(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfsqrt_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfsqrt(vfloat64m2_t op0, size_t op1){
  return vfsqrt_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfsqrt(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, size_t op3){
  return vfsqrt_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfsqrt(vfloat64m4_t op0, size_t op1){
  return vfsqrt_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfsqrt(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, size_t op3){
  return vfsqrt_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfsqrt(vfloat64m8_t op0, size_t op1){
  return vfsqrt_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfsqrt(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, size_t op3){
  return vfsqrt_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vint32mf2_t op0, size_t op1){
  return vfwcvt_f_x_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vbool64_t op0, vfloat64m1_t op1, vint32mf2_t op2, size_t op3){
  return vfwcvt_f_x_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vint32m1_t op0, size_t op1){
  return vfwcvt_f_x_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vbool32_t op0, vfloat64m2_t op1, vint32m1_t op2, size_t op3){
  return vfwcvt_f_x_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vint32m2_t op0, size_t op1){
  return vfwcvt_f_x_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vbool16_t op0, vfloat64m4_t op1, vint32m2_t op2, size_t op3){
  return vfwcvt_f_x_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vint32m4_t op0, size_t op1){
  return vfwcvt_f_x_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vbool8_t op0, vfloat64m8_t op1, vint32m4_t op2, size_t op3){
  return vfwcvt_f_x_v_f64m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vuint32mf2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vbool64_t op0, vfloat64m1_t op1, vuint32mf2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vuint32m1_t op0, size_t op1){
  return vfwcvt_f_xu_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vbool32_t op0, vfloat64m2_t op1, vuint32m1_t op2, size_t op3){
  return vfwcvt_f_xu_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vuint32m2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vbool16_t op0, vfloat64m4_t op1, vuint32m2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vuint32m4_t op0, size_t op1){
  return vfwcvt_f_xu_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vbool8_t op0, vfloat64m8_t op1, vuint32m4_t op2, size_t op3){
  return vfwcvt_f_xu_v_f64m8_m(op0, op1, op2, op3);
}

#endif

#if defined(__riscv_f) && defined(__riscv_d)
__rvv_overloaded vfloat64m1_t vfwadd_vv(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfwadd_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwadd_vv(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwadd_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwadd_vv(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfwadd_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwadd_vv(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwadd_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwadd_vv(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfwadd_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwadd_vv(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwadd_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwadd_vv(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfwadd_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwadd_vv(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwadd_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwadd_vf(vfloat32mf2_t op0, float op1, size_t op2){
  return vfwadd_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwadd_vf(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfwadd_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwadd_vf(vfloat32m1_t op0, float op1, size_t op2){
  return vfwadd_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwadd_vf(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfwadd_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwadd_vf(vfloat32m2_t op0, float op1, size_t op2){
  return vfwadd_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwadd_vf(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfwadd_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwadd_vf(vfloat32m4_t op0, float op1, size_t op2){
  return vfwadd_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwadd_vf(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfwadd_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwsub_vv(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfwsub_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwsub_vv(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwsub_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwsub_vv(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfwsub_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwsub_vv(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwsub_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwsub_vv(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfwsub_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwsub_vv(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwsub_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwsub_vv(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfwsub_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwsub_vv(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwsub_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwsub_vf(vfloat32mf2_t op0, float op1, size_t op2){
  return vfwsub_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwsub_vf(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfwsub_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwsub_vf(vfloat32m1_t op0, float op1, size_t op2){
  return vfwsub_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwsub_vf(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfwsub_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwsub_vf(vfloat32m2_t op0, float op1, size_t op2){
  return vfwsub_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwsub_vf(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfwsub_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwsub_vf(vfloat32m4_t op0, float op1, size_t op2){
  return vfwsub_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwsub_vf(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfwsub_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwadd_wv(vfloat64m1_t op0, vfloat32mf2_t op1, size_t op2){
  return vfwadd_wv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwadd_wv(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwadd_wv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwadd_wv(vfloat64m2_t op0, vfloat32m1_t op1, size_t op2){
  return vfwadd_wv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwadd_wv(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfwadd_wv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwadd_wv(vfloat64m4_t op0, vfloat32m2_t op1, size_t op2){
  return vfwadd_wv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwadd_wv(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat32m2_t op3, size_t op4){
  return vfwadd_wv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwadd_wv(vfloat64m8_t op0, vfloat32m4_t op1, size_t op2){
  return vfwadd_wv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwadd_wv(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat32m4_t op3, size_t op4){
  return vfwadd_wv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwsub_wv(vfloat64m1_t op0, vfloat32mf2_t op1, size_t op2){
  return vfwsub_wv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwsub_wv(vbool64_t op0, vfloat64m1_t op1, vfloat64m1_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwsub_wv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwsub_wv(vfloat64m2_t op0, vfloat32m1_t op1, size_t op2){
  return vfwsub_wv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwsub_wv(vbool32_t op0, vfloat64m2_t op1, vfloat64m2_t op2, vfloat32m1_t op3, size_t op4){
  return vfwsub_wv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwsub_wv(vfloat64m4_t op0, vfloat32m2_t op1, size_t op2){
  return vfwsub_wv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwsub_wv(vbool16_t op0, vfloat64m4_t op1, vfloat64m4_t op2, vfloat32m2_t op3, size_t op4){
  return vfwsub_wv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwsub_wv(vfloat64m8_t op0, vfloat32m4_t op1, size_t op2){
  return vfwsub_wv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwsub_wv(vbool8_t op0, vfloat64m8_t op1, vfloat64m8_t op2, vfloat32m4_t op3, size_t op4){
  return vfwsub_wv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmul(vfloat32mf2_t op0, vfloat32mf2_t op1, size_t op2){
  return vfwmul_vv_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwmul(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwmul_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmul(vfloat32m1_t op0, vfloat32m1_t op1, size_t op2){
  return vfwmul_vv_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwmul(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwmul_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmul(vfloat32m2_t op0, vfloat32m2_t op1, size_t op2){
  return vfwmul_vv_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwmul(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwmul_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmul(vfloat32m4_t op0, vfloat32m4_t op1, size_t op2){
  return vfwmul_vv_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwmul(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwmul_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmul(vfloat32mf2_t op0, float op1, size_t op2){
  return vfwmul_vf_f64m1(op0, op1, op2);
}

__rvv_overloaded vfloat64m1_t vfwmul(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, float op3, size_t op4){
  return vfwmul_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmul(vfloat32m1_t op0, float op1, size_t op2){
  return vfwmul_vf_f64m2(op0, op1, op2);
}

__rvv_overloaded vfloat64m2_t vfwmul(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, float op3, size_t op4){
  return vfwmul_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmul(vfloat32m2_t op0, float op1, size_t op2){
  return vfwmul_vf_f64m4(op0, op1, op2);
}

__rvv_overloaded vfloat64m4_t vfwmul(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, float op3, size_t op4){
  return vfwmul_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmul(vfloat32m4_t op0, float op1, size_t op2){
  return vfwmul_vf_f64m8(op0, op1, op2);
}

__rvv_overloaded vfloat64m8_t vfwmul(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, float op3, size_t op4){
  return vfwmul_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmacc(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwmacc_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwmacc(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwmacc_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmacc(vfloat64m2_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfwmacc_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwmacc(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwmacc_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmacc(vfloat64m4_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfwmacc_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwmacc(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwmacc_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmacc(vfloat64m8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfwmacc_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwmacc(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwmacc_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmacc(vfloat64m1_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfwmacc_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwmacc(vbool64_t op0, vfloat64m1_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfwmacc_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmacc(vfloat64m2_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfwmacc_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwmacc(vbool32_t op0, vfloat64m2_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfwmacc_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmacc(vfloat64m4_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfwmacc_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwmacc(vbool16_t op0, vfloat64m4_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfwmacc_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmacc(vfloat64m8_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfwmacc_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwmacc(vbool8_t op0, vfloat64m8_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfwmacc_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwnmacc(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwnmacc_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwnmacc(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwnmacc_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwnmacc(vfloat64m2_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfwnmacc_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwnmacc(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwnmacc_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwnmacc(vfloat64m4_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfwnmacc_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwnmacc(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwnmacc_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwnmacc(vfloat64m8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfwnmacc_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwnmacc(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwnmacc_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwnmacc(vfloat64m1_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfwnmacc_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwnmacc(vbool64_t op0, vfloat64m1_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfwnmacc_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwnmacc(vfloat64m2_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfwnmacc_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwnmacc(vbool32_t op0, vfloat64m2_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfwnmacc_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwnmacc(vfloat64m4_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfwnmacc_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwnmacc(vbool16_t op0, vfloat64m4_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfwnmacc_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwnmacc(vfloat64m8_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfwnmacc_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwnmacc(vbool8_t op0, vfloat64m8_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfwnmacc_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmsac(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwmsac_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwmsac(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwmsac_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmsac(vfloat64m2_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfwmsac_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwmsac(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwmsac_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmsac(vfloat64m4_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfwmsac_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwmsac(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwmsac_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmsac(vfloat64m8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfwmsac_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwmsac(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwmsac_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwmsac(vfloat64m1_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfwmsac_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwmsac(vbool64_t op0, vfloat64m1_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfwmsac_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwmsac(vfloat64m2_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfwmsac_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwmsac(vbool32_t op0, vfloat64m2_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfwmsac_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwmsac(vfloat64m4_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfwmsac_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwmsac(vbool16_t op0, vfloat64m4_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfwmsac_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwmsac(vfloat64m8_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfwmsac_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwmsac(vbool8_t op0, vfloat64m8_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfwmsac_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwnmsac(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwnmsac_vv_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwnmsac(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat32mf2_t op3, size_t op4){
  return vfwnmsac_vv_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwnmsac(vfloat64m2_t op0, vfloat32m1_t op1, vfloat32m1_t op2, size_t op3){
  return vfwnmsac_vv_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwnmsac(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, vfloat32m1_t op3, size_t op4){
  return vfwnmsac_vv_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwnmsac(vfloat64m4_t op0, vfloat32m2_t op1, vfloat32m2_t op2, size_t op3){
  return vfwnmsac_vv_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwnmsac(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, vfloat32m2_t op3, size_t op4){
  return vfwnmsac_vv_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwnmsac(vfloat64m8_t op0, vfloat32m4_t op1, vfloat32m4_t op2, size_t op3){
  return vfwnmsac_vv_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwnmsac(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, vfloat32m4_t op3, size_t op4){
  return vfwnmsac_vv_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwnmsac(vfloat64m1_t op0, float op1, vfloat32mf2_t op2, size_t op3){
  return vfwnmsac_vf_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwnmsac(vbool64_t op0, vfloat64m1_t op1, float op2, vfloat32mf2_t op3, size_t op4){
  return vfwnmsac_vf_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m2_t vfwnmsac(vfloat64m2_t op0, float op1, vfloat32m1_t op2, size_t op3){
  return vfwnmsac_vf_f64m2(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwnmsac(vbool32_t op0, vfloat64m2_t op1, float op2, vfloat32m1_t op3, size_t op4){
  return vfwnmsac_vf_f64m2_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m4_t vfwnmsac(vfloat64m4_t op0, float op1, vfloat32m2_t op2, size_t op3){
  return vfwnmsac_vf_f64m4(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwnmsac(vbool16_t op0, vfloat64m4_t op1, float op2, vfloat32m2_t op3, size_t op4){
  return vfwnmsac_vf_f64m4_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m8_t vfwnmsac(vfloat64m8_t op0, float op1, vfloat32m4_t op2, size_t op3){
  return vfwnmsac_vf_f64m8(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwnmsac(vbool8_t op0, vfloat64m8_t op1, float op2, vfloat32m4_t op3, size_t op4){
  return vfwnmsac_vf_f64m8_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vfloat64m1_t op0, vfloat32m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredsum_vs_f32m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vbool32_t op0, vfloat64m1_t op1, vfloat32m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredsum_vs_f32m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vfloat64m1_t op0, vfloat32m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredsum_vs_f32m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vbool16_t op0, vfloat64m1_t op1, vfloat32m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredsum_vs_f32m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vfloat64m1_t op0, vfloat32m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredsum_vs_f32m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vbool8_t op0, vfloat64m1_t op1, vfloat32m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredsum_vs_f32m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vfloat64m1_t op0, vfloat32m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredsum_vs_f32m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vbool4_t op0, vfloat64m1_t op1, vfloat32m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredsum_vs_f32m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredsum_vs_f32mf2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredsum(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredsum_vs_f32mf2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vfloat64m1_t op0, vfloat32m1_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredosum_vs_f32m1_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vbool32_t op0, vfloat64m1_t op1, vfloat32m1_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredosum_vs_f32m1_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vfloat64m1_t op0, vfloat32m2_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredosum_vs_f32m2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vbool16_t op0, vfloat64m1_t op1, vfloat32m2_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredosum_vs_f32m2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vfloat64m1_t op0, vfloat32m4_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredosum_vs_f32m4_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vbool8_t op0, vfloat64m1_t op1, vfloat32m4_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredosum_vs_f32m4_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vfloat64m1_t op0, vfloat32m8_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredosum_vs_f32m8_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vbool4_t op0, vfloat64m1_t op1, vfloat32m8_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredosum_vs_f32m8_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vfloat64m1_t op0, vfloat32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfwredosum_vs_f32mf2_f64m1(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwredosum(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, vfloat64m1_t op3, size_t op4){
  return vfwredosum_vs_f32mf2_f64m1_m(op0, op1, op2, op3, op4);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vfloat64m1_t op0, size_t op1){
  return vfncvt_f_f_w_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfncvt_f(vbool64_t op0, vfloat32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_f_f_w_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vfloat64m2_t op0, size_t op1){
  return vfncvt_f_f_w_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfncvt_f(vbool32_t op0, vfloat32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_f_f_w_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vfloat64m4_t op0, size_t op1){
  return vfncvt_f_f_w_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfncvt_f(vbool16_t op0, vfloat32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_f_f_w_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vfloat64m8_t op0, size_t op1){
  return vfncvt_f_f_w_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfncvt_f(vbool8_t op0, vfloat32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_f_f_w_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32mf2_t vfncvt_rod_f(vfloat64m1_t op0, size_t op1){
  return vfncvt_rod_f_f_w_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfncvt_rod_f(vbool64_t op0, vfloat32mf2_t op1, vfloat64m1_t op2, size_t op3){
  return vfncvt_rod_f_f_w_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfncvt_rod_f(vfloat64m2_t op0, size_t op1){
  return vfncvt_rod_f_f_w_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfncvt_rod_f(vbool32_t op0, vfloat32m1_t op1, vfloat64m2_t op2, size_t op3){
  return vfncvt_rod_f_f_w_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfncvt_rod_f(vfloat64m4_t op0, size_t op1){
  return vfncvt_rod_f_f_w_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfncvt_rod_f(vbool16_t op0, vfloat32m2_t op1, vfloat64m4_t op2, size_t op3){
  return vfncvt_rod_f_f_w_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfncvt_rod_f(vfloat64m8_t op0, size_t op1){
  return vfncvt_rod_f_f_w_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfncvt_rod_f(vbool8_t op0, vfloat32m4_t op1, vfloat64m8_t op2, size_t op3){
  return vfncvt_rod_f_f_w_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vfloat32mf2_t op0, size_t op1){
  return vfwcvt_f_f_v_f64m1(op0, op1);
}

__rvv_overloaded vfloat64m1_t vfwcvt_f(vbool64_t op0, vfloat64m1_t op1, vfloat32mf2_t op2, size_t op3){
  return vfwcvt_f_f_v_f64m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vfloat32m1_t op0, size_t op1){
  return vfwcvt_f_f_v_f64m2(op0, op1);
}

__rvv_overloaded vfloat64m2_t vfwcvt_f(vbool32_t op0, vfloat64m2_t op1, vfloat32m1_t op2, size_t op3){
  return vfwcvt_f_f_v_f64m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vfloat32m2_t op0, size_t op1){
  return vfwcvt_f_f_v_f64m4(op0, op1);
}

__rvv_overloaded vfloat64m4_t vfwcvt_f(vbool16_t op0, vfloat64m4_t op1, vfloat32m2_t op2, size_t op3){
  return vfwcvt_f_f_v_f64m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vfloat32m4_t op0, size_t op1){
  return vfwcvt_f_f_v_f64m8(op0, op1);
}

__rvv_overloaded vfloat64m8_t vfwcvt_f(vbool8_t op0, vfloat64m8_t op1, vfloat32m4_t op2, size_t op3){
  return vfwcvt_f_f_v_f64m8_m(op0, op1, op2, op3);
}

#endif

#if defined(__riscv_zfh)
__rvv_overloaded vfloat16m1_t vfcvt_f(vint16m1_t op0, size_t op1){
  return vfcvt_f_x_v_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfcvt_f(vbool16_t op0, vfloat16m1_t op1, vint16m1_t op2, size_t op3){
  return vfcvt_f_x_v_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfcvt_f(vint16m2_t op0, size_t op1){
  return vfcvt_f_x_v_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfcvt_f(vbool8_t op0, vfloat16m2_t op1, vint16m2_t op2, size_t op3){
  return vfcvt_f_x_v_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfcvt_f(vint16m4_t op0, size_t op1){
  return vfcvt_f_x_v_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfcvt_f(vbool4_t op0, vfloat16m4_t op1, vint16m4_t op2, size_t op3){
  return vfcvt_f_x_v_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m8_t vfcvt_f(vint16m8_t op0, size_t op1){
  return vfcvt_f_x_v_f16m8(op0, op1);
}

__rvv_overloaded vfloat16m8_t vfcvt_f(vbool2_t op0, vfloat16m8_t op1, vint16m8_t op2, size_t op3){
  return vfcvt_f_x_v_f16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfcvt_f(vint16mf2_t op0, size_t op1){
  return vfcvt_f_x_v_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfcvt_f(vbool32_t op0, vfloat16mf2_t op1, vint16mf2_t op2, size_t op3){
  return vfcvt_f_x_v_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfcvt_f(vint16mf4_t op0, size_t op1){
  return vfcvt_f_x_v_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfcvt_f(vbool64_t op0, vfloat16mf4_t op1, vint16mf4_t op2, size_t op3){
  return vfcvt_f_x_v_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m1_t vfcvt_f(vuint16m1_t op0, size_t op1){
  return vfcvt_f_xu_v_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfcvt_f(vbool16_t op0, vfloat16m1_t op1, vuint16m1_t op2, size_t op3){
  return vfcvt_f_xu_v_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfcvt_f(vuint16m2_t op0, size_t op1){
  return vfcvt_f_xu_v_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfcvt_f(vbool8_t op0, vfloat16m2_t op1, vuint16m2_t op2, size_t op3){
  return vfcvt_f_xu_v_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfcvt_f(vuint16m4_t op0, size_t op1){
  return vfcvt_f_xu_v_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfcvt_f(vbool4_t op0, vfloat16m4_t op1, vuint16m4_t op2, size_t op3){
  return vfcvt_f_xu_v_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m8_t vfcvt_f(vuint16m8_t op0, size_t op1){
  return vfcvt_f_xu_v_f16m8(op0, op1);
}

__rvv_overloaded vfloat16m8_t vfcvt_f(vbool2_t op0, vfloat16m8_t op1, vuint16m8_t op2, size_t op3){
  return vfcvt_f_xu_v_f16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfcvt_f(vuint16mf2_t op0, size_t op1){
  return vfcvt_f_xu_v_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfcvt_f(vbool32_t op0, vfloat16mf2_t op1, vuint16mf2_t op2, size_t op3){
  return vfcvt_f_xu_v_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfcvt_f(vuint16mf4_t op0, size_t op1){
  return vfcvt_f_xu_v_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfcvt_f(vbool64_t op0, vfloat16mf4_t op1, vuint16mf4_t op2, size_t op3){
  return vfcvt_f_xu_v_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfncvt_f(vint32mf2_t op0, size_t op1){
  return vfncvt_f_x_w_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfncvt_f(vbool64_t op0, vfloat16mf4_t op1, vint32mf2_t op2, size_t op3){
  return vfncvt_f_x_w_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfncvt_f(vint32m1_t op0, size_t op1){
  return vfncvt_f_x_w_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfncvt_f(vbool32_t op0, vfloat16mf2_t op1, vint32m1_t op2, size_t op3){
  return vfncvt_f_x_w_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m1_t vfncvt_f(vint32m2_t op0, size_t op1){
  return vfncvt_f_x_w_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfncvt_f(vbool16_t op0, vfloat16m1_t op1, vint32m2_t op2, size_t op3){
  return vfncvt_f_x_w_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfncvt_f(vint32m4_t op0, size_t op1){
  return vfncvt_f_x_w_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfncvt_f(vbool8_t op0, vfloat16m2_t op1, vint32m4_t op2, size_t op3){
  return vfncvt_f_x_w_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfncvt_f(vint32m8_t op0, size_t op1){
  return vfncvt_f_x_w_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfncvt_f(vbool4_t op0, vfloat16m4_t op1, vint32m8_t op2, size_t op3){
  return vfncvt_f_x_w_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfncvt_f(vuint32mf2_t op0, size_t op1){
  return vfncvt_f_xu_w_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfncvt_f(vbool64_t op0, vfloat16mf4_t op1, vuint32mf2_t op2, size_t op3){
  return vfncvt_f_xu_w_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfncvt_f(vuint32m1_t op0, size_t op1){
  return vfncvt_f_xu_w_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfncvt_f(vbool32_t op0, vfloat16mf2_t op1, vuint32m1_t op2, size_t op3){
  return vfncvt_f_xu_w_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m1_t vfncvt_f(vuint32m2_t op0, size_t op1){
  return vfncvt_f_xu_w_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfncvt_f(vbool16_t op0, vfloat16m1_t op1, vuint32m2_t op2, size_t op3){
  return vfncvt_f_xu_w_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfncvt_f(vuint32m4_t op0, size_t op1){
  return vfncvt_f_xu_w_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfncvt_f(vbool8_t op0, vfloat16m2_t op1, vuint32m4_t op2, size_t op3){
  return vfncvt_f_xu_w_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfncvt_f(vuint32m8_t op0, size_t op1){
  return vfncvt_f_xu_w_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfncvt_f(vbool4_t op0, vfloat16m4_t op1, vuint32m8_t op2, size_t op3){
  return vfncvt_f_xu_w_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfwcvt_f(vint8mf8_t op0, size_t op1){
  return vfwcvt_f_x_v_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfwcvt_f(vbool64_t op0, vfloat16mf4_t op1, vint8mf8_t op2, size_t op3){
  return vfwcvt_f_x_v_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfwcvt_f(vint8mf4_t op0, size_t op1){
  return vfwcvt_f_x_v_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfwcvt_f(vbool32_t op0, vfloat16mf2_t op1, vint8mf4_t op2, size_t op3){
  return vfwcvt_f_x_v_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m1_t vfwcvt_f(vint8mf2_t op0, size_t op1){
  return vfwcvt_f_x_v_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfwcvt_f(vbool16_t op0, vfloat16m1_t op1, vint8mf2_t op2, size_t op3){
  return vfwcvt_f_x_v_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfwcvt_f(vint8m1_t op0, size_t op1){
  return vfwcvt_f_x_v_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfwcvt_f(vbool8_t op0, vfloat16m2_t op1, vint8m1_t op2, size_t op3){
  return vfwcvt_f_x_v_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfwcvt_f(vint8m2_t op0, size_t op1){
  return vfwcvt_f_x_v_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfwcvt_f(vbool4_t op0, vfloat16m4_t op1, vint8m2_t op2, size_t op3){
  return vfwcvt_f_x_v_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m8_t vfwcvt_f(vint8m4_t op0, size_t op1){
  return vfwcvt_f_x_v_f16m8(op0, op1);
}

__rvv_overloaded vfloat16m8_t vfwcvt_f(vbool2_t op0, vfloat16m8_t op1, vint8m4_t op2, size_t op3){
  return vfwcvt_f_x_v_f16m8_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf4_t vfwcvt_f(vuint8mf8_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16mf4(op0, op1);
}

__rvv_overloaded vfloat16mf4_t vfwcvt_f(vbool64_t op0, vfloat16mf4_t op1, vuint8mf8_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16mf4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16mf2_t vfwcvt_f(vuint8mf4_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16mf2(op0, op1);
}

__rvv_overloaded vfloat16mf2_t vfwcvt_f(vbool32_t op0, vfloat16mf2_t op1, vuint8mf4_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m1_t vfwcvt_f(vuint8mf2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16m1(op0, op1);
}

__rvv_overloaded vfloat16m1_t vfwcvt_f(vbool16_t op0, vfloat16m1_t op1, vuint8mf2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m2_t vfwcvt_f(vuint8m1_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16m2(op0, op1);
}

__rvv_overloaded vfloat16m2_t vfwcvt_f(vbool8_t op0, vfloat16m2_t op1, vuint8m1_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m4_t vfwcvt_f(vuint8m2_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16m4(op0, op1);
}

__rvv_overloaded vfloat16m4_t vfwcvt_f(vbool4_t op0, vfloat16m4_t op1, vuint8m2_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat16m8_t vfwcvt_f(vuint8m4_t op0, size_t op1){
  return vfwcvt_f_xu_v_f16m8(op0, op1);
}

__rvv_overloaded vfloat16m8_t vfwcvt_f(vbool2_t op0, vfloat16m8_t op1, vuint8m4_t op2, size_t op3){
  return vfwcvt_f_xu_v_f16m8_m(op0, op1, op2, op3);
}

#endif

#if defined(__riscv_f) && defined(__riscv_zfh)
__rvv_overloaded vfloat32mf2_t vfwcvt_f(vfloat16mf4_t op0, size_t op1){
  return vfwcvt_f_f_v_f32mf2(op0, op1);
}

__rvv_overloaded vfloat32mf2_t vfwcvt_f(vbool64_t op0, vfloat32mf2_t op1, vfloat16mf4_t op2, size_t op3){
  return vfwcvt_f_f_v_f32mf2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vfloat16mf2_t op0, size_t op1){
  return vfwcvt_f_f_v_f32m1(op0, op1);
}

__rvv_overloaded vfloat32m1_t vfwcvt_f(vbool32_t op0, vfloat32m1_t op1, vfloat16mf2_t op2, size_t op3){
  return vfwcvt_f_f_v_f32m1_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vfloat16m1_t op0, size_t op1){
  return vfwcvt_f_f_v_f32m2(op0, op1);
}

__rvv_overloaded vfloat32m2_t vfwcvt_f(vbool16_t op0, vfloat32m2_t op1, vfloat16m1_t op2, size_t op3){
  return vfwcvt_f_f_v_f32m2_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vfloat16m2_t op0, size_t op1){
  return vfwcvt_f_f_v_f32m4(op0, op1);
}

__rvv_overloaded vfloat32m4_t vfwcvt_f(vbool8_t op0, vfloat32m4_t op1, vfloat16m2_t op2, size_t op3){
  return vfwcvt_f_f_v_f32m4_m(op0, op1, op2, op3);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vfloat16m4_t op0, size_t op1){
  return vfwcvt_f_f_v_f32m8(op0, op1);
}

__rvv_overloaded vfloat32m8_t vfwcvt_f(vbool4_t op0, vfloat32m8_t op1, vfloat16m4_t op2, size_t op3){
  return vfwcvt_f_f_v_f32m8_m(op0, op1, op2, op3);
}

#endif


#ifdef __cplusplus
}
#endif // __riscv_vector
#endif // __RISCV_VECTOR_H
